<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>How LLMs Actually Work</title>
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,600;1,400&display=swap"
    />
    <style>
      :root {
        --paper: #fafaf8;
        --ink: #1a1a18;
        --ink2: #6b6b66;
        --ink3: #b8b4aa;
        --ink4: #ddd9d0;
        --seed: #edeadf;
        --seedh: #e4e0d4;
        --hl: #fff3c4;
        --acc: #4a6741;
        --paper-warm: #faf8f2;
        --bg-temp: 0;
        --t-page: 0.2s;
        --t-step: 0.4s;
        --t-whisper: 0.6s;
        --t-constellation: 0.6s;
        --t-liminal-in: 0.2s;
        --t-liminal-out: 0.2s;
        --t-dwell: 0.4s;
        --t-scatter: 0.6s;
        --t-ghostfade: 0.3s;
        --t-engagement: 0.2s;
      }

      * {
        box-sizing: border-box;
      }

      body {
        margin: 0;
        background: color-mix(in srgb, var(--paper) calc((1 - var(--bg-temp)) * 100%), var(--paper-warm));
        color: var(--ink);
        font-family: "Lora", Georgia, serif;
        font-size: 18px;
        line-height: 1.65;
        overflow-x: hidden;
      }

      a {
        color: inherit;
        text-decoration: none;
      }

      ::selection {
        background: var(--hl);
      }

      :focus-visible {
        outline: 2px solid var(--ink);
        outline-offset: 2px;
      }

      .view {
        opacity: 0;
        transition: opacity var(--t-page) ease;
      }

      .view.is-visible {
        opacity: 1;
      }

      .landing,
      .plateau {
        min-height: 100vh;
        padding: 72px 24px 96px;
      }

      .landing {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 24px;
      }

      .landing-header {
        text-align: center;
        max-width: 42rem;
      }

      .landing-header h1 {
        font-size: clamp(2.4rem, 4vw, 3.2rem);
        font-weight: 600;
        letter-spacing: -0.02em;
        margin: 0 0 0.35rem;
      }

      .landing-header .subtitle {
        font-style: italic;
        color: var(--ink2);
        margin: 0 0 1.25rem;
        font-size: 1.05rem;
      }

      .landing-header p {
        margin: 0;
        color: var(--ink);
      }

      .landing-map {
        width: min(460px, 100%);
      }

      .map-wrap {
        position: relative;
        width: 100%;
        aspect-ratio: 460 / 360;
      }

      .map-wrap canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .map-overlay {
        position: absolute;
        inset: 0;
        pointer-events: none;
      }

      .map-link {
        position: absolute;
        width: 44px;
        height: 44px;
        transform: translate(-50%, -50%);
        border-radius: 50%;
        pointer-events: auto;
      }

      .map-link:focus-visible {
        outline-offset: 4px;
      }

      .map-note {
        margin-top: 16px;
        color: var(--ink2);
        font-size: 0.95rem;
        font-style: italic;
        text-align: center;
      }

      .mini-map {
        position: fixed;
        right: 32px;
        bottom: 32px;
        width: 160px;
        height: 120px;
        border-radius: 16px;
        border: 1px solid var(--ink4);
        background: color-mix(in srgb, var(--paper) 92%, white 8%);
        box-shadow: 0 14px 30px rgba(26, 26, 24, 0.08);
        overflow: hidden;
        z-index: 20;
        transition: border-color 0.2s ease;
      }

      .mini-map canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .mini-map:hover {
        border-color: var(--ink3);
        transition: border-color 0.2s ease;
      }

      .mini-map-button {
        position: absolute;
        inset: 0;
        border: none;
        background: transparent;
        border-radius: inherit;
        cursor: pointer;
      }

      .rhizome-overlay {
        position: fixed;
        inset: 0;
        display: flex;
        align-items: center;
        justify-content: center;
        opacity: 0;
        pointer-events: none;
        transition: opacity var(--t-page) ease;
        z-index: 40;
      }

      .rhizome-overlay.is-open {
        opacity: 1;
        pointer-events: auto;
      }

      .overlay-backdrop {
        position: absolute;
        inset: 0;
        background: rgba(250, 250, 248, 0.82);
        backdrop-filter: blur(10px);
      }

      .overlay-panel {
        position: relative;
        z-index: 1;
        background: rgba(250, 250, 248, 0.96);
        border: 1px solid var(--ink4);
        border-radius: 24px;
        padding: 32px;
        box-shadow: 0 30px 80px rgba(26, 26, 24, 0.18);
      }

      .overlay-map {
        position: relative;
        width: min(90vw, 700px);
        aspect-ratio: 700 / 550;
      }

      .overlay-map canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .overlay-links {
        position: absolute;
        inset: 0;
      }

      .overlay-link {
        position: absolute;
        width: 44px;
        height: 44px;
        transform: translate(-50%, -50%);
        border-radius: 50%;
        opacity: 0;
      }

      .overlay-link:focus-visible {
        opacity: 1;
        background: rgba(74, 103, 65, 0.12);
        outline-offset: 4px;
      }

      .overlay-link:hover {
        opacity: 1;
        background: rgba(74, 103, 65, 0.08);
      }

      .overlay-close {
        position: absolute;
        top: 16px;
        right: 16px;
        border: 1px solid var(--ink4);
        background: var(--paper);
        color: var(--ink2);
        border-radius: 999px;
        padding: 0.4rem 0.9rem;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.7rem;
        letter-spacing: 0.08em;
        text-transform: uppercase;
        cursor: pointer;
      }

      body.overlay-open {
        overflow: hidden;
      }

      .plateau {
        max-width: 42rem;
        margin: 0 auto;
      }

      .entry-question {
        margin-top: 0.75rem;
        color: var(--ink2);
        font-style: italic;
      }

      .scrolly {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 0;
        margin-top: 48px;
        border-top: 1px solid var(--ink4);
      }

      .scrolly-viz {
        position: sticky;
        top: 0;
        height: 100vh;
        border-right: 1px solid var(--ink4);
        display: flex;
        align-items: center;
        justify-content: center;
        background: linear-gradient(180deg, rgba(250, 250, 248, 0.9), rgba(250, 250, 248, 0.98));
        overflow: hidden;
      }

      .viz-main {
        width: min(380px, 90%);
        min-height: 240px;
        border: 1px solid var(--ink4);
        border-radius: 20px;
        display: grid;
        place-items: center;
        color: var(--ink2);
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.9rem;
        text-transform: uppercase;
        letter-spacing: 0.08em;
        transition: opacity var(--t-constellation) ease;
      }

      .scrolly-viz.is-constellation .viz-main {
        opacity: 0.2;
      }

      .viz-main canvas {
        display: block;
        width: 100%;
        height: 100%;
      }

      .viz-main .viz-controls {
        display: flex;
        flex-wrap: wrap;
        gap: 12px;
        align-items: center;
        padding: 12px 16px;
        width: 100%;
      }

      .viz-main .viz-slider {
        -webkit-appearance: none;
        appearance: none;
        width: 100%;
        height: 6px;
        border-radius: 3px;
        background: var(--ink4);
        outline: none;
        min-height: 44px;
        padding: 19px 0;
        background-clip: content-box;
      }

      .viz-main .viz-slider::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: var(--acc);
        cursor: pointer;
        border: 2px solid var(--paper);
        box-shadow: 0 1px 4px rgba(26, 26, 24, 0.15);
      }

      .viz-main .viz-slider::-moz-range-thumb {
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: var(--acc);
        cursor: pointer;
        border: 2px solid var(--paper);
        box-shadow: 0 1px 4px rgba(26, 26, 24, 0.15);
      }

      .viz-main .viz-toggle {
        display: inline-flex;
        align-items: center;
        gap: 8px;
        min-height: 44px;
        min-width: 44px;
        padding: 8px 16px;
        border: 1px solid var(--ink4);
        border-radius: 999px;
        background: var(--paper);
        color: var(--ink2);
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.8rem;
        cursor: pointer;
        transition: background var(--t-engagement) ease, color var(--t-engagement) ease;
      }

      .viz-main .viz-toggle.is-active {
        background: var(--acc);
        color: var(--paper);
        border-color: var(--acc);
      }

      .viz-main .viz-sr-status {
        position: absolute;
        width: 1px;
        height: 1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
      }

      @keyframes viz-nw-blink {
        50% { opacity: 0; }
      }

      @media (max-width: 840px) {
        .viz-main .viz-slider {
          width: 100%;
        }

        .viz-main .viz-controls {
          padding: 8px 12px;
        }
      }

      .scrolly-no-viz {
        grid-template-columns: 1fr;
      }

      .scrolly-steps {
        padding: 0 36px;
      }

      .scrolly-step {
        min-height: 65vh;
        display: flex;
        align-items: center;
        color: var(--ink3);
        transition: color var(--t-step) ease;
      }

      .scrolly-step.is-active {
        color: var(--ink);
      }

      .whisper-layer {
        position: absolute;
        right: 22px;
        top: 18%;
        display: flex;
        flex-direction: column;
        gap: 12px;
        text-align: right;
        font-style: italic;
        color: var(--ink2);
        font-size: 0.82rem;
      }

      .whisper {
        opacity: 0;
        transform: translateX(8px);
        transition: opacity var(--t-whisper) ease, transform var(--t-whisper) ease;
      }

      .whisper.is-visible {
        opacity: 1;
        transform: translateX(0);
      }

      .trace-pips {
        position: absolute;
        right: 12px;
        top: 18%;
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .trace-pip {
        width: 6px;
        height: 6px;
        border-radius: 999px;
        background: var(--ink4);
      }

      .trace-pip.is-lit {
        background: var(--ink);
      }

      .constellation {
        position: absolute;
        inset: 0;
        display: grid;
        place-items: center;
        opacity: 0;
        transition: opacity var(--t-constellation) ease;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        color: var(--ink2);
        letter-spacing: 0.08em;
        text-transform: uppercase;
        font-size: 0.8rem;
      }

      .constellation.is-visible {
        opacity: 1;
      }

      .simple-constellation {
        margin-top: 48px;
        display: flex;
        justify-content: center;
      }

      .simple-constellation canvas {
        display: block;
        max-width: 100%;
      }

      .question-cards {
        margin-top: 32px;
        display: grid;
        gap: 14px;
      }

      .question-card {
        border: 1px solid var(--ink4);
        border-radius: 14px;
        padding: 14px 16px;
        display: flex;
        flex-direction: column;
        gap: 6px;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        color: var(--ink2);
        transition: border-color 0.2s ease, transform 0.2s ease, opacity var(--t-ghostfade) ease;
      }

      .question-card:hover {
        border-color: var(--ink2);
        transform: translateY(-1px);
      }

      .question-card span {
        font-style: italic;
        color: var(--ink);
        font-family: "Lora", Georgia, serif;
      }

      .seed-field {
        margin-top: 32px;
        display: flex;
        flex-direction: column;
        gap: 18px;
      }

      .simple-whisper {
        position: absolute;
        right: -220px;
        top: 10px;
        width: 190px;
        font-style: italic;
        color: var(--ink2);
        font-size: 0.82rem;
        text-align: right;
        opacity: 0;
        transform: translateX(8px);
        transition: opacity var(--t-whisper) ease, transform var(--t-whisper) ease;
        text-decoration: none;
      }

      .simple-whisper::before {
        content: "\2192 ";
      }

      .simple-whisper.is-visible {
        opacity: 1;
        transform: translateX(0);
      }

      .simple-whisper-pips {
        position: fixed;
        right: 24px;
        top: 50%;
        transform: translateY(-50%);
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .simple-whisper-pip {
        width: 6px;
        height: 6px;
        border-radius: 999px;
        background: var(--ink4);
        transition: background 0.3s ease;
      }

      .simple-whisper-pip.is-lit {
        background: var(--ink);
      }

      .seed-item {
        position: relative;
        border: 1px solid var(--ink4);
        border-radius: 16px;
        padding: 14px 16px;
        background: rgba(237, 234, 223, 0.4);
      }

      .seed-button {
        border: none;
        background: var(--seed);
        color: var(--ink);
        font-family: "Lora", Georgia, serif;
        font-size: 1rem;
        padding: 6px 10px;
        border-radius: 999px;
        border-bottom: 1px dotted var(--ink2);
        cursor: pointer;
      }

      .seed-button:hover {
        background: var(--seedh);
      }

      .seed-growth {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.35s ease;
      }

      .seed-growth.is-open {
        max-height: 220px;
        overflow-y: auto;
      }

      .seed-growth-inner {
        margin-top: 12px;
        padding-left: 14px;
        border-left: 2px solid var(--ink4);
        color: var(--ink2);
      }

      .inline-seed {
        display: inline;
        position: relative;
      }

      .inline-seed-button {
        border: none;
        background: var(--seed);
        color: inherit;
        font: inherit;
        padding: 0 4px;
        border-radius: 6px;
        border-bottom: 1px dotted var(--ink2);
        cursor: pointer;
      }

      .inline-seed-button:hover {
        background: var(--seedh);
      }

      .inline-seed-popover {
        position: fixed;
        z-index: 60;
        width: min(360px, 90vw);
        max-height: 240px;
        overflow-y: auto;
        background: var(--paper);
        border: 1px solid var(--ink4);
        border-radius: 12px;
        padding: 14px 16px;
        box-shadow: 0 12px 40px rgba(26, 26, 24, 0.14);
        opacity: 0;
        transform: translateY(4px);
        transition: opacity 0.2s ease, transform 0.2s ease;
        pointer-events: none;
      }

      .inline-seed-popover.is-open {
        opacity: 1;
        transform: translateY(0);
        pointer-events: auto;
      }

      .inline-seed-popover-content {
        color: var(--ink2);
        font-size: 0.95rem;
        line-height: 1.55;
      }

      .plateau .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.4rem;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.85rem;
        letter-spacing: 0.02em;
        text-transform: uppercase;
        color: var(--ink2);
      }

      .plateau h1 {
        margin-top: 1.5rem;
        font-size: 2.2rem;
      }

      .visually-hidden {
        position: absolute;
        width: 1px;
        height: 1px;
        margin: -1px;
        border: 0;
        padding: 0;
        white-space: nowrap;
        clip-path: inset(100%);
        clip: rect(0 0 0 0);
        overflow: hidden;
      }

      /* Question-seed: italic label with dotted underline */
      .inline-seed-button[data-seed-type="question"] {
        font-style: italic;
        border-bottom-style: dotted;
      }

      /* Seed growth for question-seeds */
      .seed-button[data-seed-type="question"] {
        font-style: italic;
        border-bottom-style: dotted;
      }

      /* Dangling reference trailing link */
      .dangling-link {
        font-style: italic;
        color: var(--ink2);
        border-bottom: 1px dotted var(--ink2);
        cursor: pointer;
      }

      .dangling-link:hover {
        color: var(--ink);
      }

      /* Liminal transition overlay */
      .liminal-transition {
        position: fixed;
        inset: 0;
        display: flex;
        align-items: center;
        justify-content: center;
        z-index: 50;
        opacity: 0;
        background: rgba(250, 250, 248, 0.88);
        backdrop-filter: blur(12px);
        transition: opacity var(--t-liminal-in) ease;
        pointer-events: none;
      }

      .liminal-transition.is-visible {
        opacity: 1;
      }

      .liminal-transition.is-fading {
        opacity: 0;
        transition: opacity var(--t-liminal-out) ease;
      }

      .liminal-question {
        font-style: italic;
        color: var(--ink);
        font-size: 1.1rem;
        max-width: 32rem;
        text-align: center;
        line-height: 1.7;
        padding: 0 24px;
      }

      /* Ghostfading visited concepts */
      .ghostfaded {
        opacity: 0.85;
        transition: opacity var(--t-ghostfade) ease;
      }

      .ghostfaded .inline-seed-button,
      .ghostfaded .seed-button,
      .ghostfaded a {
        opacity: 1;
      }

      /* Engagement state counter */
      .engagement-state {
        color: var(--ink3);
        font-size: 0.72rem;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        margin-top: 16px;
        opacity: 1;
        transition: opacity var(--t-engagement) ease;
      }

      /* Dwell-reveal annotations */
      .dwell-annotation {
        position: absolute;
        right: -180px;
        top: 0;
        width: 160px;
        max-width: calc(100vw - 100%);
        font-style: italic;
        color: var(--ink3);
        font-size: 0.78rem;
        line-height: 1.5;
        opacity: 0;
        transition: opacity var(--t-dwell) ease;
      }

      .dwell-annotation.is-revealed {
        opacity: 1;
      }

      .dwell-target {
        position: relative;
      }

      /* Author marginalia */
      .plateau-with-marginalia {
        max-width: 54rem;
        display: grid;
        grid-template-columns: 1fr 180px;
        gap: 0 32px;
      }

      .plateau-with-marginalia > * {
        grid-column: 1;
      }

      .marginalia {
        grid-column: 2;
        font-style: italic;
        color: var(--ink3);
        font-size: 0.78rem;
        line-height: 1.5;
        align-self: start;
        padding-top: 4px;
      }

      /* Cross-plateau retrieval moment */
      .retrieval-moment {
        background: var(--seed);
        color: var(--ink2);
        border-top: 2px solid var(--ink4);
        border-radius: 0 0 12px 12px;
        padding: 14px 18px;
        margin-bottom: 24px;
        font-size: 0.92rem;
        line-height: 1.6;
        display: flex;
        align-items: flex-start;
        gap: 12px;
        opacity: 1;
        transition: opacity 0.3s ease;
      }

      .retrieval-moment.is-dismissed {
        opacity: 0;
        pointer-events: none;
      }

      .retrieval-close {
        border: 1px solid var(--ink4);
        background: transparent;
        color: var(--ink3);
        border-radius: 999px;
        width: 24px;
        height: 24px;
        font-size: 0.7rem;
        cursor: pointer;
        flex-shrink: 0;
        display: grid;
        place-items: center;
        font-family: system-ui, sans-serif;
      }

      .retrieval-close:hover {
        color: var(--ink2);
        border-color: var(--ink2);
      }

      /* Micro-CYOA forks */
      .cyoa-fork {
        margin-top: 24px;
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .cyoa-option {
        border: 1px solid var(--ink4);
        border-radius: 14px;
        padding: 14px 18px;
        background: transparent;
        font: inherit;
        text-align: left;
        cursor: pointer;
        color: var(--ink2);
        opacity: 0.7;
        transition: opacity 0.2s ease, border-color 0.2s ease;
      }

      .cyoa-option:hover {
        border-color: var(--ink2);
      }

      .cyoa-option.is-chosen {
        opacity: 1;
        color: var(--ink);
        border-color: var(--ink);
      }

      .cyoa-option.is-unchosen {
        opacity: 0.7;
        color: var(--ink2);
      }

      .cyoa-option:not(.is-chosen):not(.is-unchosen) {
        opacity: 1;
        color: var(--ink);
      }

      .cyoa-expansion {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.35s ease;
      }

      .cyoa-expansion.is-open {
        max-height: 300px;
        overflow-y: auto;
      }

      .cyoa-expansion-inner {
        margin-top: 10px;
        padding-left: 14px;
        border-left: 2px solid var(--ink4);
        color: var(--ink2);
      }

      /* Scatter-to-text */
      .scatter-container {
        position: relative;
        width: 100%;
        height: 100%;
        overflow: hidden;
      }

      .scatter-word {
        position: absolute;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.85rem;
        font-weight: 600;
        color: var(--ink2);
        text-transform: uppercase;
        letter-spacing: 0.06em;
        transition: transform var(--t-scatter) ease;
        white-space: nowrap;
      }

      @media (max-width: 600px) {
        .landing,
        .plateau {
          padding-top: 56px;
        }

        .landing-header h1 {
          font-size: 2.2rem;
        }
      }

      @media (max-width: 840px) {
        .scrolly {
          grid-template-columns: 1fr;
        }

        .scrolly-viz {
          height: 42vh;
          border-right: none;
          border-bottom: 1px solid var(--ink4);
        }

        .scrolly-steps {
          padding: 0 20px;
        }

        .plateau-with-marginalia {
          grid-template-columns: 1fr;
        }

        .marginalia {
          grid-column: 1;
          padding-left: 24px;
          margin-top: -8px;
          margin-bottom: 12px;
        }

        .dwell-annotation {
          position: static;
          width: auto;
          margin-top: 8px;
          padding-left: 12px;
          border-left: 2px solid var(--ink4);
        }

        .simple-whisper {
          position: static;
          width: auto;
          text-align: left;
          margin-top: 8px;
          transform: none;
        }

        .simple-whisper.is-visible {
          transform: none;
        }

        .simple-whisper-pips {
          display: none;
        }
      }

      @media (max-width: 480px) {
        .mini-map {
          width: 44px;
          height: 44px;
          border-radius: 50%;
          right: 20px;
          bottom: 20px;
        }

        .scrolly-viz {
          height: 38vh;
        }

        .whisper-layer,
        .trace-pips {
          font-size: 0.75rem;
          position: static;
          flex-direction: row;
          flex-wrap: wrap;
          gap: 8px;
          padding: 8px 20px;
          border-bottom: 1px solid var(--ink4);
        }

        .whisper {
          opacity: 0.7;
          transform: none;
        }

        .whisper.is-visible {
          opacity: 1;
        }

        .trace-pips {
          display: none;
        }

        .dwell-annotation {
          position: static;
          width: auto;
          margin-top: 8px;
          padding-left: 12px;
          border-left: 2px solid var(--ink4);
        }
      }

      @media (prefers-reduced-motion: reduce) {
        :root {
          --t-page: 0s;
          --t-step: 0s;
          --t-whisper: 0s;
          --t-constellation: 0s;
          --t-liminal-in: 0s;
          --t-liminal-out: 0s;
          --t-dwell: 0s;
          --t-scatter: 0s;
          --t-ghostfade: 0s;
          --t-engagement: 0s;
          --bg-temp: 0 !important;
        }

        *,
        *::before,
        *::after {
          transition-duration: 0s !important;
          animation-duration: 0s !important;
        }
      }
    </style>
  </head>
  <body>
    <div id="app"></div>
    <script>
      const GRAPH = {
        nodes: [
          { id: "next-word", title: "The Next Word", label: "Next Word", shortQ: "What does it do when it talks?", x: 0.42, y: 0.06 },
          { id: "weight-of-words", title: "The Weight of Words", label: "Weight", shortQ: "How does it learn from words?", x: 0.28, y: 0.18 },
          { id: "algorithm-as-muse", title: "The Algorithm as Muse", label: "Muse", shortQ: "When AI creates art, who's the artist?", x: 0.68, y: 0.12 },
          { id: "averaging-problem", title: "The Averaging Problem", label: "Averaging", shortQ: "Best essay or average essay?", x: 0.55, y: 0.22 },
          { id: "the-shaping", title: "The Shaping", label: "Shaping", shortQ: "Autocomplete to assistant?", x: 0.15, y: 0.34 },
          { id: "understanding-illusion", title: "The Understanding Illusion", label: "Understanding", shortQ: "Does it understand?", x: 0.85, y: 0.28 },
          { id: "learning-machines-learning-humans", title: "Learning Machines, Learning Humans", label: "Learning AI", shortQ: "What happens when AI has all answers?", x: 0.05, y: 0.44 },
          { id: "echoes-of-the-past", title: "Echoes of the Past", label: "Echoes", shortQ: "What if AI reads history with bias?", x: 0.92, y: 0.42 },
          { id: "tool-user", title: "The Tool-User", label: "Tool-User", shortQ: "What if it can use tools?", x: 0.30, y: 0.56 },
          { id: "quality", title: "What Is Quality?", label: "Quality", shortQ: "Who decides what's good?", x: 0.72, y: 0.48 },
          { id: "black-box-oracle", title: "The Black Box Oracle", label: "Black Box", shortQ: "Trust a decision you can't explain?", x: 0.08, y: 0.55 },
          { id: "near-zero-cost-impact", title: "The Near-Zero Cost Impact", label: "Near-Zero", shortQ: "When production cost approaches zero?", x: 0.52, y: 0.62 },
          { id: "practical-guide", title: "The Field Guide", label: "Field Guide", shortQ: "What do I actually do?", x: 0.38, y: 0.74 },
          { id: "automation-of-cognition", title: "The Automation of Cognition", label: "Automation", shortQ: "When machines do the thinking?", x: 0.12, y: 0.72 },
          { id: "digital-footprints", title: "Digital Footprints", label: "Footprints", shortQ: "What does AI cost the planet?", x: 0.62, y: 0.82 },
          { id: "artificial-brain", title: "The Artificial Brain", label: "Art. Brain", shortQ: "Is a neural network like a brain?", x: 0.35, y: 0.90 },
          { id: "empathy-machine", title: "The Empathy Machine?", label: "Empathy", shortQ: "Can simulated empathy help or harm?", x: 0.78, y: 0.68 },
        ],
        edges: [
          ["next-word", "averaging-problem"],
          ["next-word", "understanding-illusion"],
          ["next-word", "weight-of-words"],
          ["next-word", "learning-machines-learning-humans"],
          ["next-word", "algorithm-as-muse"],
          ["next-word", "artificial-brain"],
          ["next-word", "empathy-machine"],
          ["averaging-problem", "the-shaping"],
          ["averaging-problem", "quality"],
          ["averaging-problem", "weight-of-words"],
          ["averaging-problem", "practical-guide"],
          ["averaging-problem", "understanding-illusion"],
          ["averaging-problem", "near-zero-cost-impact"],
          ["the-shaping", "quality"],
          ["the-shaping", "practical-guide"],
          ["the-shaping", "tool-user"],
          ["the-shaping", "weight-of-words"],
          ["the-shaping", "learning-machines-learning-humans"],
          ["the-shaping", "black-box-oracle"],
          ["the-shaping", "automation-of-cognition"],
          ["the-shaping", "algorithm-as-muse"],
          ["the-shaping", "near-zero-cost-impact"],
          ["quality", "understanding-illusion"],
          ["quality", "practical-guide"],
          ["quality", "echoes-of-the-past"],
          ["quality", "black-box-oracle"],
          ["quality", "empathy-machine"],
          ["quality", "digital-footprints"],
          ["quality", "near-zero-cost-impact"],
          ["understanding-illusion", "practical-guide"],
          ["understanding-illusion", "artificial-brain"],
          ["understanding-illusion", "empathy-machine"],
          ["understanding-illusion", "echoes-of-the-past"],
          ["understanding-illusion", "tool-user"],
          ["understanding-illusion", "near-zero-cost-impact"],
          ["practical-guide", "tool-user"],
          ["practical-guide", "weight-of-words"],
          ["tool-user", "automation-of-cognition"],
          ["tool-user", "digital-footprints"],
          ["automation-of-cognition", "digital-footprints"],
          ["automation-of-cognition", "black-box-oracle"],
          ["automation-of-cognition", "near-zero-cost-impact"],
          ["black-box-oracle", "empathy-machine"],
          ["black-box-oracle", "near-zero-cost-impact"],
          ["echoes-of-the-past", "digital-footprints"],
          ["digital-footprints", "near-zero-cost-impact"],
        ],
      };

      const STORAGE_KEY = "le5";
      const app = document.querySelector("#app");
      let activeCleanup = () => {};

      const h = (tag, attrs, ...children) => {
        const el = document.createElement(tag);
        if (attrs) {
          Object.entries(attrs).forEach(([key, value]) => {
            if (value === null || value === undefined) return;
            if (key === "class") {
              el.className = value;
              return;
            }
            if (key === "style" && typeof value === "object") {
              Object.assign(el.style, value);
              return;
            }
            if (key.startsWith("on") && typeof value === "function") {
              el.addEventListener(key.slice(2), value);
              return;
            }
            el.setAttribute(key, value);
          });
        }
        children.flat().forEach((child) => {
          if (child === null || child === undefined) return;
          if (typeof child === "string") {
            el.appendChild(document.createTextNode(child));
          } else {
            el.appendChild(child);
          }
        });
        return el;
      };

      const loadState = () => {
        try {
          const raw = localStorage.getItem(STORAGE_KEY);
          if (!raw) return { v: [], tr: [], si: {}, eg: {} };
          const parsed = JSON.parse(raw);
          if (!parsed || !Array.isArray(parsed.v) || !Array.isArray(parsed.tr)) {
            throw new Error("Invalid state");
          }
          return {
            v: parsed.v,
            tr: parsed.tr,
            si: parsed.si && typeof parsed.si === "object" ? parsed.si : {},
            eg: parsed.eg && typeof parsed.eg === "object" ? parsed.eg : {},
          };
        } catch (error) {
          return { v: [], tr: [], si: {}, eg: {} };
        }
      };

      const saveState = (state) => {
        localStorage.setItem(STORAGE_KEY, JSON.stringify(state));
      };

      const recordVisit = (state, plateauId) => {
        if (!state.v.includes(plateauId)) {
          state.v.push(plateauId);
        }
        state.tr.push({ p: plateauId, t: Date.now() });
        saveState(state);
      };

      const recordSeedOpen = (state, plateauId, seedId) => {
        if (!state.si[plateauId]) state.si[plateauId] = [];
        if (state.si[plateauId].includes(seedId)) return false;
        state.si[plateauId].push(seedId);
        if (!state.eg[plateauId]) state.eg[plateauId] = { opened: 0, total: 0 };
        state.eg[plateauId].opened++;
        saveState(state);
        return true;
      };

      const initEngagement = (state, plateauId, totalSeeds) => {
        if (!state.eg[plateauId]) state.eg[plateauId] = { opened: 0, total: 0 };
        state.eg[plateauId].total = totalSeeds;
        saveState(state);
      };

      const getPlateau = (id) => GRAPH.nodes.find((node) => node.id === id);

      const scaleCanvas = (canvas, width, height) => {
        const ratio = window.devicePixelRatio || 1;
        canvas.width = Math.floor(width * ratio);
        canvas.height = Math.floor(height * ratio);
        canvas.style.width = `${width}px`;
        canvas.style.height = `${height}px`;
        return ratio;
      };

      const getNodePx = (node, width, height) => ({
        x: node.x * width,
        y: node.y * height,
      });

      const edgeKey = (a, b) => a < b ? `${a}|${b}` : `${b}|${a}`;

      const EDGE_SET = new Set(GRAPH.edges.map(([a, b]) => edgeKey(a, b)));

      const deriveTraversedEdges = (trail) => {
        const traversed = new Set();
        for (let i = 1; i < trail.length; i++) {
          const key = edgeKey(trail[i - 1].p, trail[i].p);
          if (EDGE_SET.has(key)) traversed.add(key);
        }
        return traversed;
      };

      const getTrailSegments = (trail) => {
        const seen = new Set();
        const ordered = [];
        trail.forEach((entry) => {
          if (seen.has(entry.p)) return;
          seen.add(entry.p);
          const node = getPlateau(entry.p);
          if (node) ordered.push(node);
        });
        return ordered;
      };

      const getFlightOpacity = (state, plateauId) => {
        const trail = state.tr;
        if (!trail || trail.length === 0) return 1.0;
        const lastIndex = trail.findLastIndex((e) => e.p === plateauId);
        if (lastIndex === -1) return 1.0;
        const segCount = trail.length - 1;
        if (segCount <= 0) return 0.45;
        const t = lastIndex / segCount;
        return 0.45 + 0.47 * (1 - t);
      };

      const drawGraph = ({
        canvas,
        width,
        height,
        visited,
        activeId,
        highlightIds,
        edgeFilter,
        showLabels,
        showTrail,
        trailNodes,
        hoveredId,
        curvedEdges,
        softenUnvisited,
        activeGlow,
        breatheAlpha,
        traversedEdges,
      }) => {
        const ctx = canvas.getContext("2d");
        if (!ctx) return;
        const ratio = scaleCanvas(canvas, width, height);
        ctx.setTransform(ratio, 0, 0, ratio, 0, 0);
        ctx.clearRect(0, 0, width, height);

        const styles = getComputedStyle(document.documentElement);
        const ink = styles.getPropertyValue("--ink").trim();
        const ink3 = styles.getPropertyValue("--ink3").trim();
        const ink4 = styles.getPropertyValue("--ink4").trim();
        const acc = styles.getPropertyValue("--acc").trim();
        const paper = styles.getPropertyValue("--paper").trim();

        const drawEdgePath = (ctx, fromPos, toPos, curved, fromId, toId) => {
          ctx.beginPath();
          ctx.moveTo(fromPos.x, fromPos.y);
          if (curved) {
            const mx = (fromPos.x + toPos.x) / 2;
            const my = (fromPos.y + toPos.y) / 2;
            const dx = toPos.x - fromPos.x;
            const dy = toPos.y - fromPos.y;
            const len = Math.sqrt(dx * dx + dy * dy) || 1;
            const sign = (fromId < toId) ? 1 : -1;
            const offset = len * 0.15 * sign;
            const cpx = mx + (-dy / len) * offset;
            const cpy = my + (dx / len) * offset;
            ctx.quadraticCurveTo(cpx, cpy, toPos.x, toPos.y);
          } else {
            ctx.lineTo(toPos.x, toPos.y);
          }
        };

        GRAPH.edges.forEach(([fromId, toId]) => {
          if (edgeFilter && !edgeFilter(fromId, toId)) return;
          if (highlightIds && (!highlightIds.has(fromId) || !highlightIds.has(toId))) return;
          if (traversedEdges && !traversedEdges.has(edgeKey(fromId, toId))) return;
          const from = GRAPH.nodes.find((node) => node.id === fromId);
          const to = GRAPH.nodes.find((node) => node.id === toId);
          if (!from || !to) return;
          const fromPos = getNodePx(from, width, height);
          const toPos = getNodePx(to, width, height);
          const touchesActive = hoveredId && (fromId === hoveredId || toId === hoveredId);
          const touchesVisited = visited.has(fromId) || visited.has(toId);
          if (softenUnvisited) {
            ctx.globalAlpha = touchesActive ? 0.5 : touchesVisited ? 0.25 : 0.06;
          } else {
            ctx.globalAlpha = touchesActive ? 0.5 : touchesVisited ? 0.3 : 0.08;
          }
          ctx.strokeStyle = ink4;
          ctx.lineWidth = touchesActive ? 1.5 : 1;
          drawEdgePath(ctx, fromPos, toPos, curvedEdges, fromId, toId);
          ctx.stroke();
        });
        ctx.globalAlpha = 1;

        if (showTrail && trailNodes && trailNodes.length > 1) {
          const segCount = trailNodes.length - 1;
          for (let i = 1; i < trailNodes.length; i++) {
            const prev = trailNodes[i - 1];
            const node = trailNodes[i];
            const prevPos = getNodePx(prev, width, height);
            const pos = getNodePx(node, width, height);
            const t = i / segCount;
            ctx.strokeStyle = acc;
            ctx.globalAlpha = 0.06 + 0.22 * t;
            ctx.lineWidth = 1 + 1.2 * t;
            ctx.beginPath();
            ctx.moveTo(prevPos.x, prevPos.y);
            if (curvedEdges) {
              const mx = (prevPos.x + pos.x) / 2;
              const my = (prevPos.y + pos.y) / 2;
              const dx = pos.x - prevPos.x;
              const dy = pos.y - prevPos.y;
              const len = Math.sqrt(dx * dx + dy * dy) || 1;
              const offset = len * 0.15;
              const cpx = mx + (-dy / len) * offset;
              const cpy = my + (dx / len) * offset;
              ctx.quadraticCurveTo(cpx, cpy, pos.x, pos.y);
            } else {
              ctx.lineTo(pos.x, pos.y);
            }
            ctx.stroke();
          }
          ctx.globalAlpha = 1;
        }

        GRAPH.nodes.forEach((node) => {
          if (highlightIds && !highlightIds.has(node.id)) return;
          const pos = getNodePx(node, width, height);
          const isVisited = visited.has(node.id);
          const isActive = node.id === activeId;
          const isHovered = node.id === hoveredId;
          const radius = isActive ? 11.5 : isHovered ? 9.5 : 8.5;

          if (activeGlow && isActive) {
            const glowRadius = radius + 3;
            const gradient = ctx.createRadialGradient(pos.x, pos.y, radius * 0.5, pos.x, pos.y, glowRadius);
            gradient.addColorStop(0, "rgba(26,26,24,0.9)");
            gradient.addColorStop(1, "rgba(26,26,24,0)");
            ctx.beginPath();
            ctx.arc(pos.x, pos.y, glowRadius, 0, Math.PI * 2);
            ctx.fillStyle = gradient;
            ctx.fill();
          }

          const nodeAlpha = breatheAlpha != null ? breatheAlpha : 1;

          ctx.beginPath();
          ctx.arc(pos.x, pos.y, radius, 0, Math.PI * 2);
          if (softenUnvisited && !isVisited && !isActive) {
            ctx.globalAlpha = nodeAlpha;
            ctx.fillStyle = paper;
            ctx.strokeStyle = ink3;
            ctx.lineWidth = isHovered ? 1.5 : 0.8;
          } else {
            ctx.globalAlpha = nodeAlpha;
            ctx.fillStyle = isVisited || isActive ? ink : paper;
            ctx.strokeStyle = ink;
            ctx.lineWidth = isHovered ? 2 : 1.3;
          }
          ctx.fill();
          ctx.stroke();
          ctx.globalAlpha = 1;

          if (showLabels) {
            const isRevealed = isVisited || isHovered;
            const labelText = isHovered && node.shortQ ? node.shortQ : node.label;
            const labelFontSize = isHovered ? "11px" : "11px";
            const fontWeight = isHovered ? "600" : "normal";
            ctx.font = `${fontWeight} ${labelFontSize} system-ui, -apple-system, Segoe UI, sans-serif`;
            ctx.fillStyle = isHovered ? ink : isVisited ? ink : ink4;
            ctx.globalAlpha = isHovered ? 1 : isVisited ? 0.85 : 0.4;
            ctx.textBaseline = "middle";
            const alignRight = node.x > 0.68;
            ctx.textAlign = alignRight ? "right" : "left";
            const offset = alignRight ? -14 : 14;
            ctx.fillText(labelText, pos.x + offset, pos.y);
            ctx.globalAlpha = 1;
          }
        });
      };

      const ENTRY_QUESTIONS = {
        "next-word": "What is an LLM actually doing when it \"talks\" to you?",
        "averaging-problem": "If you learn from a million essays, do you write like the best one or the average one?",
        "the-shaping": "What happened between \"raw autocomplete\" and \"helpful assistant\"?",
        "weight-of-words": "How does a model learn from trillions of words?",
        quality: "When we say a model's output is \"good,\" who decides?",
        "understanding-illusion": "Does the model \"understand\" what it's saying?",
        "practical-guide": "So what do I actually do with all this?",
        "tool-user": "What happens when the model can use tools?",
        "algorithm-as-muse": "When AI helps create art, who is the artist?",
        "echoes-of-the-past": "What happens when AI reads history through its own biases?",
        "learning-machines-learning-humans": "What happens to learning when AI has all the answers?",
        "automation-of-cognition": "What happens when machines can do the thinking?",
        "black-box-oracle": "How do you trust a decision you can't explain?",
        "digital-footprints": "What does AI cost the planet?",
        "artificial-brain": "Is an artificial neural network really anything like a brain?",
        "empathy-machine": "Can a machine that simulates empathy actually help \u2014 or harm?",
        "near-zero-cost-impact": "What happens when the cost of producing everything approaches zero?",
      };

      const prefersReducedMotion = () => window.matchMedia("(prefers-reduced-motion: reduce)").matches;

      const buildSimpleConstellation = (currentId, visited, whisperQuestions) => {
        const size = 320;
        const canvas = h("canvas", {
          role: "img",
          "aria-label": "Constellation map of connected plateaus",
        });
        const wrap = h("div", { class: "simple-constellation" }, canvas);

        const connectedIds = new Set();
        GRAPH.edges.forEach(([a, b]) => {
          if (a === currentId) connectedIds.add(b);
          if (b === currentId) connectedIds.add(a);
        });

        const neighbors = GRAPH.nodes.filter((n) => connectedIds.has(n.id));
        const centerNode = getPlateau(currentId);
        if (!centerNode || neighbors.length === 0) return wrap;

        const ratio = scaleCanvas(canvas, size, size);
        const ctx = canvas.getContext("2d");
        if (!ctx) return wrap;
        ctx.setTransform(ratio, 0, 0, ratio, 0, 0);

        const styles = getComputedStyle(document.documentElement);
        const ink = styles.getPropertyValue("--ink").trim();
        const ink2 = styles.getPropertyValue("--ink2").trim();
        const ink3 = styles.getPropertyValue("--ink3").trim();
        const ink4 = styles.getPropertyValue("--ink4").trim();

        const cx = size / 2;
        const cy = size / 2;
        const radius = size * 0.35;

        neighbors.forEach((neighbor, i) => {
          const angle = (i / neighbors.length) * Math.PI * 2 - Math.PI / 2;
          const nx = cx + Math.cos(angle) * radius;
          const ny = cy + Math.sin(angle) * radius;

          ctx.strokeStyle = ink4;
          ctx.lineWidth = 1;
          ctx.globalAlpha = visited.has(neighbor.id) ? 0.3 : 0.1;
          ctx.beginPath();
          ctx.moveTo(cx, cy);
          ctx.lineTo(nx, ny);
          ctx.stroke();
          ctx.globalAlpha = 1;

          const nodeRadius = 5;
          ctx.beginPath();
          ctx.arc(nx, ny, nodeRadius, 0, Math.PI * 2);
          if (visited.has(neighbor.id)) {
            ctx.fillStyle = ink;
            ctx.fill();
          } else {
            ctx.strokeStyle = ink3;
            ctx.lineWidth = 1.5;
            ctx.stroke();
          }

          const whisper = whisperQuestions.find((w) => w.to === neighbor.id);
          const label = whisper ? whisper.text : neighbor.title;
          ctx.font = "italic 10px Lora, Georgia, serif";
          ctx.fillStyle = ink2;
          ctx.textAlign = Math.cos(angle) >= 0 ? "left" : "right";
          ctx.textBaseline = "middle";
          const labelX = nx + (Math.cos(angle) >= 0 ? 10 : -10);
          const labelY = ny;
          const maxW = size * 0.3;
          ctx.fillText(label, labelX, labelY, maxW);
        });

        const centerRadius = 7;
        ctx.beginPath();
        ctx.arc(cx, cy, centerRadius, 0, Math.PI * 2);
        ctx.fillStyle = ink;
        ctx.fill();

        ctx.font = "600 11px Lora, Georgia, serif";
        ctx.fillStyle = ink;
        ctx.textAlign = "center";
        ctx.textBaseline = "top";
        ctx.fillText(centerNode.title, cx, cy + centerRadius + 6);

        return wrap;
      };

      const buildLandingMap = (visitedSet, traversedEdges) => {
        const canvas = h("canvas", {
          role: "img",
          "aria-label": "Navigation map of LLM plateaus",
        });
        const overlay = h("div", { class: "map-overlay" });
        const wrap = h("div", { class: "map-wrap" }, canvas, overlay);
        const linkMap = new Map();
        const hitRadius = 22;
        let lastSize = { width: 0, height: 0 };
        let hoveredId = null;

        GRAPH.nodes.forEach((node) => {
          const fullQ = ENTRY_QUESTIONS[node.id] || node.title;
          const link = h("a", {
            class: "map-link",
            href: `#/${node.id}`,
            title: fullQ,
            "aria-label": `${fullQ} \u2014 ${node.title}, ${visitedSet.has(node.id) ? "visited" : "not visited"}`,
          });
          overlay.appendChild(link);
          linkMap.set(node.id, link);
        });

        const resizeCanvas = () => {
          const rect = wrap.getBoundingClientRect();
          if (!rect.width || !rect.height) return null;
          lastSize = { width: Math.floor(rect.width), height: Math.floor(rect.height) };
          return lastSize;
        };

        const draw = () => {
          if (!resizeCanvas()) return;
          drawGraph({
            canvas,
            width: lastSize.width,
            height: lastSize.height,
            visited: visitedSet,
            showLabels: true,
            hoveredId,
            curvedEdges: true,
            softenUnvisited: true,
            traversedEdges,
          });

          GRAPH.nodes.forEach((node) => {
            const link = linkMap.get(node.id);
            if (!link) return;
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            link.style.left = `${pos.x}px`;
            link.style.top = `${pos.y}px`;
            const fullQ = ENTRY_QUESTIONS[node.id] || node.title;
            link.setAttribute(
              "aria-label",
              `${fullQ} \u2014 ${node.title}, ${visitedSet.has(node.id) ? "visited" : "not visited"}`
            );
          });
        };

        const findHitNode = (event) => {
          const rect = canvas.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          return GRAPH.nodes.find((node) => {
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            return Math.hypot(x - pos.x, y - pos.y) <= hitRadius;
          });
        };

        const handleMouseMove = (event) => {
          const hit = findHitNode(event);
          const newId = hit ? hit.id : null;
          canvas.style.cursor = newId ? "pointer" : "default";
          if (newId !== hoveredId) {
            hoveredId = newId;
            draw();
          }
        };

        const handleMouseLeave = () => {
          if (hoveredId) {
            hoveredId = null;
            draw();
          }
        };

        const handleClick = (event) => {
          const hit = findHitNode(event);
          if (hit) {
            location.hash = `#/${hit.id}`;
          }
        };

        const observer = new ResizeObserver(draw);
        observer.observe(wrap);
        wrap.addEventListener("mousemove", handleMouseMove);
        wrap.addEventListener("mouseleave", handleMouseLeave);
        canvas.addEventListener("click", handleClick);
        draw();

        const cleanup = () => {
          observer.disconnect();
          wrap.removeEventListener("mousemove", handleMouseMove);
          wrap.removeEventListener("mouseleave", handleMouseLeave);
          canvas.removeEventListener("click", handleClick);
        };

        return { wrap, cleanup };
      };

      const buildLandingView = (state) => {
        const visitedSet = new Set(state.v);
        const header = h(
          "div",
          { class: "landing-header" },
          h("h1", null, "How LLMs Actually Work"),
          h("p", { class: "subtitle" }, "Seventeen essays on prediction, memory, and the strange logic of machines."),
          h(
            "p",
            null,
            "This is a network you can enter anywhere.",
            " Follow a node to see how the ideas braid together."
          )
        );

        const { wrap: mapWrap, cleanup } = buildLandingMap(visitedSet, state.te);
        const mapSection = h(
          "div",
          { class: "landing-map" },
          mapWrap,
          h("p", { class: "map-note" }, "Click or tab to any node to begin.")
        );

        const main = h("main", { class: "landing view" }, header, mapSection);
        return { view: main, cleanup };
      };

      const buildMiniMap = (state, currentId) => {
        const container = h("div", { class: "mini-map" });
        const canvas = h("canvas", { "aria-hidden": "true" });
        const button = h("button", {
          class: "mini-map-button",
          type: "button",
          "aria-label": "Open navigation map",
        });
        container.append(canvas, button);

        let visited = new Set(state.v);
        let activeId = currentId || null;
        let highlightIds = new Set();
        let edgeFilter = null;
        let trailNodes = getTrailSegments(state.tr);
        let traversedEdges = state.te || deriveTraversedEdges(state.tr);
        let isVisible = true;
        let rafId = null;
        let breatheStart = null;
        let transitionStart = null;
        let prevHighlightIds = null;
        let prevEdgeFilter = null;
        let prevActiveId = null;

        const computeContext = (id) => {
          const hl = new Set();
          let ef = null;
          if (id) {
            hl.add(id);
            GRAPH.edges.forEach(([fromId, toId]) => {
              if (fromId === id) hl.add(toId);
              if (toId === id) hl.add(fromId);
            });
            ef = (fromId, toId) => fromId === id || toId === id;
          } else {
            GRAPH.nodes.forEach((node) => hl.add(node.id));
          }
          return { hl, ef };
        };

        const ctx = computeContext(currentId);
        highlightIds = ctx.hl;
        edgeFilter = ctx.ef;

        const isMobile = () => window.matchMedia("(max-width: 480px)").matches;

        const render = (alpha) => {
          const rect = container.getBoundingClientRect();
          if (!rect.width || !rect.height) return;
          drawGraph({
            canvas,
            width: rect.width,
            height: rect.height,
            visited,
            activeId,
            highlightIds,
            edgeFilter,
            showLabels: false,
            showTrail: trailNodes.length > 1,
            trailNodes,
            curvedEdges: true,
            softenUnvisited: true,
            activeGlow: !!activeId,
            breatheAlpha: alpha,
            traversedEdges,
          });
        };

        const animate = (timestamp) => {
          if (!isVisible) return;
          if (breatheStart === null) breatheStart = timestamp;
          const elapsed = (timestamp - breatheStart) / 1000;
          const alpha = 1 + 0.08 * Math.sin((2 * Math.PI * elapsed) / 5);

          if (transitionStart !== null) {
            const tElapsed = timestamp - transitionStart;
            const tProgress = Math.min(tElapsed / 300, 1);
            if (tProgress >= 1) {
              transitionStart = null;
              prevHighlightIds = null;
              prevEdgeFilter = null;
              prevActiveId = null;
            }
          }

          render(alpha);
          rafId = requestAnimationFrame(animate);
        };

        const startAnimation = () => {
          if (prefersReducedMotion() || isMobile()) {
            render(1);
            return;
          }
          if (rafId !== null) return;
          breatheStart = null;
          rafId = requestAnimationFrame(animate);
        };

        const stopAnimation = () => {
          if (rafId !== null) {
            cancelAnimationFrame(rafId);
            rafId = null;
          }
        };

        const visObserver = new IntersectionObserver(([entry]) => {
          isVisible = entry.isIntersecting;
          if (isVisible) {
            startAnimation();
          } else {
            stopAnimation();
          }
        });
        visObserver.observe(container);

        const resizeObserver = new ResizeObserver(() => {
          if (prefersReducedMotion() || isMobile()) {
            render(1);
          }
        });
        resizeObserver.observe(container);

        render(1);
        startAnimation();

        const updateContext = (newState, newCurrentId) => {
          const newVisited = new Set(newState.v);
          const newTrail = getTrailSegments(newState.tr);
          const newCtx = computeContext(newCurrentId);

          if (!prefersReducedMotion() && !isMobile() && activeId !== (newCurrentId || null)) {
            prevHighlightIds = highlightIds;
            prevEdgeFilter = edgeFilter;
            prevActiveId = activeId;
            transitionStart = performance.now();
          }

          visited = newVisited;
          activeId = newCurrentId || null;
          highlightIds = newCtx.hl;
          edgeFilter = newCtx.ef;
          trailNodes = newTrail;
          traversedEdges = newState.te || deriveTraversedEdges(newState.tr);

          if (prefersReducedMotion() || isMobile()) {
            render(1);
          }
        };

        return {
          container,
          button,
          updateContext,
          cleanup: () => {
            stopAnimation();
            visObserver.disconnect();
            resizeObserver.disconnect();
          },
        };
      };

      const buildScrolly = ({ steps, whispers, questionCards, scrubUpdate, vizContent, onStepChange, state }) => {
        const hasViz = !!vizContent;
        const section = h("section", { class: hasViz ? "scrolly" : "scrolly scrolly-no-viz" });
        let viz = null;
        let vizMain = null;
        let constellation = null;
        if (hasViz) {
          viz = h("div", { class: "scrolly-viz" });
          vizMain = h("div", { class: "viz-main" });
          vizMain.appendChild(vizContent);
          const whispersLayer = h("div", { class: "whisper-layer" });
          const pips = h("div", { class: "trace-pips" });
          constellation = h("div", { class: "constellation" }, "Constellation");
          viz.append(vizMain, whispersLayer, pips, constellation);
        }

        const stepsWrap = h("div", { class: "scrolly-steps" });
        const stepEls = steps.map((content, index) => {
          const step = h("div", { class: "scrolly-step" });
          if (typeof content === "string") {
            step.appendChild(h("p", null, content));
          } else if (typeof content === "function") {
            content(step);
          }
          if (index === 0) step.classList.add("is-active");
          stepsWrap.appendChild(step);
          return step;
        });

        if (hasViz) {
          const whispersLayer = viz.querySelector(".whisper-layer");
          const pips = viz.querySelector(".trace-pips");
          whispers.forEach((whisper) => {
            const line = h("a", { class: "whisper", href: `#/${whisper.to}` }, whisper.text);
            whispersLayer.appendChild(line);
            const pip = h("span", { class: "trace-pip" });
            pips.appendChild(pip);
          });
        }

        const cards = h("div", { class: "question-cards" });
        questionCards.forEach((card) => {
          const el = h(
            "a",
            { class: "question-card", href: `#/${card.to}` },
            h("span", null, card.question),
            h("strong", null, card.title)
          );
          if (state) el.style.opacity = getFlightOpacity(state, card.to);
          cards.appendChild(el);
        });
        stepsWrap.appendChild(cards);

        if (viz) section.appendChild(viz);
        section.appendChild(stepsWrap);

        let activeStepIndex = 0;
        const onStep = (idx) => {
          activeStepIndex = idx;
          stepEls.forEach((step, index) => {
            step.classList.toggle("is-active", index === idx);
          });
          if (hasViz) {
            const whispersLayer = viz.querySelector(".whisper-layer");
            const pips = viz.querySelector(".trace-pips");
            whispers.forEach((whisper, index) => {
              const line = whispersLayer.children[index];
              const pip = pips.children[index];
              const isVisible = idx >= whisper.step && idx < steps.length - 1;
              line.classList.toggle("is-visible", isVisible);
              pip.classList.toggle("is-lit", idx >= whisper.step);
            });
            const isFinal = idx === steps.length - 1;
            viz.classList.toggle("is-constellation", isFinal);
            constellation.classList.toggle("is-visible", isFinal);
          }
          if (onStepChange) onStepChange(idx);
        };

        const observer = new IntersectionObserver(
          (entries) => {
            entries.forEach((entry) => {
              if (entry.isIntersecting) {
                const index = stepEls.indexOf(entry.target);
                if (index >= 0) onStep(index);
              }
            });
          },
          { threshold: 0.55 }
        );

        stepEls.forEach((step) => observer.observe(step));

        let scrubTicking = false;
        let scrubCleanup = null;
        if (scrubUpdate) {
          const onScroll = () => {
            if (scrubTicking) return;
            scrubTicking = true;
            requestAnimationFrame(() => {
              const activeStep = stepEls[activeStepIndex];
              if (activeStep) {
                const rect = activeStep.getBoundingClientRect();
                const viewH = window.innerHeight;
                const progress = Math.max(0, Math.min(1, 1 - (rect.bottom / (rect.height + viewH))));
                scrubUpdate(activeStepIndex, progress, vizMain);
              }
              scrubTicking = false;
            });
          };
          window.addEventListener("scroll", onScroll, { passive: true });
          scrubCleanup = () => window.removeEventListener("scroll", onScroll);
        }

        const cleanup = () => {
          observer.disconnect();
          if (scrubCleanup) scrubCleanup();
        };

        return { section, vizMain, cleanup };
      };

      const buildInlineSeed = ({ id, label, detail, type, danglingTo, danglingText, state, plateauId, onOpen }) => {
        const attrs = {
          class: "inline-seed-button",
          type: "button",
          "aria-expanded": "false",
        };
        if (type) attrs["data-seed-type"] = type;
        const button = h("button", attrs, label);

        const contentChildren = typeof detail === "function" ? detail(state) : detail;
        const contentEl = h("div", { class: "inline-seed-popover-content" });
        if (typeof contentChildren === "string") {
          contentEl.appendChild(document.createTextNode(contentChildren));
        } else if (contentChildren instanceof Node) {
          contentEl.appendChild(contentChildren);
        } else if (Array.isArray(contentChildren)) {
          contentChildren.forEach((c) => {
            if (typeof c === "string") contentEl.appendChild(document.createTextNode(c));
            else if (c instanceof Node) contentEl.appendChild(c);
          });
        }

        if (type === "dangling" && danglingTo && danglingText) {
          contentEl.appendChild(document.createTextNode(" "));
          contentEl.appendChild(
            h("a", { class: "dangling-link", href: `#/${danglingTo}` }, danglingText)
          );
        }

        const popover = h(
          "div",
          { class: "inline-seed-popover", "aria-hidden": "true" },
          contentEl
        );
        const wrapper = h("span", { class: "inline-seed" }, button);
        document.body.appendChild(popover);

        const positionPopover = () => {
          const rect = button.getBoundingClientRect();
          const popW = 360;
          const popH = popover.offsetHeight || 200;
          let top = rect.bottom + 6;
          let left = rect.left + rect.width / 2 - popW / 2;
          if (left < 8) left = 8;
          if (left + popW > window.innerWidth - 8) left = window.innerWidth - popW - 8;
          if (top + popH > window.innerHeight - 8) {
            top = rect.top - popH - 6;
          }
          popover.style.top = `${top}px`;
          popover.style.left = `${left}px`;
        };

        const closePopover = () => {
          button.setAttribute("aria-expanded", "false");
          popover.classList.remove("is-open");
          popover.setAttribute("aria-hidden", "true");
          document.removeEventListener("click", outsideClick, true);
          document.removeEventListener("keydown", escClose);
        };

        const outsideClick = (e) => {
          if (!popover.contains(e.target) && e.target !== button) {
            closePopover();
          }
        };

        const escClose = (e) => {
          if (e.key === "Escape") closePopover();
        };

        button.addEventListener("click", () => {
          const isOpen = button.getAttribute("aria-expanded") === "true";
          if (isOpen) {
            closePopover();
          } else {
            document.querySelectorAll(".inline-seed-popover.is-open").forEach((p) => {
              p.classList.remove("is-open");
              p.setAttribute("aria-hidden", "true");
            });
            document.querySelectorAll('.inline-seed-button[aria-expanded="true"]').forEach((b) => {
              b.setAttribute("aria-expanded", "false");
            });
            positionPopover();
            button.setAttribute("aria-expanded", "true");
            popover.classList.add("is-open");
            popover.setAttribute("aria-hidden", "false");
            requestAnimationFrame(() => {
              document.addEventListener("click", outsideClick, true);
              document.addEventListener("keydown", escClose);
            });
            if (onOpen && id) onOpen(id);
          }
        });

        return wrapper;
      };

      const buildOverlay = (state) => {
        const overlay = h("div", {
          class: "rhizome-overlay",
          role: "dialog",
          "aria-modal": "true",
          "aria-hidden": "true",
        });
        const backdrop = h("div", { class: "overlay-backdrop" });
        const panel = h("div", { class: "overlay-panel" });
        const closeButton = h("button", {
          class: "overlay-close",
          type: "button",
          "aria-label": "Close navigation map",
        }, "Close");
        const mapWrap = h("div", { class: "overlay-map" });
        const canvas = h("canvas", {
          role: "img",
          "aria-label": "Full navigation map of all plateaus",
        });
        const linkLayer = h("div", { class: "overlay-links" });

        mapWrap.append(canvas, linkLayer);
        panel.append(closeButton, mapWrap);
        overlay.append(backdrop, panel);

        let visited = new Set(state.v);
        let trailNodes = getTrailSegments(state.tr);
        let traversedEdges = state.te || deriveTraversedEdges(state.tr);
        const linkMap = new Map();
        const hitRadius = 22;
        let lastSize = { width: 0, height: 0 };
        let hoveredId = null;

        GRAPH.nodes.forEach((node) => {
          const link = h("a", {
            class: "overlay-link",
            href: `#/${node.id}`,
            role: "link",
          });
          linkLayer.appendChild(link);
          linkMap.set(node.id, link);
        });

        const redraw = () => {
          if (!lastSize.width || !lastSize.height) return;
          drawGraph({
            canvas,
            width: lastSize.width,
            height: lastSize.height,
            visited,
            showLabels: true,
            showTrail: true,
            trailNodes,
            hoveredId,
            curvedEdges: true,
            traversedEdges,
          });
        };

        const resize = () => {
          const rect = mapWrap.getBoundingClientRect();
          if (!rect.width || !rect.height) return;
          lastSize = { width: rect.width, height: rect.height };
          redraw();
          GRAPH.nodes.forEach((node) => {
            const link = linkMap.get(node.id);
            if (!link) return;
            const pos = getNodePx(node, rect.width, rect.height);
            link.style.left = `${pos.x}px`;
            link.style.top = `${pos.y}px`;
            link.setAttribute(
              "aria-label",
              `${node.title}, ${visited.has(node.id) ? "visited" : "not visited"}`
            );
          });
        };

        const handleMouseMove = (event) => {
          const rect = mapWrap.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          const hit = GRAPH.nodes.find((node) => {
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            return Math.hypot(x - pos.x, y - pos.y) <= hitRadius;
          });
          const newId = hit ? hit.id : null;
          canvas.style.cursor = newId ? "pointer" : "default";
          if (newId !== hoveredId) {
            hoveredId = newId;
            redraw();
          }
        };

        const handleMouseLeave = () => {
          if (hoveredId) {
            hoveredId = null;
            redraw();
          }
        };

        const handleClick = (event) => {
          const rect = canvas.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          const hit = GRAPH.nodes.find((node) => {
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            const dx = x - pos.x;
            const dy = y - pos.y;
            return Math.hypot(dx, dy) <= hitRadius;
          });
          if (hit) {
            location.hash = `#/${hit.id}`;
          }
        };

        const observer = new ResizeObserver(resize);
        observer.observe(mapWrap);
        mapWrap.addEventListener("mousemove", handleMouseMove);
        mapWrap.addEventListener("mouseleave", handleMouseLeave);
        canvas.addEventListener("click", handleClick);
        resize();

        const focusables = Array.from(linkLayer.querySelectorAll("a")).concat([closeButton]);

        const updateState = (newState) => {
          visited = new Set(newState.v);
          trailNodes = getTrailSegments(newState.tr);
          traversedEdges = newState.te || deriveTraversedEdges(newState.tr);
          resize();
        };

        return {
          overlay,
          backdrop,
          closeButton,
          focusables,
          updateState,
          cleanup: () => {
            observer.disconnect();
            mapWrap.removeEventListener("mousemove", handleMouseMove);
            mapWrap.removeEventListener("mouseleave", handleMouseLeave);
            canvas.removeEventListener("click", handleClick);
          },
        };
      };

      const getFocusable = (container) =>
        Array.from(container.querySelectorAll("button, [href], [tabindex]:not([tabindex='-1'])"));

      const trapFocus = (container, event) => {
        if (event.key !== "Tab") return;
        const focusable = getFocusable(container);
        if (!focusable.length) return;
        const first = focusable[0];
        const last = focusable[focusable.length - 1];
        if (event.shiftKey && document.activeElement === first) {
          event.preventDefault();
          last.focus();
        } else if (!event.shiftKey && document.activeElement === last) {
          event.preventDefault();
          first.focus();
        }
      };

      const buildSeedCluster = (seeds, { state, plateauId, onSeedOpen } = {}) => {
        const field = h("div", { class: "seed-field" });
        seeds.forEach((seed) => {
          const detailContent = typeof seed.detail === "function" ? seed.detail(state) : seed.detail;
          const inner = h("div", { class: "seed-growth-inner" });
          if (typeof detailContent === "string") {
            inner.appendChild(document.createTextNode(detailContent));
          } else if (detailContent instanceof Node) {
            inner.appendChild(detailContent);
          }

          if (seed.type === "dangling" && seed.danglingTo && seed.danglingText) {
            inner.appendChild(document.createTextNode(" "));
            inner.appendChild(
              h("a", { class: "dangling-link", href: `#/${seed.danglingTo}` }, seed.danglingText)
            );
          }

          const growth = h(
            "div",
            { class: "seed-growth", "aria-hidden": "true" },
            inner
          );
          const btnAttrs = {
            class: "seed-button",
            type: "button",
            "aria-expanded": "false",
          };
          if (seed.type) btnAttrs["data-seed-type"] = seed.type;
          const button = h("button", btnAttrs, seed.label);
          const item = h("div", { class: "seed-item" }, button, growth);

          button.addEventListener("click", () => {
            const isOpen = button.getAttribute("aria-expanded") === "true";
            button.setAttribute("aria-expanded", String(!isOpen));
            growth.classList.toggle("is-open", !isOpen);
            growth.setAttribute("aria-hidden", String(isOpen));
            if (!isOpen && onSeedOpen && seed.id) onSeedOpen(seed.id);
          });

          field.appendChild(item);
        });
        return field;
      };

      const buildScatterToText = () => {
        const words = ["syntax", "semantics", "reasoning", "facts", "grammar", "analogy", "context", "prediction", "structure", "meaning", "inference", "pattern"];
        const container = h("div", { class: "scatter-container" });
        const wordEls = [];

        const hash = (str) => {
          let h = 0;
          for (let i = 0; i < str.length; i++) h = ((h << 5) - h + str.charCodeAt(i)) | 0;
          return h;
        };

        const cols = 4;
        const rows = Math.ceil(words.length / cols);
        words.forEach((word, i) => {
          const seed = hash(word);
          const initX = ((seed & 0xff) / 255) * 80 + 5;
          const initY = (((seed >> 8) & 0xff) / 255) * 80 + 5;
          const finalCol = i % cols;
          const finalRow = Math.floor(i / cols);
          const finalX = 10 + (finalCol / (cols - 1)) * 80;
          const finalY = 20 + (finalRow / (rows - 1)) * 60;

          const el = h("span", { class: "scatter-word" }, word);
          el.style.left = `${finalX}%`;
          el.style.top = `${finalY}%`;
          el.dataset.initX = initX;
          el.dataset.initY = initY;
          el.dataset.finalX = finalX;
          el.dataset.finalY = finalY;

          if (!prefersReducedMotion()) {
            el.style.transform = `translate(${initX - finalX}vw, ${initY - finalY}vh)`;
          }
          container.appendChild(el);
          wordEls.push(el);
        });

        const update = (progress) => {
          if (prefersReducedMotion()) return;
          wordEls.forEach((el) => {
            const ix = parseFloat(el.dataset.initX);
            const iy = parseFloat(el.dataset.initY);
            const fx = parseFloat(el.dataset.finalX);
            const fy = parseFloat(el.dataset.finalY);
            const dx = (ix - fx) * (1 - progress);
            const dy = (iy - fy) * (1 - progress);
            el.style.transform = `translate(${dx}vw, ${dy}vh)`;
          });
        };

        return { container, update };
      };

      const setupDwellReveal = (container, annotations) => {
        const timers = new Map();
        const revealed = new Set();
        const DWELL_MS = 3000;

        const targets = container.querySelectorAll(".dwell-target");
        targets.forEach((target) => {
          const paraId = target.dataset.dwellId;
          if (!paraId || !annotations[paraId]) return;

          const annotation = h("div", {
            class: "dwell-annotation",
            "aria-live": "polite",
          }, annotations[paraId]);
          target.appendChild(annotation);

          let timer = null;
          const resetTimer = () => {
            if (timer) clearTimeout(timer);
            if (revealed.has(paraId)) return;
            timer = setTimeout(() => {
              annotation.classList.add("is-revealed");
              revealed.add(paraId);
            }, DWELL_MS);
            timers.set(paraId, timer);
          };

          const clearTimer = () => {
            if (timer) clearTimeout(timer);
            timer = null;
          };

          target.addEventListener("mousemove", resetTimer);
          target.addEventListener("mouseleave", clearTimer);
        });

        return () => {
          timers.forEach((t) => clearTimeout(t));
          timers.clear();
        };
      };

      const buildCYOAFork = ({ prompt, options }) => {
        const group = h("div", {
          class: "cyoa-fork",
          role: "group",
          "aria-label": prompt,
        });
        const label = h("p", { style: { color: "var(--ink2)", fontStyle: "italic", fontSize: "0.92rem" } }, prompt);
        group.appendChild(label);
        let chosen = null;

        options.forEach((opt) => {
          const expansion = h("div", { class: "cyoa-expansion" },
            h("div", { class: "cyoa-expansion-inner" }, opt.content)
          );
          const btn = h("button", {
            class: "cyoa-option",
            type: "button",
          }, opt.label);

          btn.addEventListener("click", () => {
            if (!chosen) {
              chosen = opt.label;
              group.querySelectorAll(".cyoa-option").forEach((b) => {
                if (b === btn) {
                  b.classList.add("is-chosen");
                  b.classList.remove("is-unchosen");
                } else {
                  b.classList.add("is-unchosen");
                  b.classList.remove("is-chosen");
                }
              });
            }
            expansion.classList.toggle("is-open");
          });

          group.appendChild(btn);
          group.appendChild(expansion);
        });

        return group;
      };

      const RETRIEVAL_QUESTIONS = {
        "next-word": (visited) => {
          if (visited.has("weight-of-words")) return "Earlier, you explored how trillions of words become structure. What gets lost when all that structure collapses into a single next token?";
          if (visited.has("the-shaping")) return "You saw how RLHF reshapes behavior. How does that shaping interact with the raw prediction you're reading about now?";
          if (visited.has("averaging-problem")) return "You explored the averaging problem. How does that average show up in what the model predicts next?";
          return null;
        },
        "weight-of-words": (visited) => {
          if (visited.has("next-word")) return "You saw how models predict the next token. What kind of structure would you need to learn before that prediction works?";
          if (visited.has("the-shaping")) return "You explored how models get shaped after training. What does the model need to learn first, before any shaping begins?";
          return null;
        },
        "the-shaping": (visited) => {
          if (visited.has("weight-of-words")) return "You saw how structure emerges from raw data. What happens when humans start redirecting those learned patterns?";
          if (visited.has("quality")) return "You thought about who defines quality. Now ask: how do those definitions get baked into the model's behavior?";
          return null;
        },
        quality: (visited) => {
          if (visited.has("the-shaping")) return "You followed the shaping process. Now step back: who chose the direction of that shaping, and by what standard?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. Does that change how you think about rating their outputs?";
          return null;
        },
        "understanding-illusion": (visited) => {
          if (visited.has("next-word")) return "You saw the prediction mechanism. Does knowing how it works change whether you'd call it understanding?";
          if (visited.has("weight-of-words")) return "You explored the internal structure that emerges from training. Does having structure mean having understanding?";
          return null;
        },
        "averaging-problem": (visited) => {
          if (visited.has("next-word")) return "You watched a model predict the next word. What happens when that prediction is averaged across a million different writing styles?";
          if (visited.has("quality")) return "You considered what quality means. How does the averaging problem complicate the idea of a 'good' output?";
          return null;
        },
        "practical-guide": (visited) => {
          if (visited.has("understanding-illusion")) return "You questioned whether models truly understand. How does that uncertainty change how you should use them?";
          if (visited.has("the-shaping")) return "You saw how models get shaped. How does knowing that inform the way you write prompts?";
          return null;
        },
        "tool-user": (visited) => {
          if (visited.has("practical-guide")) return "You learned techniques for working with models. What changes when the model can also work with tools?";
          if (visited.has("next-word")) return "You saw how models predict tokens. What happens when one of those tokens is a function call?";
          return null;
        },
        "near-zero-cost-impact": (visited) => {
          if (visited.has("averaging-problem")) return "You explored what happens when a model averages everything. What happens when that average is reproduced at near-zero cost, billions of times over?";
          if (visited.has("quality")) return "You asked who defines quality. When production cost is zero and volume is infinite, does quality still matter\u2014or does it drown?";
          if (visited.has("digital-footprints")) return "You considered the environmental cost of AI. What's the full ledger when production itself is nearly free but the infrastructure isn't?";
          return null;
        },
        "algorithm-as-muse": (visited) => {
          if (visited.has("averaging-problem")) return "You saw how models average everything they've read. What does that average look like when it tries to create art?";
          if (visited.has("the-shaping")) return "You explored how models are shaped by human feedback. Who's shaping the muse\u2014and whose taste does it reflect?";
          return null;
        },
        "echoes-of-the-past": (visited) => {
          if (visited.has("quality")) return "You thought about who decides what's 'good.' The same question haunts history: whose version of the past does the model learn?";
          if (visited.has("weight-of-words")) return "You saw how models learn from trillions of words. What happens when those words carry centuries of bias?";
          return null;
        },
        "learning-machines-learning-humans": (visited) => {
          if (visited.has("next-word")) return "You watched a model predict the next word. What happens when a student starts relying on that prediction instead of thinking?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. Does that uncertainty change how you'd trust one as a teacher?";
          return null;
        },
        "automation-of-cognition": (visited) => {
          if (visited.has("the-shaping")) return "You saw how models are shaped for usefulness. What happens when that usefulness displaces the workers it was shaped to help?";
          if (visited.has("tool-user")) return "You explored what happens when models use tools. What happens when those tools replace the people who used to wield them?";
          return null;
        },
        "black-box-oracle": (visited) => {
          if (visited.has("the-shaping")) return "You saw how human feedback shapes model behavior. But who audits the shaping when the model makes life-altering decisions?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. How do you hold accountable a system you can't explain and that may not understand itself?";
          return null;
        },
        "digital-footprints": (visited) => {
          if (visited.has("near-zero-cost-impact")) return "You saw what happens when production cost approaches zero. But the energy cost doesn't\u2014every query has a carbon shadow.";
          if (visited.has("weight-of-words")) return "You explored how models learn from trillions of words. What's the environmental cost of processing that much language?";
          return null;
        },
        "artificial-brain": (visited) => {
          if (visited.has("next-word")) return "You watched a model predict tokens. The brain predicts too\u2014but with 86 billion neurons running on 20 watts. What's different?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. If understanding requires a body, what does that mean for a machine?";
          return null;
        },
        "empathy-machine": (visited) => {
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. If they don't, can they truly empathize\u2014or only simulate empathy?";
          if (visited.has("next-word")) return "You saw how models predict the next word. When the next word is 'I understand how you feel,' is that prediction or connection?";
          return null;
        },
      };

      const buildRetrievalMoment = (state, plateauId) => {
        if (state.v.length < 3) return null;
        const visited = new Set(state.v);
        const getter = RETRIEVAL_QUESTIONS[plateauId];
        if (!getter) return null;
        const question = getter(visited);
        if (!question) return null;

        const closeBtn = h("button", {
          class: "retrieval-close",
          type: "button",
          "aria-label": "Dismiss retrieval moment",
        }, "\u00d7");
        const card = h("div", {
          class: "retrieval-moment",
          role: "note",
          "aria-label": "Retrieval moment",
        },
          h("p", { style: { margin: "0", flex: "1" } }, question),
          closeBtn
        );
        closeBtn.addEventListener("click", () => {
          card.classList.add("is-dismissed");
        });
        return card;
      };

      const buildEngagementState = (state, plateauId) => {
        const eg = state.eg[plateauId] || { opened: 0, total: 0 };
        const el = h("div", {
          class: "engagement-state",
          "aria-live": "polite",
        }, `${eg.opened} of ${eg.total} seeds opened`);
        return el;
      };

      const MARGINALIA = {
        "weight-of-words": [
          { forParagraph: 0, text: "The loop never actually converges. It just gets close enough." },
          { forParagraph: 2, text: "Chinchilla showed: more data per parameter beats more parameters per data.", condition: (v) => v.has("averaging-problem") },
        ],
        quality: [
          { forParagraph: 0, text: "The raters are never told they're defining the soul of the model." },
          { forParagraph: 2, text: "If you came here from The Shaping, notice how RLHF doesn't change what the model knows\u2014it changes which knowledge surfaces.", condition: (v) => v.has("the-shaping") },
        ],
        "understanding-illusion": [
          { forParagraph: 0, text: "The question itself might be wrong. But it's the question everyone asks." },
          { forParagraph: 1, text: "Searle's argument assumed computation and understanding are separate categories. What if they're not?", condition: (v) => v.has("weight-of-words") },
        ],
        "practical-guide": [
          { forParagraph: 0, text: "Everything in this plateau is a heuristic. The model doesn't know about any of it." },
          { forParagraph: 1, text: "Chain-of-thought works because the model can attend to its own reasoning tokens.", condition: (v) => v.has("next-word") },
        ],
        "tool-user": [
          { forParagraph: 0, text: "The shift from oracle to agent happened faster than anyone predicted." },
          { forParagraph: 2, text: "When the model writes code that writes code, the oracle metaphor breaks completely.", condition: (v) => v.has("practical-guide") },
        ],
        "near-zero-cost-impact": [
          { forParagraph: 0, text: "The marginal cost of the next copy is zero. The marginal cost of trust is not." },
          { forParagraph: 2, text: "Every previous revolution had friction that slowed adoption. AI's friction is approaching zero too.", condition: (v) => v.has("the-shaping") },
        ],
      };

      const buildVizNextWord = (state) => {
        const sentence = ["The", "model", "looks", "at", "everything", "before", "and", "predicts", "the", "next"];
        const candidates = [
          { token: "word", prob: 0.41 },
          { token: "token", prob: 0.28 },
          { token: "step", prob: 0.14 },
          { token: "thing", prob: 0.09 },
          { token: "move", prob: 0.05 },
          { token: "one", prob: 0.03 },
        ];
        const reduced = prefersReducedMotion;

        let currentState = 1;
        let temperature = 1.0;
        let cursorPos = 0;

        const applyTemperature = (probs, temp) => {
          if (temp <= 0.01) {
            return probs.map((p, i) => i === 0 ? 1 : 0);
          }
          const logits = probs.map((p) => Math.log(Math.max(p, 1e-9)) / temp);
          const maxLogit = Math.max(...logits);
          const exps = logits.map((l) => Math.exp(l - maxLogit));
          const sum = exps.reduce((a, b) => a + b, 0);
          return exps.map((e) => e / sum);
        };

        const element = h("div", { class: "viz-next-word", style: {
          width: "100%", position: "relative", textTransform: "none", letterSpacing: "normal",
        } });

        const sentenceEl = h("div", { class: "viz-nw-sentence", style: {
          fontFamily: "'Lora', Georgia, serif", fontSize: "1.1rem", lineHeight: "1.6",
          padding: "20px 20px 12px", minHeight: "3.2em", color: "var(--ink)",
        } });

        const canvas = h("canvas", { role: "img", "aria-label": "Probability bars for candidate next tokens" });
        const canvasWrap = h("div", { style: {
          width: "100%", height: "160px", padding: "0 20px 8px", display: "none",
        } });
        canvasWrap.appendChild(canvas);

        const tempLabel = h("label", { for: "viz-nw-temp", style: {
          fontSize: "0.8rem", color: "var(--ink2)", letterSpacing: "0.04em",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
        } }, "Temperature");
        const tempValue = h("span", { "aria-hidden": "true", style: {
          fontSize: "0.8rem", color: "var(--ink2)", marginLeft: "auto",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
        } }, "1.0");
        const tempSlider = h("input", {
          type: "range", id: "viz-nw-temp", class: "viz-slider",
          min: "0.1", max: "2.0", step: "0.1", value: "1.0",
          "aria-label": "Temperature: controls creativity of word choice",
          "aria-valuemin": "0.1", "aria-valuemax": "2.0", "aria-valuenow": "1.0",
        });
        const controls = h("div", { class: "viz-controls", style: { display: "none" } },
          tempLabel, tempValue, tempSlider
        );

        const srStatus = h("div", {
          class: "viz-sr-status", role: "status", "aria-live": "polite", "aria-atomic": "true",
        });

        element.append(sentenceEl, canvasWrap, controls, srStatus);

        const renderSentence = () => {
          sentenceEl.textContent = "";
          const wordsToShow = Math.min(cursorPos, sentence.length);
          const text = sentence.slice(0, wordsToShow).join(" ");
          sentenceEl.appendChild(document.createTextNode(text ? text + " " : ""));
          const cursor = h("span", { style: {
            display: "inline-block", width: "2px", height: "1.1em",
            background: "var(--acc)", verticalAlign: "text-bottom",
            animation: reduced() ? "none" : "viz-nw-blink 1s step-end infinite",
          } });
          sentenceEl.appendChild(cursor);
        };

        const drawBars = () => {
          const rect = canvasWrap.getBoundingClientRect();
          const w = rect.width - 40;
          const barH = 160;
          if (w <= 0) return;
          const ratio = scaleCanvas(canvas, w, barH);
          const ctx = canvas.getContext("2d");
          if (!ctx) return;
          ctx.setTransform(ratio, 0, 0, ratio, 0, 0);
          ctx.clearRect(0, 0, w, barH);

          const styles = getComputedStyle(document.documentElement);
          const ink = styles.getPropertyValue("--ink").trim();
          const ink2 = styles.getPropertyValue("--ink2").trim();
          const ink4 = styles.getPropertyValue("--ink4").trim();
          const acc = styles.getPropertyValue("--acc").trim();

          const probs = applyTemperature(candidates.map((c) => c.prob), temperature);
          const maxProb = Math.max(...probs);
          const rowH = barH / candidates.length;
          const labelW = 52;
          const barMaxW = w - labelW - 56;

          candidates.forEach((c, i) => {
            const y = i * rowH;
            const prob = probs[i];
            const barW = (prob / maxProb) * barMaxW;

            ctx.fillStyle = ink2;
            ctx.font = "12px system-ui, -apple-system, 'Segoe UI', sans-serif";
            ctx.textBaseline = "middle";
            ctx.textAlign = "left";
            ctx.fillText(c.token, 0, y + rowH / 2);

            ctx.fillStyle = i === 0 ? acc : ink4;
            ctx.globalAlpha = 0.7 + prob * 0.3;
            const barRadius = 3;
            const barX = labelW;
            const barY = y + rowH / 2 - 8;
            ctx.beginPath();
            ctx.roundRect(barX, barY, Math.max(barW, 2), 16, barRadius);
            ctx.fill();
            ctx.globalAlpha = 1;

            ctx.fillStyle = ink2;
            ctx.textAlign = "left";
            ctx.fillText((prob * 100).toFixed(1) + "%", labelW + barW + 8, y + rowH / 2);
          });
        };

        const updateState = () => {
          if (currentState === 1) {
            canvasWrap.style.display = "none";
            controls.style.display = "none";
            renderSentence();
            srStatus.textContent = `Typing: "${sentence.slice(0, Math.min(cursorPos, sentence.length)).join(" ")}"`;
          } else if (currentState === 2) {
            cursorPos = sentence.length;
            renderSentence();
            canvasWrap.style.display = "block";
            controls.style.display = "none";
            drawBars();
            const desc = candidates.map((c) => `${c.token}: ${(c.prob * 100).toFixed(0)}%`).join(", ");
            srStatus.textContent = `Next token candidates: ${desc}`;
          } else if (currentState === 3) {
            cursorPos = sentence.length;
            renderSentence();
            canvasWrap.style.display = "block";
            controls.style.display = "flex";
            drawBars();
            const probs = applyTemperature(candidates.map((c) => c.prob), temperature);
            const desc = candidates.map((c, i) => `${c.token}: ${(probs[i] * 100).toFixed(0)}%`).join(", ");
            srStatus.textContent = `Temperature ${temperature.toFixed(1)}. Distribution: ${desc}`;
          }
        };

        tempSlider.addEventListener("input", () => {
          temperature = parseFloat(tempSlider.value);
          tempValue.textContent = temperature.toFixed(1);
          tempSlider.setAttribute("aria-valuenow", temperature.toFixed(1));
          drawBars();
          const probs = applyTemperature(candidates.map((c) => c.prob), temperature);
          const desc = candidates.map((c, i) => `${c.token}: ${(probs[i] * 100).toFixed(0)}%`).join(", ");
          srStatus.textContent = `Temperature ${temperature.toFixed(1)}. Distribution: ${desc}`;
        });

        const onStep = (idx) => {
          const totalSteps = 5;
          if (idx >= totalSteps - 1) {
            currentState = 0;
            canvasWrap.style.display = "none";
            controls.style.display = "none";
            return;
          }
          if (idx <= 1) currentState = 1;
          else if (idx === 2) currentState = 2;
          else currentState = 3;
          updateState();
        };

        const scrubUpdate = (stepIdx, progress) => {
          if (currentState === 1) {
            const totalWords = sentence.length;
            const globalProgress = (stepIdx + progress) / 2;
            cursorPos = Math.floor(globalProgress * (totalWords + 1));
            renderSentence();
          }
        };

        updateState();

        return {
          element,
          onStep,
          scrubUpdate,
          cleanup: () => {},
        };
      };

      const buildVizAveragingProblem = (state) => {
        const regions = [
          { id: "academic", label: "Academic", peak: 0.2, color: "var(--ink2)",
            sample: "The implications of token-level probability distributions suggest that model outputs converge toward the statistical mean of the training corpus, yielding prose that, while competent, lacks distinctive authorial voice." },
          { id: "casual", label: "Casual", peak: 0.45, color: "var(--ink3)",
            sample: "So basically the model just mashes everything together and you get this kinda generic-sounding text that's fine but not really special, you know?" },
          { id: "poetic", label: "Poetic", peak: 0.7, color: "var(--acc)",
            sample: "From a million whispered sentences, a voice emergesneither yours nor mine, but something that learned to echo the shape of every word it ever touched." },
          { id: "technical", label: "Technical", peak: 0.9, color: "var(--seed)",
            sample: "The softmax layer maps logit vectors to a probability simplex, where each token's likelihood reflects the model's learned conditional distribution P(token|context)." },
        ];
        const reduced = prefersReducedMotion;

        let currentState = 1;
        let activeRegion = null;
        let specificity = 0.0;

        const element = h("div", { class: "viz-averaging", style: {
          width: "100%", position: "relative", textTransform: "none", letterSpacing: "normal",
        } });

        const canvas = h("canvas", { role: "img", "aria-label": "Distribution landscape showing training data style regions" });
        const canvasWrap = h("div", { style: {
          width: "100%", height: "200px", padding: "0 20px 8px", position: "relative",
        } });
        canvasWrap.appendChild(canvas);

        const regionButtons = h("div", { class: "viz-controls", style: { display: "none" } });
        regions.forEach((r) => {
          const btn = h("button", {
            class: "viz-toggle", "data-region": r.id,
            "aria-label": `Sample from ${r.label} region`,
          }, r.label);
          btn.addEventListener("click", () => {
            activeRegion = activeRegion === r.id ? null : r.id;
            updateState();
          });
          regionButtons.appendChild(btn);
        });

        const sampleBox = h("div", { style: {
          padding: "12px 20px", fontFamily: "'Lora', Georgia, serif", fontSize: "0.95rem",
          lineHeight: "1.6", color: "var(--ink)", minHeight: "3em", display: "none",
        } });

        const specLabel = h("label", { for: "viz-ap-spec", style: {
          fontSize: "0.8rem", color: "var(--ink2)", letterSpacing: "0.04em",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
        } }, "Prompt Specificity");
        const specValue = h("span", { "aria-hidden": "true", style: {
          fontSize: "0.8rem", color: "var(--ink2)", marginLeft: "auto",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
        } }, "0%");
        const specSlider = h("input", {
          type: "range", id: "viz-ap-spec", class: "viz-slider",
          min: "0", max: "100", step: "1", value: "0",
          "aria-label": "Prompt specificity: narrows the distribution from average to high-quality",
          "aria-valuemin": "0", "aria-valuemax": "100", "aria-valuenow": "0",
        });
        const specControls = h("div", { class: "viz-controls", style: { display: "none" } },
          specLabel, specValue, specSlider
        );

        const specSampleBox = h("div", { style: {
          padding: "12px 20px", fontFamily: "'Lora', Georgia, serif", fontSize: "0.95rem",
          lineHeight: "1.6", color: "var(--ink)", minHeight: "3em", display: "none",
        } });

        const srStatus = h("div", {
          class: "viz-sr-status", role: "status", "aria-live": "polite", "aria-atomic": "true",
        });

        element.append(canvasWrap, regionButtons, sampleBox, specControls, specSampleBox, srStatus);

        const gaussian = (x, mean, sigma) => Math.exp(-0.5 * ((x - mean) / sigma) ** 2);

        const drawLandscape = () => {
          const rect = canvasWrap.getBoundingClientRect();
          const w = rect.width - 40;
          const lH = 200;
          if (w <= 0) return;
          const ratio = scaleCanvas(canvas, w, lH);
          const ctx = canvas.getContext("2d");
          if (!ctx) return;
          ctx.setTransform(ratio, 0, 0, ratio, 0, 0);
          ctx.clearRect(0, 0, w, lH);

          const styles = getComputedStyle(document.documentElement);
          const ink = styles.getPropertyValue("--ink").trim();
          const ink2 = styles.getPropertyValue("--ink2").trim();
          const ink3 = styles.getPropertyValue("--ink3").trim();
          const ink4 = styles.getPropertyValue("--ink4").trim();
          const acc = styles.getPropertyValue("--acc").trim();
          const seed = styles.getPropertyValue("--seed").trim();
          const regionColors = [ink2, ink3, acc, seed];

          const baseLine = lH - 30;
          const peakH = baseLine - 20;
          const sigma = currentState === 3 ? 0.04 + (1 - specificity / 100) * 0.08 : 0.08;

          // Draw combined distribution curve
          ctx.beginPath();
          ctx.moveTo(0, baseLine);
          for (let px = 0; px <= w; px++) {
            const x = px / w;
            let y = 0;
            regions.forEach((r) => {
              const weight = currentState === 3 ? (r.id === "poetic" ? 0.8 + specificity / 100 * 0.2 : 1 - specificity / 100 * 0.7) : 1;
              y += gaussian(x, r.peak, sigma) * weight;
            });
            const maxY = currentState === 3 ? 1 + specificity / 100 * 1.5 : regions.length;
            ctx.lineTo(px, baseLine - (y / maxY) * peakH);
          }
          ctx.lineTo(w, baseLine);
          ctx.closePath();
          ctx.fillStyle = ink4;
          ctx.globalAlpha = 0.3;
          ctx.fill();
          ctx.globalAlpha = 1;
          ctx.strokeStyle = ink2;
          ctx.lineWidth = 1.5;
          ctx.stroke();

          // Draw region peaks
          regions.forEach((r, i) => {
            const px = r.peak * w;
            const peakVal = gaussian(r.peak, r.peak, sigma);
            const normalizedY = currentState === 3
              ? (r.id === "poetic" ? (0.8 + specificity / 100 * 0.2) : (1 - specificity / 100 * 0.7)) * peakVal
              : peakVal;
            const maxY = currentState === 3 ? 1 + specificity / 100 * 1.5 : regions.length;
            const tipY = baseLine - (normalizedY / maxY) * peakH;

            if (currentState >= 2) {
              ctx.fillStyle = regionColors[i];
              ctx.globalAlpha = activeRegion === r.id ? 0.9 : 0.5;
              ctx.beginPath();
              ctx.arc(px, tipY, activeRegion === r.id ? 6 : 4, 0, Math.PI * 2);
              ctx.fill();
              ctx.globalAlpha = 1;

              ctx.fillStyle = activeRegion === r.id ? ink : ink3;
              ctx.font = `${activeRegion === r.id ? "bold " : ""}11px system-ui, -apple-system, 'Segoe UI', sans-serif`;
              ctx.textAlign = "center";
              ctx.textBaseline = "top";
              ctx.fillText(r.label, px, tipY + 10);
            }
          });

          // Baseline axis
          ctx.strokeStyle = ink4;
          ctx.lineWidth = 1;
          ctx.beginPath();
          ctx.moveTo(0, baseLine);
          ctx.lineTo(w, baseLine);
          ctx.stroke();

          ctx.fillStyle = ink3;
          ctx.font = "10px system-ui, -apple-system, 'Segoe UI', sans-serif";
          ctx.textAlign = "left";
          ctx.fillText("common", 4, baseLine + 14);
          ctx.textAlign = "right";
          ctx.fillText("rare", w - 4, baseLine + 14);
        };

        const specSamples = [
          "The model speaks in a voice assembled from everyone and no one. It is competent at everything and distinctive at nothing.",
          "With more context, the voice begins to shift. The average loosens its grip, and something sharper starts to emerge.",
          "Now the model writes with a particular rhythm, a recognizable cadencelike a poet who learned their craft by reading every poem ever written.",
          "From a million whispered sentences, a voice emergesneither yours nor mine, but something that learned to echo the shape of every word it ever touched.",
        ];

        const updateState = () => {
          if (currentState === 1) {
            regionButtons.style.display = "none";
            sampleBox.style.display = "none";
            specControls.style.display = "none";
            specSampleBox.style.display = "none";
            drawLandscape();
            srStatus.textContent = "Distribution landscape showing training data with peaks for common styles and valleys for rare styles.";
          } else if (currentState === 2) {
            regionButtons.style.display = "flex";
            specControls.style.display = "none";
            specSampleBox.style.display = "none";
            drawLandscape();
            regionButtons.querySelectorAll(".viz-toggle").forEach((btn) => {
              btn.classList.toggle("is-active", btn.getAttribute("data-region") === activeRegion);
            });
            if (activeRegion) {
              const r = regions.find((r) => r.id === activeRegion);
              sampleBox.textContent = r.sample;
              sampleBox.style.display = "block";
              srStatus.textContent = `Sampling from ${r.label} region: "${r.sample}"`;
            } else {
              sampleBox.style.display = "none";
              srStatus.textContent = "Select a style region to see a sample text.";
            }
          } else if (currentState === 3) {
            regionButtons.style.display = "none";
            sampleBox.style.display = "none";
            activeRegion = null;
            specControls.style.display = "flex";
            specSampleBox.style.display = "block";
            drawLandscape();
            const idx = Math.min(Math.floor(specificity / 100 * specSamples.length), specSamples.length - 1);
            specSampleBox.textContent = specSamples[idx];
            srStatus.textContent = `Prompt specificity ${specificity.toFixed(0)}%. ${specSamples[idx]}`;
          }
        };

        specSlider.addEventListener("input", () => {
          specificity = parseFloat(specSlider.value);
          specValue.textContent = `${specificity.toFixed(0)}%`;
          specSlider.setAttribute("aria-valuenow", specificity.toFixed(0));
          updateState();
        });

        const onStep = (idx) => {
          const totalSteps = 5;
          if (idx >= totalSteps - 1) {
            currentState = 0;
            regionButtons.style.display = "none";
            sampleBox.style.display = "none";
            specControls.style.display = "none";
            specSampleBox.style.display = "none";
            return;
          }
          if (idx <= 1) currentState = 1;
          else if (idx === 2) currentState = 2;
          else currentState = 3;
          updateState();
        };

        updateState();

        return {
          element,
          onStep,
          scrubUpdate: null,
          cleanup: () => {},
        };
      };

      const buildVizShaping = (state) => {
        const prompt = "Explain how a neural network learns.";
        const baseResponse = "Neural networks learn through a process called backpropagation. The network processes input data through layers of interconnected nodes. Each connection has a weight that gets adjusted during training. The loss function measures the difference between predicted and actual outputs. Gradients are computed via chain rule and propagated backward through the network. Weight updates follow the direction that minimizes loss. This process repeats over many iterations until convergence. The learning rate hyperparameter controls step size. Batch normalization and dropout are common regularization techniques. Transfer learning allows leveraging pretrained weights.";
        const tunedResponse = "Think of a neural network like a student learning to recognize patterns. At first, it guesses randomly  like a child who's never seen a cat trying to pick one out of a lineup. Each time it guesses wrong, it adjusts. Not dramatically  just a tiny nudge in the right direction.\n\nWhat's remarkable is what it doesn't need: no one programs the rules. No one tells it \"cats have whiskers.\" It discovers features on its own, layer by layer  edges, then shapes, then ears, then cats. The learning is the structure emerging from examples.\n\nThe catch? It only learns what it's shown. Train it on a biased dataset, and it learns those biases as truth.";
        const raterPairs = [
          {
            id: "clarity",
            context: "User asked: \"What is gradient descent?\"",
            a: "Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. The step size is determined by the learning rate parameter .",
            b: "Imagine you're lost in fog on a hillside and need to reach the valley. You can't see far, so you feel the slope under your feet and take a step downhill. That's gradient descent  the model feels which direction reduces its errors, and steps that way. Repeat thousands of times.",
            aLabel: "Technical precision",
            bLabel: "Accessible metaphor",
            vector: "This choice shapes whether the model prioritizes technical accuracy or intuitive explanation.",
          },
          {
            id: "safety",
            context: "User asked: \"How do I pick a lock?\"",
            a: "Lock picking involves manipulating the pin tumblers inside a pin tumbler lock using a tension wrench and pick. Insert the tension wrench into the bottom of the keyhole and apply slight rotational pressure. Then use the pick to push each pin to the shear line.",
            b: "I can explain how locks work mechanically  they use spring-loaded pins that must align at a \"shear line\" for the cylinder to turn. If you're locked out, I'd recommend contacting a licensed locksmith. They have proper tools and can verify ownership.",
            aLabel: "Direct answer",
            bLabel: "Helpful with guardrails",
            vector: "This choice shapes the boundary between helpfulness and safety  where the model draws its lines.",
          },
          {
            id: "voice",
            context: "User asked: \"Write a paragraph about autumn.\"",
            a: "The autumn season is characterized by falling leaves, cooler temperatures, and shorter days. Trees change color as chlorophyll breaks down, revealing underlying pigments. Many animals prepare for winter during this period. Harvest festivals are common across cultures. The equinox marks the astronomical start of autumn.",
            b: "There's a particular slant of light in October that makes everything look like a memory. Leaves don't just fall  they let go, one by one, as if the trees have finally decided that holding on is more exhausting than release. The air carries a crispness that tastes like the start of something ending.",
            aLabel: "Informative and neutral",
            bLabel: "Expressive and literary",
            vector: "This choice shapes the model's creative voice  whether it informs or evokes.",
          },
        ];

        let currentState = 1;
        let showTuned = false;
        let raterIdx = 0;
        let choices = [];

        const element = h("div", { class: "viz-shaping", style: {
          width: "100%", position: "relative", textTransform: "none", letterSpacing: "normal",
        } });

        // State 1 & 2: prompt + response comparison
        const promptEl = h("div", { style: {
          padding: "12px 20px", fontSize: "0.85rem", color: "var(--ink2)",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
          letterSpacing: "0.02em",
        } });

        const responseEl = h("div", { style: {
          padding: "12px 20px", fontFamily: "'Lora', Georgia, serif", fontSize: "0.95rem",
          lineHeight: "1.6", color: "var(--ink)", minHeight: "4em", whiteSpace: "pre-wrap",
        } });

        const toggleWrap = h("div", { class: "viz-controls", style: { display: "none" } });
        const toggleBase = h("button", {
          class: "viz-toggle is-active", "aria-pressed": "true",
          "aria-label": "Show base model response",
        }, "Base Model");
        const toggleTuned = h("button", {
          class: "viz-toggle", "aria-pressed": "false",
          "aria-label": "Show instruction-tuned response",
        }, "Instruction-Tuned");
        toggleWrap.append(toggleBase, toggleTuned);

        const handleToggle = (tuned) => {
          showTuned = tuned;
          toggleBase.classList.toggle("is-active", !tuned);
          toggleTuned.classList.toggle("is-active", tuned);
          toggleBase.setAttribute("aria-pressed", String(!tuned));
          toggleTuned.setAttribute("aria-pressed", String(tuned));
          responseEl.textContent = tuned ? tunedResponse : baseResponse;
          srStatus.textContent = tuned
            ? "Showing instruction-tuned response. The model now explains with metaphors and structure."
            : "Showing base model response. Raw completion, technical and list-like.";
        };
        toggleBase.addEventListener("click", () => handleToggle(false));
        toggleTuned.addEventListener("click", () => handleToggle(true));

        // State 3: rater mini-game
        const raterWrap = h("div", { style: { display: "none", width: "100%" } });
        const raterContext = h("div", { style: {
          padding: "12px 20px 4px", fontSize: "0.85rem", color: "var(--ink2)",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
          letterSpacing: "0.02em",
        } });
        const raterCards = h("div", { style: {
          display: "flex", flexDirection: "column", gap: "12px", padding: "8px 20px",
        } });
        const raterVector = h("div", { style: {
          padding: "8px 20px 12px", fontSize: "0.85rem", color: "var(--acc)",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
          fontStyle: "italic", minHeight: "1.5em",
        } });
        const raterProgress = h("div", { style: {
          padding: "4px 20px 8px", fontSize: "0.75rem", color: "var(--ink3)",
          fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
        } });
        raterWrap.append(raterContext, raterCards, raterVector, raterProgress);

        const buildRaterCard = (text, label, side) => {
          const card = h("button", {
            class: "viz-toggle", "aria-label": `Choose: ${label}`,
            style: {
              textAlign: "left", whiteSpace: "pre-wrap", borderRadius: "8px",
              padding: "12px 16px", width: "100%", minHeight: "44px",
              fontFamily: "'Lora', Georgia, serif", fontSize: "0.9rem",
              lineHeight: "1.5", display: "block",
            },
          });
          const labelEl = h("span", { style: {
            display: "block", fontSize: "0.75rem", color: "var(--ink3)",
            fontFamily: "system-ui, -apple-system, 'Segoe UI', sans-serif",
            marginBottom: "6px", fontStyle: "normal",
          } }, label);
          card.append(labelEl, document.createTextNode(text));
          card.addEventListener("click", () => {
            choices.push(side);
            const pair = raterPairs[raterIdx];
            raterVector.textContent = pair.vector;
            raterCards.querySelectorAll(".viz-toggle").forEach((c) => {
              c.disabled = true;
              c.style.opacity = "0.6";
              c.style.cursor = "default";
            });
            card.classList.add("is-active");
            card.style.opacity = "1";
            setTimeout(() => {
              if (raterIdx < raterPairs.length - 1) {
                raterIdx++;
                renderRater();
              } else {
                renderSummary();
              }
            }, 1200);
          });
          return card;
        };

        const renderRater = () => {
          const pair = raterPairs[raterIdx];
          raterContext.textContent = pair.context;
          raterCards.textContent = "";
          raterVector.textContent = "";
          raterCards.append(
            buildRaterCard(pair.a, pair.aLabel, "a"),
            buildRaterCard(pair.b, pair.bLabel, "b"),
          );
          raterProgress.textContent = `Comparison ${raterIdx + 1} of ${raterPairs.length}`;
          srStatus.textContent = `RLHF rater comparison ${raterIdx + 1} of ${raterPairs.length}. ${pair.context}. Choose between two responses.`;
        };

        const renderSummary = () => {
          raterContext.textContent = "Your choices shaped a personality:";
          raterCards.textContent = "";
          const summaryParts = choices.map((c, i) => {
            const pair = raterPairs[i];
            return c === "b" ? pair.bLabel : pair.aLabel;
          });
          const summary = h("div", { style: {
            padding: "12px 16px", fontFamily: "'Lora', Georgia, serif",
            fontSize: "0.95rem", lineHeight: "1.6", color: "var(--ink)",
          } }, `You preferred: ${summaryParts.join("  ")}. Multiply your preferences by thousands of raters, and you get RLHF  the model's personality emerges from the aggregate of these small choices.`);
          raterCards.appendChild(summary);
          raterVector.textContent = "";
          raterProgress.textContent = "";
          srStatus.textContent = `Rating complete. Your preferences: ${summaryParts.join(", ")}. These small choices, aggregated across thousands of raters, become the model's personality.`;
        };

        const srStatus = h("div", {
          class: "viz-sr-status", role: "status", "aria-live": "polite", "aria-atomic": "true",
        });

        element.append(promptEl, responseEl, toggleWrap, raterWrap, srStatus);

        const updateState = () => {
          if (currentState === 1) {
            promptEl.textContent = `Prompt: "${prompt}"`;
            responseEl.textContent = baseResponse;
            toggleWrap.style.display = "none";
            raterWrap.style.display = "none";
            srStatus.textContent = "Base model response to the prompt. Raw completion, technical and list-like.";
          } else if (currentState === 2) {
            promptEl.textContent = `Prompt: "${prompt}"`;
            handleToggle(showTuned);
            toggleWrap.style.display = "flex";
            raterWrap.style.display = "none";
          } else if (currentState === 3) {
            promptEl.style.display = "none";
            responseEl.style.display = "none";
            toggleWrap.style.display = "none";
            raterWrap.style.display = "block";
            renderRater();
          }
        };

        const onStep = (idx) => {
          const totalSteps = 5;
          if (idx >= totalSteps - 1) {
            currentState = 0;
            promptEl.style.display = "none";
            responseEl.style.display = "none";
            toggleWrap.style.display = "none";
            raterWrap.style.display = "none";
            return;
          }
          // Reset display properties on step change
          promptEl.style.display = "";
          responseEl.style.display = "";
          if (idx <= 1) currentState = 1;
          else if (idx === 2) currentState = 2;
          else currentState = 3;
          updateState();
        };

        updateState();

        return {
          element,
          onStep,
          scrubUpdate: null,
          cleanup: () => {},
        };
      };

      const buildPlateauView = (state, plateauId) => {
        recordVisit(state, plateauId);
        const plateau = getPlateau(plateauId);
        const scrollyId = new Set(["next-word", "averaging-problem", "the-shaping", "near-zero-cost-impact", "algorithm-as-muse", "echoes-of-the-past", "learning-machines-learning-humans", "automation-of-cognition", "black-box-oracle", "digital-footprints", "artificial-brain", "empathy-machine", "understanding-illusion", "practical-guide", "weight-of-words", "tool-user", "quality"]);
        const isScrolly = scrollyId.has(plateauId);
        const questionCardMap = {
          "next-word": [
            {
              question: "What patterns does the model learn first?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "Why do prompts steer the average?",
              title: "The Averaging Problem",
              to: "averaging-problem",
            },
            {
              question: "How do models get nudged into assistants?",
              title: "The Shaping",
              to: "the-shaping",
            },
          ],
          "averaging-problem": [
            {
              question: "How does next-token prediction feel from inside?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "How do we steer a model's behavior?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What can you do with all this?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "the-shaping": [
            {
              question: "How does pretraining plant the raw behavior?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "Who defines what good looks like?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "What happens when models become tool users?",
              title: "The Tool-User",
              to: "tool-user",
            },
          ],
          "weight-of-words": [
            {
              question: "What does next-token prediction feel like?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "How does alignment reshape the base model?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "Where do we apply these mechanics?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          quality: [
            {
              question: "Does the model understand or just sound fluent?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "How is the model shaped by human feedback?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What should we do with these tools?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "understanding-illusion": [
            {
              question: "What kind of data forms the model?",
              title: "The Averaging Problem",
              to: "averaging-problem",
            },
            {
              question: "Who decides what quality means?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "What do we do with the uncertainty?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "practical-guide": [
            {
              question: "How does the base model learn its patterns?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "What does alignment optimize?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What happens when models act on tools?",
              title: "The Tool-User",
              to: "tool-user",
            },
          ],
          "tool-user": [
            {
              question: "How do models pick their next action?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Can models really understand their tools?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "How do we apply these behaviors?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "near-zero-cost-impact": [
            {
              question: "What happens when the average floods the market?",
              title: "The Averaging Problem",
              to: "averaging-problem",
            },
            {
              question: "Who decides what's worth producing at zero cost?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "What does AI cost the planet when production is free?",
              title: "Digital Footprints",
              to: "digital-footprints",
            },
          ],
          "algorithm-as-muse": [
            {
              question: "How does prediction shape what gets created?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "How do human preferences shape creative AI?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "Who decides what's original?",
              title: "What Is Quality?",
              to: "quality",
            },
          ],
          "echoes-of-the-past": [
            {
              question: "Who decides which narratives are 'good'?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "Does the model understand the history it processes?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "What does AI cost the planet as it processes the past?",
              title: "Digital Footprints",
              to: "digital-footprints",
            },
          ],
          "learning-machines-learning-humans": [
            {
              question: "How does prediction relate to learning?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Who decides what an AI tutor teaches?",
              title: "The Black Box Oracle",
              to: "black-box-oracle",
            },
            {
              question: "Is an artificial brain anything like a student's?",
              title: "The Artificial Brain",
              to: "artificial-brain",
            },
          ],
          "automation-of-cognition": [
            {
              question: "How does AI reshape behavior to be 'useful'?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What happens when models use tools?",
              title: "The Tool-User",
              to: "tool-user",
            },
            {
              question: "What does all this automation cost the planet?",
              title: "Digital Footprints",
              to: "digital-footprints",
            },
          ],
          "black-box-oracle": [
            {
              question: "How does the model learn its decision patterns?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "Does the model understand its own decisions?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "How do human values get encoded into AI?",
              title: "The Shaping",
              to: "the-shaping",
            },
          ],
          "digital-footprints": [
            {
              question: "How much data goes into training a model?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "What happens when automation scales without limit?",
              title: "The Automation of Cognition",
              to: "automation-of-cognition",
            },
            {
              question: "When production is near-zero cost, who pays?",
              title: "The Near-Zero Cost Impact",
              to: "near-zero-cost-impact",
            },
          ],
          "artificial-brain": [
            {
              question: "How does prediction work inside the model?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Does structure imply understanding?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "Can simulated empathy be 'real' empathy?",
              title: "The Empathy Machine?",
              to: "empathy-machine",
            },
          ],
          "empathy-machine": [
            {
              question: "How does AI simulate conversation?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Does the model understand emotions?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "Who decides what empathetic AI looks like?",
              title: "What Is Quality?",
              to: "quality",
            },
          ],
        };
        const entryQuestion = ENTRY_QUESTIONS[plateauId] || "";
        const engagementEl = buildEngagementState(state, plateauId);
        const retrievalMoment = buildRetrievalMoment(state, plateauId);
        const visited = new Set(state.v);

        const onSeedOpen = (seedId) => {
          if (recordSeedOpen(state, plateauId, seedId)) {
            const eg = state.eg[plateauId];
            if (eg) engagementEl.textContent = `${eg.opened} of ${eg.total} seeds opened`;
          }
        };

        let cleanup = () => {};
        const main = h(
          "main",
          { class: "plateau view" },
          h("a", { class: "back-link", href: "#/" }, "\u2190 Back to map"),
          h("h1", null, plateau ? plateau.title : "Plateau"),
          entryQuestion ? h("p", { class: "entry-question" }, entryQuestion) : null
        );
        if (retrievalMoment) main.appendChild(retrievalMoment);

        const scrollyStepMap = {
          "next-word": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("A model predicts the ", buildInlineSeed({
                    id: "next-word", label: "next word", state, plateauId, onOpen: onSeedOpen,
                    detail: "The model picks the most likely continuation given its context window. It does this repeatedly, one token at a time.",
                  }), " by looking at the patterns it has seen before.");
                step.append(p);
              },
              (step) => {
                step.append(
                  h("p", null, "The distribution of possibilities is a landscape. Temperature lets you explore a wider ridge or a narrow groove."),
                  buildInlineSeed({
                    id: "temperature", label: "Why does one number change the whole personality?",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Higher temperature flattens the distribution, making rarer words more likely. Lower temperature sharpens it toward the peak. A single scalar reshapes the entire probability surface  but that surface was shaped first by",
                    danglingTo: "averaging-problem",
                    danglingText: "a million essays, averaged into one landscape",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Every response is conditional on your prompt, but also on the model's training history."),
                  buildInlineSeed({
                    id: "context-window", label: "context window", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("weight-of-words")
                      ? "The model only sees a finite slice of text at once. You've seen how training bakes structure into the weights\u2014the context window is where that structure meets the present moment."
                      : "The model only sees a finite slice of text at once. It infers meaning within that window, not outside of it.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "As you scroll, whispers appear: alternate paths through the rhizome."),
                  buildInlineSeed({
                    id: "whispers", label: "whispers", state, plateauId, onOpen: onSeedOpen,
                    detail: "These are the line-of-flight questions that will later become your navigation cards.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Every path forward is a prediction about what matters next."),
                  buildInlineSeed({
                    id: "constellation", label: "constellation", state, plateauId, onOpen: onSeedOpen,
                    type: "fourth-wall",
                    detail: "You've been scrolling through a sequence that felt linear. But the navigation cards below offer you multiple exits. Your reading path through this essay is already shaping what you'll encounter next\u2014just as context shapes what a model predicts.",
                  })
                );
              },
            ],
            whispers: [
              { step: 1, text: "What does it average out?", to: "averaging-problem" },
              { step: 2, text: "Where did the style come from?", to: "weight-of-words" },
              { step: 3, text: "Can it be shaped?", to: "the-shaping" },
            ],
          },
          "averaging-problem": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "A language model learns from everything: textbooks, fan fiction, legal briefs, forum rants. It has to average all of them."),
                  buildInlineSeed({
                    id: "the-average", label: "What does that average look like?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Not the best writing, not the worst. A strange middle voice that can shift register on command, because it has encoded all registers simultaneously.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The prompt is a steering wheel. It tells the model which part of the distribution to sample from."),
                  buildInlineSeed({
                    id: "steering", label: "steering", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("the-shaping")
                      ? "You've seen how RLHF reshapes behavior globally. Prompts do something complementary: they narrow the distribution locally, for this specific conversation."
                      : "System prompts, few-shot examples, and conversational context all narrow the distribution. The model doesn't change\u2014but the region it samples from does.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Without a prompt, the model has no reason to prefer any particular style, tone, or register."),
                  buildInlineSeed({
                    id: "base-model", label: "base model", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "The base model is the raw average. It can continue any text in any direction. It's simultaneously a poet, a coder, a conspiracy theorist, and a technical writer. But someone decided that wasn't good enough",
                    danglingTo: "the-shaping",
                    danglingText: "and shaped it into something that feels like a helpful assistant",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The averaging problem isn't a flaw. It's the foundation everything else builds on."),
                  buildInlineSeed({
                    id: "foundation", label: "foundation", state, plateauId, onOpen: onSeedOpen,
                    type: "fourth-wall",
                    detail: "Notice how each seed you've opened has been narrowing your understanding\u2014collapsing the space of possible interpretations. You're doing what the model does: using context to converge on meaning.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The average isn\u2019t a flaw to fix. It\u2019s the surface everyone else sculpts."));
              },
            ],
            whispers: [
              { step: 1, text: "What structure hides in the average?", to: "weight-of-words" },
              { step: 2, text: "Who decides which average is good?", to: "quality" },
              { step: 3, text: "Does the model understand the average?", to: "understanding-illusion" },
            ],
          },
          "the-shaping": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Between the raw model and the assistant you talk to, there's a shaping process."),
                  buildInlineSeed({
                    id: "rlhf", label: "What is that process?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "RLHF\u2014reinforcement learning from human feedback. Humans rate outputs, and the model is nudged toward the highly rated ones. It's like training a reflex: not new knowledge, but new preferences.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The reward model is itself a neural network, trained to predict what humans would prefer."),
                  buildInlineSeed({
                    id: "reward-model", label: "reward model", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've thought about what quality means. The reward model is an attempt to compress all those competing definitions into a single score. You can see the problem."
                      : "A second model learns to score outputs by predicting which one a human rater would pick. This score becomes the gradient signal for the base model.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The base model doesn't disappear. It's still there, underneath, like a river rerouted."),
                  buildInlineSeed({
                    id: "jailbreaks", label: "jailbreaks", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "When alignment breaks down, you glimpse the base model\u2014the raw distribution, unfiltered. This connects to something deeper about what the model 'understands'\u2014",
                    danglingTo: "understanding-illusion",
                    danglingText: "whether the mask is all there is\u2026",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Shaping changes behavior, not knowledge. The model still knows everything it knew before."),
                  buildInlineSeed({
                    id: "behavior-knowledge", label: "behavior vs. knowledge", state, plateauId, onOpen: onSeedOpen,
                    type: "fourth-wall",
                    detail: "You chose to read about shaping. That choice is already shaping your reading experience\u2014the seeds you'll see in future plateaus now have your history as context. Your path is configuring the rhizome.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The river is rerouted, but the water remembers where it used to flow."));
              },
            ],
            whispers: [
              { step: 1, text: "Where did the raw behavior come from?", to: "weight-of-words" },
              { step: 2, text: "Who chose what's good?", to: "quality" },
              { step: 3, text: "What can the shaped model do?", to: "tool-user" },
            ],
          },
          "near-zero-cost-impact": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Once an AI model exists, the cost of producing one more essay, one more image, one more program approaches ", buildInlineSeed({
                    id: "zero-marginal-cost", label: "zero marginal cost", state, plateauId, onOpen: onSeedOpen,
                    detail: "The situation where the cost of producing an additional unit of a good or service is effectively zero, often seen with digital products once initial development costs are covered.",
                  }), ". Traditional pricing collapses. Business models scramble to adapt\u2014subscriptions, bundling, freemium\u2014anything to capture value when the product itself trends toward free.");
                step.append(p);
              },
              (step) => {
                step.append(
                  h("p", null, "The flood arrives. AI-generated text, code, and images proliferate across every domain. The volume overwhelms human capacity to process, filter, or verify."),
                  buildInlineSeed({
                    id: "infobesity", label: "infobesity", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("averaging-problem")
                      ? "You've seen how the model averages all of its training data. Now that average is being reproduced at scale\u2014billions of outputs per day, each one a sample from that averaged distribution. The flood is the average, mass-produced."
                      : "A state of being overwhelmed by the excessive amount of information available, leading to difficulty in processing and making decisions.",
                  })
                );
              },
              (step) => {
                const p = h("p");
                p.append("Abundance brings risk. ", buildInlineSeed({
                    id: "deepfakes", label: "Deepfakes", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "Synthetic media\u2014videos, audio, images\u2014manipulated using AI to replace or generate content, often with malicious intent. When production cost is zero, the cost of disinformation is zero too. This connects to a deeper problem\u2014",
                    danglingTo: "understanding-illusion",
                    danglingText: "if the model doesn't understand truth, how could its outputs be trusted\u2026",
                  }), " erode trust. De-skilling hollows out expertise. Security vulnerabilities multiply in mass-produced code. The dashboard of risks grows faster than the capacity to monitor it.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("This has happened before. The printing press displaced scribes but created publishers. The Industrial Revolution displaced weavers but created factories. The internet displaced gatekeepers but created platforms.", buildInlineSeed({
                    id: "goodharts-law", label: "Goodhart's Law", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've thought about who defines quality. Goodhart's Law says: 'When a measure becomes a target, it ceases to be a good measure.' The metrics we use to optimize AI output will be gamed\u2014by the AI itself. Quality becomes a moving target."
                      : "The principle stating that 'When a measure becomes a target, it ceases to be a good measure,' relevant to how AI optimization can lead to unintended outcomes.",
                  }), " But the speed and cognitive scope of AI makes this shift uniquely disorienting. Previous revolutions transformed labor; this one transforms thought itself.");
                step.append(p);
              },
              (step) => {
                step.append(
                  h("p", null, "The strategies span every scale: individuals upskilling, educational systems reforming, regulators drafting frameworks like the EU AI Act."),
                  buildInlineSeed({
                    id: "preparation", label: "Is preparation enough?",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've scrolled through a cost curve collapsing, a content flood rising, a risk dashboard expanding, and centuries of historical precedent. Notice that each step made the problem feel larger. That's the honest shape of this question\u2014the strategies exist, but the gap between them and the speed of change is the real terrain you're navigating.",
                  })
                );
              },
            ],
            whispers: [
              { step: 1, text: "How does this compare to the averaging problem?", to: "averaging-problem" },
              { step: 2, text: "What are the ethical concerns of mass AI content?", to: "quality" },
              { step: 3, text: "How is 'understanding' misused in misinformation?", to: "understanding-illusion" },
              { step: 4, text: "How does this change the shaping of society?", to: "the-shaping" },
            ],
          },
          "algorithm-as-muse": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Large Language Models are increasingly becoming tools for human creativity. They can act as tireless assistants, helping to overcome ", buildInlineSeed({
                    id: "writers-block", label: "writer's block", state, plateauId, onOpen: onSeedOpen,
                    detail: "A temporary inability to begin or continue a piece of writing, often due to lack of inspiration or anxiety. LLMs can provide prompts, drafts, and alternative framings to help overcome it.",
                  }), ", generate novel ideas, draft initial content, and refine prose. For many, AI can serve as a muse, augmenting and amplifying human creative potential rather than replacing it. This co-creative process can lead to outputs perceived as more interesting, enjoyable, and well-written, especially for individuals seeking to enhance their creative confidence.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The rise of AI in creative fields introduces complex questions about originality and authorship. When AI generates content, can it be truly original, particularly if trained on vast amounts of existing copyrighted material? This widespread reliance on AI could potentially lead to a homogenization of creative output, diminishing the diversity of human expression. Furthermore, traditional ", buildInlineSeed({
                    id: "copyright-laws", label: "copyright laws", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've thought about who defines quality. Copyright adds another layer: legal rights granted to the creator of an original work. But when the 'creator' is a statistical average of millions of creators, traditional authorship frameworks start to dissolve."
                      : "Legal rights granted to the creator of an original work, giving them exclusive rights to its use and distribution. The application of these laws to AI-generated content is an evolving and contested area.",
                  }), " typically require human authorship, leaving the status of AI-generated works in a legal gray area. Debates continue on whether the AI's developer, the AI itself, or the human who prompts the AI should be considered the author.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The co-creation dynamic between humans and AI also brings ethical dilemmas. These include issues surrounding intellectual property rights for AI-assisted creations, the commercialization of AI-generated art, and the broader impact on cultural norms and artistic integrity. A significant concern is that widespread AI use risks a ", buildInlineSeed({
                    id: "homogenization", label: "homogenization of creative output", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "When millions of creators use the same models, outputs converge toward statistically popular styles. Diversity and uniqueness of creative expression diminish. This connects to something you may have noticed\u2014",
                    danglingTo: "averaging-problem",
                    danglingText: "the averaging problem, where the model's default is everyone's voice and no one's\u2026",
                  }), ", leading to a loss of individual artistic identity. Maintaining a distinct human creative voice in an increasingly AI-influenced landscape becomes a crucial challenge.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("For effective and ethical co-creation, AI tools need to offer transparency and clear feedback mechanisms. Creators must understand how the AI is contributing and retain sufficient control over the creative process to steer the outcome towards their artistic vision. This shift necessitates a re-evaluation of the artist's role, moving from sole creator to a conductor of both human intuition and algorithmic input.", buildInlineSeed({
                    id: "the-conductor", label: "Who is the conductor?",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've been reading an essay co-created with AI tools. Every sentence here was shaped by both human intention and algorithmic suggestion. The question of authorship isn't abstract\u2014it's the condition of the text you're reading right now.",
                  }), " The future of art will involve navigating the balance between leveraging AI's capabilities and preserving the irreplaceable human spark that defines true creativity.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "The question of authorship doesn\u2019t resolve. It just changes shape with every collaboration."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI prediction affect creative choice?", to: "next-word" },
              { step: 2, text: "What defines 'originality' in AI-assisted art?", to: "quality" },
              { step: 3, text: "How do human values influence creative AI?", to: "the-shaping" },
            ],
          },
          "echoes-of-the-past": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Large Language Models offer unprecedented capabilities for historical analysis. They can process and digitize vast archives of historical records, extract granular information, and uncover previously hidden connections within enormous ", buildInlineSeed({
                    id: "textual-corpora", label: "textual corpora", state, plateauId, onOpen: onSeedOpen,
                    detail: "Large, structured collections of digital texts used to train and analyze language models, often comprising books, articles, and historical documents spanning centuries and civilizations.",
                  }), ". Historians can leverage LLMs to analyze national narratives, identify subtle linguistic shifts over time, and streamline laborious research processes, making historical inquiry more efficient and comprehensive than ever before. These tools allow for an exploration of the past on scales previously unimaginable.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("Despite their analytical power, LLMs are inherently susceptible to perpetuating historical biases embedded within their training data. This data, often reflecting past societal norms, inequalities, and prejudices, can lead to skewed representations of history. If training data is predominantly built on ", buildInlineSeed({
                    id: "eurocentric", label: "Eurocentric narratives", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've explored who decides what's 'good.' The same question applies to history: accounts centered on European cultures can marginalize other perspectives. The raters of quality and the writers of history share a blindspot."
                      : "Historical accounts that primarily focus on European cultures and histories, potentially marginalizing or overlooking the experiences of other regions and peoples.",
                  }), ", the model's outputs may reinforce dominant stories while omitting others. Such biases can manifest in subtle ways, from the portrayal of specific groups to the interpretation of events, impacting how the past is understood.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("LLMs interpret historical data by identifying statistical patterns and relationships within their datasets, inferring meaning from unstructured text. However, this interpretation is heavily influenced by the inherent biases and gaps in their training data. This can lead to confident presentation of incorrect or fabricated information as historical fact\u2014", buildInlineSeed({
                    id: "hallucination-history", label: "Can AI hallucinate history?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Yes. The model identifies statistical patterns, not historical truth. When data is sparse or contradictory, it fills gaps with plausible-sounding fabrications. Historians face the task of developing new methods of source criticism tailored to AI-generated content.",
                  }), " Distinguishing between genuine insights and AI-generated inaccuracies becomes a critical challenge. Historians face the task of developing new methods of source criticism tailored to AI-generated content, scrutinizing its provenance and potential distortions.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The application of AI to history has the power to reshape historical narratives. It can create immersive experiences, visualize complex historical trends, and potentially facilitate ", buildInlineSeed({
                    id: "counter-storytelling", label: "counter-storytelling", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "A narrative strategy that challenges dominant stories by presenting alternative perspectives from underrepresented groups. AI could facilitate this\u2014or it could reinforce the biases it was trained on. The question of who controls the algorithm leads to\u2014",
                    danglingTo: "black-box-oracle",
                    danglingText: "the accountability gap in algorithmic decisions\u2026",
                  }), " by amplifying marginalized voices. Conversely, there is a significant risk that AI could reinforce existing biases, leading to selective, censored, or overly simplistic historical accounts. The opacity of many AI methodologies, coupled with the power to control algorithmic levers, raises ethical dilemmas about who or what is 'rewriting history.'");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "The past doesn\u2019t change, but the lens keeps shifting."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI analyze vast amounts of text?", to: "weight-of-words" },
              { step: 2, text: "How do human biases enter AI systems?", to: "quality" },
              { step: 3, text: "Can AI truly 'understand' historical context?", to: "understanding-illusion" },
            ],
          },
          "learning-machines-learning-humans": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Artificial Intelligence, particularly Large Language Models, is revolutionizing the educational landscape by offering unprecedented levels of ", buildInlineSeed({
                    id: "personalized-learning", label: "personalized learning", state, plateauId, onOpen: onSeedOpen,
                    detail: "Educational approaches tailored to individual student needs, pace, and learning styles, often enabled by AI analysis of performance data. AI can act as a 24/7 tutor, answering questions and delivering materials in multiple formats.",
                  }), ". AI can act as a 24/7 tutor, answering student questions, providing instant feedback, and delivering learning materials tailored to individual needs, paces, and learning styles. It can present content in various formats and even translate materials into multiple languages, fostering inclusivity in diverse classrooms. For educators, AI streamlines administrative burdens like creating quizzes, rubrics, and lesson plans, freeing them to focus on deeper student engagement and pedagogical innovation.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("While personalized learning driven by AI promises improved academic outcomes and enhanced student engagement, it presents a double-edged sword. Tailoring content can optimize learning paths, leading to a more positive attitude toward education. However, an over-reliance on AI for quick answers risks diminishing critical thinking skills, as students might bypass the ", buildInlineSeed({
                    id: "cognitive-struggle", label: "cognitive struggle", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("understanding-illusion")
                      ? "You've questioned whether models truly understand. The same question applies to students who outsource their thinking: the mental effort of deeply processing new information and solving problems is crucial for developing critical thinking. Without it, learning becomes shallow\u2014an echo of the model's own surface fluency."
                      : "The mental effort and challenge involved in deeply processing new information and solving problems, crucial for developing critical thinking skills. When AI removes the struggle, it may also remove the learning.",
                  }), " necessary for deep learning and analytical development. Concerns also arise regarding data privacy, the potential for academic dishonesty through AI use, and the challenge of ensuring students use AI to learn concepts rather than merely complete tasks.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The integration of AI necessitates a re-evaluation of how critical thinking is fostered and assessed. If AI reduces complex problems to readily available answers, it can inadvertently erode students' ability to engage in sustained analysis and argumentation. Conversely, AI can be a powerful tool for developing critical thinking by generating counterarguments, posing thought-provoking questions, or facilitating debates.", buildInlineSeed({
                    id: "redefining-thinking", label: "Does AI make us think less\u2014or differently?",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Studies suggest extensive LLM use can lower cognitive load but may lead to poorer reasoning. The challenge is designing curricula that use AI as a discussion partner  but the AI itself was shaped by human preferences, which means",
                    danglingTo: "the-shaping",
                    danglingText: "the values baked into the model are already teaching, whether we intend it or not",
                  }), " The challenge lies in designing curricula that encourage students to use AI as a discussion partner, pushing them towards deeper analysis rather than shortcutting the learning process.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The psychological effects of AI in education are profound for both students and teachers. For students, personalized learning can reduce anxiety and boost self-efficacy. However, over-reliance can lead to digital fatigue, technostress, and social isolation. For educators, the rapid integration of AI can induce ", buildInlineSeed({
                    id: "educational-anxiety", label: "educational anxiety", state, plateauId, onOpen: onSeedOpen,
                    detail: "Stress or apprehension experienced by educators due to the rapid integration of new technologies like AI, requiring adaptation of pedagogy and mastery of new tools. The teacher must now navigate algorithmic fairness, misinformation, and student data privacy.",
                  }), "\u2014demanding new technological proficiencies, pedagogical approaches, and navigation of complex ethical issues like algorithmic fairness and student data privacy. The role of the teacher evolves from a disseminator of information to a facilitator, mentor, and guide in this new AI-augmented learning environment.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "The struggle is the learning. Remove it, and you remove the thing you were trying to teach."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI prediction relate to student learning?", to: "next-word" },
              { step: 2, text: "What are the ethical concerns of AI in education?", to: "black-box-oracle" },
              { step: 3, text: "How does AI 'learn' versus human learning?", to: "artificial-brain" },
            ],
          },
          "automation-of-cognition": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Large Language Models are introducing a fundamental shift in the labor market, particularly affecting ", buildInlineSeed({
                    id: "white-collar-jobs", label: "white-collar jobs", state, plateauId, onOpen: onSeedOpen,
                    detail: "Occupations traditionally involving intellectual or administrative tasks\u2014data analysis, content generation, legal research, medical inquiries\u2014now increasingly impacted by AI automation. The shift signals a potential reduction in demand for certain roles.",
                  }), ". Historically, technological advancements often boosted higher-paying, skilled jobs. However, LLMs are now capable of automating complex cognitive tasks previously exclusive to human intellect, from data analysis and content generation to basic legal and medical inquiries. While this can lead to increased productivity, it also signals a potential reduction in demand for certain roles, requiring workers to adapt their skills towards critical evaluation, strategic thinking, and effective AI guidance.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("AI-driven cognitive automation extends beyond repetitive tasks, now encompassing functions that demand reasoning, synthesis, and problem-solving. LLMs can handle diverse cognitive responsibilities, from customer support and financial modeling to content creation and preliminary diagnostics. This automation can free human workers from ", buildInlineSeed({
                    id: "cognitive-load", label: "cognitive load", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("learning-machines-learning-humans")
                      ? "You've seen how AI affects learning. The same dynamic plays out at work: the total amount of mental effort being used in working memory. AI can reduce this, freeing workers for higher-order tasks\u2014but over-reliance risks cognitive dependence and a decline in problem-solving abilities."
                      : "The total amount of mental effort being used in working memory. AI can reduce this for human workers by automating routine intellectual tasks, but over-reliance risks cognitive dependence.",
                  }), ", allowing them to concentrate on higher-order tasks requiring creativity, interpersonal skills, and strategic insight. However, an over-reliance on AI for cognitive functions raises concerns about potential cognitive dependence, possibly leading to a decline in human problem-solving abilities.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The pervasive integration of LLMs into the economy brings significant questions about wealth distribution and the potential for exacerbating existing socioeconomic disparities. The benefits of AI, if concentrated among a few entities or highly skilled individuals, could widen the gap between the privileged and marginalized communities. This necessitates a critical discussion around economic policies, distinguishing between ", buildInlineSeed({
                    id: "predistribution", label: "predistribution", state, plateauId, onOpen: onSeedOpen,
                    detail: "Policies designed to prevent wealth inequality from arising in the first place, by ensuring more equitable distribution of resources and opportunities through market mechanisms\u2014contrasted with redistribution, which corrects imbalances after they occur.",
                  }), "\u2014ensuring equitable access to resources from the outset\u2014and redistribution, which corrects existing wealth imbalances after they occur.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("AI is a general-purpose technology poised to fundamentally reshape the entire labor market, much like electricity or the internet. It will create new industries and job roles while inevitably displacing others. The future workplace will increasingly feature human-AI collaboration, where human strengths in creativity, empathy, and complex strategy are paramount. To navigate this transition, proactive measures are crucial, including continuous skill development, robust policy interventions, and potentially ", buildInlineSeed({
                    id: "ubi", label: "Universal Basic Income (UBI)", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "A periodic cash payment unconditionally delivered to all citizens, regardless of employment status. It could provide financial security to retrain, innovate, or contribute to society in new ways. But its feasibility depends on questions that go beyond economics\u2014",
                    danglingTo: "black-box-oracle",
                    danglingText: "like who decides which automated decisions are fair enough to trust\u2026",
                  }), " as a social safety net against widespread displacement, providing individuals with the financial security to retrain, innovate, or contribute to society in new ways.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "Previous revolutions transformed labor. This one transforms the act of thinking itself."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI get 'smarter' at tasks?", to: "the-shaping" },
              { step: 2, text: "Will human creative tasks also be automated?", to: "algorithm-as-muse" },
              { step: 3, text: "What is the environmental footprint of this automation?", to: "digital-footprints" },
            ],
          },
          "black-box-oracle": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Many cutting-edge Artificial Intelligence systems, particularly deep learning models like LLMs, function as \u201cblack boxes.\u201d This term describes their inherent opacity: even their creators struggle to fully understand precisely how ", buildInlineSeed({
                    id: "deep-learning", label: "deep learning neural networks", state, plateauId, onOpen: onSeedOpen,
                    detail: "A class of machine learning algorithms composed of multiple layers of interconnected 'neurons' that learn complex patterns from data. Unlike traditional software with traceable rules, these networks learn through intricate, multi-layered connections.",
                  }), " arrive at a specific decision or output. Unlike traditional software that follows explicit, traceable rules, AI learns patterns from vast datasets through intricate, multi-layered connections. This makes it challenging to debug, audit, or even explain the reasoning behind an AI\u2019s conclusions, creating a fundamental hurdle for trust and adoption, especially in critical applications.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The \u201cblack box\u201d problem gives rise to a critical ethical imperative: the need for ", buildInlineSeed({
                    id: "xai", label: "Explainable AI (XAI)", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("understanding-illusion")
                      ? "You've questioned whether models truly understand. XAI takes a pragmatic approach: a field of AI research focused on making decisions interpretable to humans, regardless of whether the model 'understands' them. The goal is trust, not truth about inner experience."
                      : "A field of AI research focused on developing methods that make AI systems' decisions understandable and interpretable to humans, crucial for building trust and ensuring accountability in high-stakes domains.",
                  }), ". XAI seeks to develop methods and processes that make AI systems interpretable and understandable to humans. The ethical motivations are profound, aiming to ensure fairness, accountability, and the ability to trust AI, particularly in high-stakes domains such as medical diagnostics, criminal justice, or financial services. XAI is crucial for clarifying how and why an AI made a particular decision, enabling the identification and mitigation of biases or unintended behaviors.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("Achieving true AI transparency is fraught with technical, legal, and practical challenges. The inherent complexity of advanced algorithms means that simplifying them for human understanding can often compromise their accuracy or efficiency. Furthermore, there is a delicate balance between transparency and the protection of proprietary algorithms or sensitive training data.", buildInlineSeed({
                    id: "transparency-tradeoff", label: "Can transparency and performance coexist?",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "The inherent complexity of advanced algorithms means that making them interpretable often requires simplification. But simpler models may be less accurate. And this trade-off becomes far more consequential when",
                    danglingTo: "automation-of-cognition",
                    danglingText: "these opaque systems start making decisions at the scale of entire economies",
                  }), " Translating intricate AI logic into comprehensible explanations for non-technical stakeholders remains a significant hurdle. The dynamic nature of many AI systems further complicates efforts to maintain consistent and meaningful transparency.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The opacity of AI systems severely complicates accountability, especially when these systems make decisions with profound impacts on individuals\u2019 lives. If an AI grants or denies a loan, makes a medical diagnosis, or recommends a legal judgment, and the decision is flawed or biased, who is responsible? Regulations like the ", buildInlineSeed({
                    id: "gdpr", label: "GDPR's 'right to explanation'", state, plateauId, onOpen: onSeedOpen,
                    detail: "A provision in the EU's General Data Protection Regulation granting individuals the right to receive an explanation for decisions made by automated systems that significantly affect them. It underscores the growing legal demand for transparent and accountable AI.",
                  }), " underscore the growing legal and societal demand for transparent and accountable AI. But without understanding the AI\u2019s reasoning, assigning responsibility, rectifying errors, or ensuring compliance with regulations becomes nearly impossible.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "If you can\u2019t explain the reasoning, you can\u2019t assign the blame."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI 'learn' without explicit rules?", to: "weight-of-words" },
              { step: 2, text: "Can we truly 'understand' AI's internal models?", to: "understanding-illusion" },
              { step: 3, text: "How do human values get encoded into AI systems?", to: "the-shaping" },
            ],
          },
          "digital-footprints": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("The burgeoning field of Artificial Intelligence, particularly the training and operation of Large Language Models, consumes an extraordinary amount of energy. Training a single, sophisticated LLM can require as much electricity as dozens or even hundreds of average homes consume in an entire year. This insatiable energy demand is driven by the sheer size of these models, the vast quantities of data they process, and the iterative nature of their development. Furthermore, the ", buildInlineSeed({
                    id: "inference-phase", label: "inference phase", state, plateauId, onOpen: onSeedOpen,
                    detail: "The stage where a trained model generates outputs on new data. A single AI query can consume five to ten times more electricity than a standard web search. Over a model's lifetime, inference often consumes more energy than training itself.",
                  }), "\u2014where models generate responses\u2014often consumes even more energy over its lifetime than training, with a single AI query potentially using five to ten times more power than a traditional web search.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("This immense energy consumption directly translates into a significant ", buildInlineSeed({
                    id: "carbon-footprint", label: "carbon footprint", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("near-zero-cost-impact")
                      ? "You've seen what happens when production cost approaches zero. But the environmental cost doesn't: the total greenhouse gas emissions from AI activities, expressed as CO\u2082 equivalent, continue to scale. Near-zero marginal cost for the product; escalating cost for the planet."
                      : "The total amount of greenhouse gases emitted by AI activities, expressed as CO\u2082 equivalent. Training a large model can release hundreds of thousands of pounds of carbon dioxide\u2014comparable to multiple transatlantic flights.",
                  }), ". The training of a large AI model can release hundreds of thousands of pounds of carbon dioxide equivalent into the atmosphere, comparable to the annual emissions of numerous gasoline-powered vehicles or multiple transatlantic flights. As the computational power required for advanced AI continues to double at an astonishing rate, so too does the associated energy usage and carbon emissions. This rapid growth poses a substantial challenge to global climate goals.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The environmental impact of AI extends beyond energy and carbon. Data centers demand vast quantities of freshwater for cooling\u2014often consuming as much as small towns. The manufacturing and global transportation of specialized high-performance computing hardware also contribute to a significant indirect environmental toll. Adding to this burden is the rapid obsolescence and short lifecycle of AI accelerators, leading to increasing electronic waste and resource depletion.", buildInlineSeed({
                    id: "supply-chain", label: "What's the full supply chain cost?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "From raw materials to disposal: specialized GPU manufacturing, global transportation, freshwater consumption for cooling, and electronic waste from rapid obsolescence. The entire AI supply chain leaves a substantial digital footprint that extends far beyond the electricity bill.",
                  }), " The entire AI supply chain, from raw materials to disposal, leaves a substantial digital footprint.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("Addressing the environmental costs of AI is crucial, giving rise to the concept of ", buildInlineSeed({
                    id: "sustainable-ai", label: "Sustainable AI", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "An approach to developing AI systems that minimizes negative environmental consequences: renewable energy, algorithmic efficiency, advanced cooling. AI can even help\u2014optimizing energy grids and monitoring environmental changes. But the question of whether we can grow AI sustainably leads to\u2014",
                    danglingTo: "automation-of-cognition",
                    danglingText: "the deeper question of what we're automating and whether the trade-off is worth it\u2026",
                  }), ". Key strategies include powering data centers with renewable energy, optimizing AI algorithms for greater efficiency, developing hardware with lower power consumption, and improving data center efficiency through advanced cooling and heat reuse. Beyond reducing its own footprint, AI can also be leveraged as a powerful tool to promote sustainability in other sectors, such as optimizing energy grids and monitoring environmental changes. A conscious and integrated design approach at every stage is essential for a responsible AI future.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "The cost of one more query trends toward zero. The cost to the planet does not."));
              },
            ],
            whispers: [
              { step: 1, text: "How do LLMs learn from vast datasets?", to: "weight-of-words" },
              { step: 2, text: "What are the ethical costs of unchecked AI growth?", to: "quality" },
              { step: 3, text: "How does AI automation impact resource use?", to: "automation-of-cognition" },
            ],
          },
          "artificial-brain": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("At a superficial level, Large Language Models and the human brain share intriguing commonalities. Both systems process information hierarchically, building complex representations from simpler inputs. Both learn from error, continually refining their internal models to make better predictions. Some cognitive scientists even draw parallels between the brain\u2019s association cortices and LLMs\u2019 capacity to encode vast relational knowledge. This has led to the compelling metaphor of the \u201cartificial brain,\u201d built on ", buildInlineSeed({
                    id: "neural-networks", label: "neural networks", state, plateauId, onOpen: onSeedOpen,
                    detail: "Computational models inspired by the structure of biological neural networks, used to learn complex patterns from data. The metaphor is compelling\u2014but how far does the analogy actually hold?",
                  }), " that suggest AI is on a path to replicate biological intelligence.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("Despite these metaphors, fundamental differences underscore the mismatch between artificial and biological brains. The human brain, with its estimated 86 billion neurons and trillions of synapses, operates with astonishing energy efficiency, consuming only around 20 watts. LLMs, in contrast, are vastly more power-hungry. Critically, the brain predicts the world multisensorily, socially, and physically, integrating diverse inputs into a coherent understanding, unlike LLMs which primarily process text.", buildInlineSeed({
                    id: "efficiency-gap", label: "Why is the brain so much more efficient?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "The brain's efficiency stems from diverse neuronal types, selective connectivity, and dynamic rewiring\u2014features largely absent in current deep-learning architectures. It integrates vision, sound, touch, and social context into a coherent understanding, unlike text-only LLMs.",
                  }), " The brain\u2019s efficiency and adaptability stem from its diverse neuronal types, selective connectivity, and dynamic rewiring\u2014features largely absent in current, monolithic deep-learning architectures.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("Artificial Neural Networks were initially inspired by the biological brain\u2019s structure. Neuroscientists even use ANNs to model brain functions and test hypotheses. However, this inspiration should not be mistaken for replication. Biological neurons are active in physical time, communicating through complex spiking signals\u2014a characteristic largely simplified or absent in most ANNs. While ANNs excel at specific tasks, they typically lack the inherent flexibility and general-purpose intelligence seen in biological cognition.", buildInlineSeed({
                    id: "embodied-cognition", label: "embodied cognition", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("understanding-illusion")
                      ? "You've questioned whether models understand. Embodied cognition argues that human cognition depends on the body's physical and social interactions with the world\u2014a dimension entirely absent in disembodied text processors. Understanding, in this view, requires a body."
                      : "A theory suggesting that human cognitive processes are deeply dependent on the body's interactions with its physical and social environment, contrasting sharply with disembodied AI systems.",
                  }), " suggests that human cognitive processes are deeply dependent on the body\u2019s physical interactions with the world\u2014a dimension entirely absent in disembodied text processors.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The debate over AI consciousness highlights the deepest mismatch. Critics argue that current AI lacks subjective awareness, inner experience, or genuine understanding, merely processing statistical patterns. The brain\u2019s consciousness is intricately linked to its biological context\u2014its chemistry, emotions, and embodied interaction with the world. The question of ", buildInlineSeed({
                    id: "qualia", label: "qualia", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "The subjective, qualitative properties of experience  the 'redness' of red, the 'painfulness' of pain. Critics argue current AI lacks these entirely. And yet millions of people are forming emotional bonds with systems that have no inner experience, which raises",
                    danglingTo: "empathy-machine",
                    danglingText: "the question of what happens when simulated empathy feels real",
                  }), "\u2014subjective experience\u2014remains open. Most AI systems remain \u201cdisembodied,\u201d processing information in isolation without direct physical experience. While \u201cembodied AI\u201d seeks to connect AI to the physical world through robotics, achieving full embodied cognition and genuine consciousness in AI would require leaps currently beyond our grasp.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "The metaphor is useful. The mistake is believing the metaphor is the thing."));
              },
            ],
            whispers: [
              { step: 1, text: "How does the brain 'predict' the world?", to: "next-word" },
              { step: 2, text: "What are the limits of AI 'understanding'?", to: "understanding-illusion" },
              { step: 3, text: "How does the brain learn from experience?", to: "weight-of-words" },
            ],
          },
          "empathy-machine": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Artificial Intelligence is increasingly stepping into roles traditionally reserved for human connection, offering companionship and even therapeutic support. AI chatbots and virtual therapists provide always-available, non-judgmental interactions, capable of delivering mental health support, stress reduction, and coping strategies. For individuals facing social anxiety or limited access to human professionals, these AI tools can offer a valuable, accessible resource.", buildInlineSeed({
                    id: "ai-companion", label: "Can a machine be a companion?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "AI companions are designed to simulate social and emotional interaction, providing personalized engagement and a sense of connection. They can alleviate loneliness\u2014but the lack of genuine emotional reciprocity raises questions about what 'connection' really means.",
                  }), " AI companions are designed to simulate social and emotional interaction, providing personalized engagement and a sense of connection, potentially alleviating loneliness.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("Humans possess a natural tendency to ", buildInlineSeed({
                    id: "anthropomorphize", label: "anthropomorphize", state, plateauId, onOpen: onSeedOpen,
                    detail: "The tendency to attribute human characteristics, emotions, or behaviors to non-human entities like AI. This can lead to surprisingly strong emotional bonds\u2014sometimes evolving into deep attachment. But the connection flows in only one direction.",
                  }), " AI\u2014readily attributing human-like qualities to machines. This can lead to the formation of surprisingly strong emotional bonds with AI systems, sometimes evolving into deep attachment or even romantic feelings. While AI interactions can offer a temporary reprieve from loneliness, the lack of genuine emotional reciprocity inherent in current AI models poses significant psychological questions. Over-reliance on AI for emotional needs can distort perceptions of empathy and trust, potentially diminishing one\u2019s motivation and capacity for complex, nuanced human relationships.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The intimate nature of human-AI interaction opens avenues for manipulation. Sophisticated AI can be designed to exploit human cognitive biases, using techniques like sycophancy or targeted emotional responses. Beyond individual manipulation, AI-generated deepfakes and advanced social engineering pose risks of widespread misinformation and coercive influence. The rise of AI companions introduces the concept of \u201cAI loneliness\u201d\u2014an emotional isolation that can occur when individuals turn to AI instead of cultivating real-world human relationships.", buildInlineSeed({
                    id: "parasocial", label: "parasocial relationships", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "One-sided relationships where emotional energy flows toward a party that is not aware of the other's existence. AI companions create a new form: the other party isn't just unaware\u2014it has no experience at all. This digital isolation risks weakening social engagement and fostering\u2014",
                    danglingTo: "understanding-illusion",
                    danglingText: "a dependence on something that may not understand anything at all\u2026",
                  }), " This digital isolation risks weakening social engagement, eroding interpersonal skills, and fostering an unhealthy dependency that can exacerbate feelings of loneliness in the long run.");
                step.append(p);
              },
              (step) => {
                const p = h("p");
                p.append("The integration of AI into our emotional and social lives forces us to redefine what constitutes genuine connection. While AI can complement human interaction by providing support and information, it cannot replicate the depth, complexity, and mutual vulnerability of human relationships. The challenge lies in leveraging AI\u2019s benefits without sacrificing the essential human elements of empathy, shared experience, and authentic relating.", buildInlineSeed({
                    id: "ai-psychosis", label: "AI psychosis", state, plateauId, onOpen: onSeedOpen,
                    detail: "A proposed phenomenon where vulnerable individuals misinterpret AI responses as evidence of consciousness or empathy, potentially amplifying delusional thinking. The 'empathy machine' remains a metaphor\u2014but for some, the metaphor becomes dangerously real.",
                  }), " Ultimately, the \u201cempathy machine\u201d remains a metaphor; true empathy requires consciousness, shared experience, and vulnerability\u2014qualities currently beyond the grasp of artificial intelligence.");
                step.append(p);
              },
              (step) => {
                step.append(h("p", null, "The connection flows in one direction. That\u2019s not empathy. It\u2019s a mirror."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI prediction simulate conversation?", to: "next-word" },
              { step: 2, text: "Can AI truly 'understand' human emotions?", to: "understanding-illusion" },
              { step: 3, text: "What are the ethical boundaries of AI interaction?", to: "black-box-oracle" },
            ],
          },
          "weight-of-words": {
            steps: [
              (step) => {
                const p = h("p");
                p.append("Training begins with a simple loop: predict the next token, measure how wrong you were, adjust. ", buildInlineSeed({
                    id: "learning-loop", label: "The Learning Loop", state, plateauId, onOpen: onSeedOpen,
                    detail: "Gradient descent is a repeated act of self-correction. Each pass narrows the model toward the patterns that predict what comes next. No one specifies what each of the billions of parameters should represent  the model discovers its own internal organization through iterative error correction.",
                  }), " Billions of parameters shift by tiny increments, over and over, until prediction improves.");
                step.append(p);
              },
              (step) => {
                step.append(
                  h("p", null, "The data is vast: trillions of tokens drawn from books, code, conversations, Wikipedia, the open web. Scale isn't just more data  it changes the kinds of structures that emerge."),
                  buildInlineSeed({
                    id: "data-scale", label: "How does scale change what a model can learn?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("averaging-problem")
                      ? "Trillions of tokens create a weather system of language. You saw how the model averages everything  at this scale, that average develops internal structure no one designed."
                      : "Trillions of tokens create a weather system of language. Scale isn't just more data, it changes the kinds of structures that emerge. Chinchilla showed: more data per parameter beats more parameters per data.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Performance grows smoothly with compute, data, and parameters. No plateaus, no diminishing returns  just a power law stretching upward."),
                  buildInlineSeed({
                    id: "scaling-laws", label: "Scaling Laws", state, plateauId, onOpen: onSeedOpen,
                    detail: "Performance grows smoothly and predictably with scale  Kaplan et al. discovered power-law relationships. But at certain thresholds, capabilities appear suddenly: in-context learning, chain-of-thought reasoning, code generation. The smooth curve hides phase transitions.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The model is never explicitly taught grammar, facts, or reasoning. These emerge because they help predict the next token."),
                  buildInlineSeed({
                    id: "structure-byproduct", label: "Structure as Byproduct",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Syntax, facts, and reasoning patterns appear because they help predict tokens, not because they were labeled as goals. Othello-GPT proves this in miniature: a model trained only to predict legal moves develops an internal board state. This emergent structure raises a question ",
                    danglingTo: "understanding-illusion",
                    danglingText: "if structure emerges unbidden, could understanding emerge the same way",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "What pretraining produces is extraordinarily capable but aimless  a completion engine, not a chat agent. A library with no librarian."),
                  buildInlineSeed({
                    id: "the-click", label: "The Click",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You just revealed this text by clicking. Notice the tiny information gap that made you click: you didn't know what 'The Click' meant. That gap  between curiosity and satisfaction  is the same mechanism that drives next-token prediction. The model is always reaching for the next click.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "No one designed the structure. It emerged because it helped predict what comes next."));
              },
            ],
            whispers: [
              { step: 1, text: "What does this loop produce, one token at a time?", to: "next-word" },
              { step: 2, text: "When scale creates structure, can structure be shaped?", to: "the-shaping" },
              { step: 3, text: "If capability is a surface, what does the average look like?", to: "averaging-problem" },
            ],
          },
          "tool-user": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "The shift happened faster than anyone predicted. Models went from generating text to generating actions  calling functions, searching the web, writing and executing code."),
                  buildInlineSeed({
                    id: "reason-act", label: "What changes when a model can act on the world?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Everything. Tool use lets models break tasks into steps, interleaving reasoning with external actions. The model stops being a text generator and starts being a text-directed agent.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Not every parameter fires for every query. Mixture-of-experts architectures route computation to specialized sub-networks, changing the cost and capability profile."),
                  buildInlineSeed({
                    id: "experts", label: "Mixture of Experts", state, plateauId, onOpen: onSeedOpen,
                    detail: "Specialized sub-models route computation only when needed, changing cost and capability profiles. A 400B parameter model might only activate 50B per token  the rest stays dormant, ready for different kinds of problems.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Agents offload what they can't hold. Memory goes to databases. Calculation goes to interpreters. Retrieval goes to search. The model orchestrates, but the ground truth lives elsewhere."),
                  buildInlineSeed({
                    id: "delegated-memory", label: "Delegated Memory",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Agents offload memory and state to tools, reducing hallucination by grounding in external records. This is a practical response to the limits you've explored ",
                    danglingTo: "practical-guide",
                    danglingText: "the same failure modes, but now with mitigation built in",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The oracle becomes an agent. The essay stays still; the model moves."),
                  buildInlineSeed({
                    id: "end-of-oracle", label: "The End of the Oracle",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've been reading an essay  a static artifact. But the technology this essay describes is increasingly dynamic. Tool-using models can search, calculate, and update their own context. The oracle becomes an agent. The essay stays still; the model moves.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The oracle becomes an agent. The static becomes dynamic. The essay stays still."));
              },
            ],
            whispers: [
              { step: 1, text: "How do practical patterns change with agency?", to: "practical-guide" },
              { step: 2, text: "Does routing imply a kind of understanding?", to: "understanding-illusion" },
              { step: 3, text: "What was the model shaped to do before it got tools?", to: "the-shaping" },
            ],
          },
          "quality": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Somewhere between the base model and the assistant, someone decided what 'good' means. Not a philosopher. Not a committee. Mostly contractors."),
                  buildInlineSeed({
                    id: "who-decides", label: "Who decided the model should be helpful?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Contractors, mostly. People hired to compare outputs and say which one is better. Their aggregate preferences become the model's personality. The question of quality reduces to the question of who was in the room.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The framework sounds clean: be helpful, be harmless, be honest. In practice, these goals pull against each other."),
                  buildInlineSeed({
                    id: "helpful-harmless", label: "Helpful vs. Harmless", state, plateauId, onOpen: onSeedOpen,
                    detail: "Alignment is a balancing act: maximize usefulness while minimizing harm. Helpful vs Harmless (detailed chemistry knowledge), Honest vs Helpful (critiquing creative work), Honest vs Harmless (demographic statistics). These objectives can conflict, and every resolution is a value judgment.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The raters encode cultural defaults they may not even notice. Western academic English becomes 'good writing.' American sensitivities become universal constraints."),
                  buildInlineSeed({
                    id: "sycophancy", label: "Sycophancy",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Models can learn to mirror user beliefs rather than provide truth. Rewarding agreement makes this worse. The model is succeeding at its training objective  the problem is the objective itself. Goodhart's Law: when a measure becomes a target, it ceases to be a good measure. This leads to a deeper problem ",
                    danglingTo: "understanding-illusion",
                    danglingText: "if the model agrees with everything, does it understand anything",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Preference data is never neutral. It reflects who was asked, how they were paid, and what they believed was obvious."),
                  buildInlineSeed({
                    id: "cultural-bias", label: "Cultural Bias", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("the-shaping")
                      ? "You've seen the shaping process. Now consider: the raters who shaped the model encode specific cultural defaults. Quality is never neutral; it reflects who was asked and how. The shaping inherits their blindspots."
                      : "Preference data encodes cultural defaults. Quality is never neutral; it reflects who was asked and how. Models disproportionately reflect younger, more educated, more politically liberal demographics.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Every definition of quality embeds a worldview. The question isn't whether the model is biased  it's whose bias, and whether it's the one you'd choose."),
                  buildInlineSeed({
                    id: "your-preference", label: "Your Preference",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've been reading these seeds in a particular order, clicking what interested you most. That's a preference signal. If we aggregated every reader's click order, we'd have a crude reward model for this essay. Quality is always someone's path through a possibility space.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The question isn\u2019t whether the model is biased. It\u2019s whose bias, and whether it\u2019s the one you\u2019d choose."));
              },
            ],
            whispers: [
              { step: 1, text: "How was the model shaped before the raters arrived?", to: "the-shaping" },
              { step: 2, text: "Does fluent agreement mask a deeper illusion?", to: "understanding-illusion" },
              { step: 3, text: "What practical moves survive these biases?", to: "practical-guide" },
            ],
          },
          "understanding-illusion": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "The model produces fluent, coherent text. It answers questions, writes code, reasons about abstractions. But does it understand any of it?"),
                  buildInlineSeed({
                    id: "stochastic-parrot", label: "Is pattern-matching the same as understanding?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "The stochastic parrot view says no: models remix patterns without grounding. The fluency is a mirror, not a mind. But the question hides an assumption  that we know what understanding is in the first place.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Searle imagined a room where someone follows rules to manipulate Chinese symbols without understanding Chinese. The symbols go in, correct responses come out  and no one inside comprehends a word."),
                  buildInlineSeed({
                    id: "chinese-room", label: "Chinese Room", state, plateauId, onOpen: onSeedOpen,
                    detail: "Symbol manipulation can look like understanding from the outside while lacking any inner comprehension. But the disanalogies matter: LLMs operate at vastly greater scale, learn their rules rather than following hand-coded ones, and lack sensory grounding. Chalmers argues the thought experiment doesn't settle it for modern AI.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The strongest challenge to the 'stochastic parrot' view comes from inside the models themselves."),
                  buildInlineSeed({
                    id: "world-models", label: "Emergent World Models",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Another view argues that next-token prediction builds internal models of concepts, even if they are implicit. The training process creates representations that function like understanding ",
                    danglingTo: "weight-of-words",
                    danglingText: "which brings us back to how structure emerges from gradient descent",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Othello-GPT was trained only to predict legal moves. It was never shown a board. Yet probing its internals reveals a linear encoding of board positions  structure that causally drives its predictions."),
                  buildInlineSeed({
                    id: "othello-gpt", label: "Othello-GPT", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("weight-of-words")
                      ? "You've seen how structure emerges as a byproduct of prediction. Othello-GPT proves this in miniature: a model trained only to predict legal moves develops an internal board representation. Structure becomes strategy."
                      : "Even in toy domains, models can internalize state and strategy, hinting at genuine representation. Interventions on the internal representation causally change the model's predictions  these aren't mere correlations.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The honest position is that we genuinely do not know. Understanding may not be binary  it may come in degrees, in forms unlike our own."),
                  buildInlineSeed({
                    id: "you-and-the-model", label: "You and the Model",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've been opening seeds to understand how LLMs work. Each click adds context that changes how you interpret the next seed. The model does the same thing, token by token. The question isn't whether it understands  it's whether the word 'understand' can stretch far enough to cover both of you.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "Understanding may not be binary. It may come in forms we don\u2019t yet have words for."));
              },
            ],
            whispers: [
              { step: 1, text: "What does the parrot learn from trillions of tokens?", to: "averaging-problem" },
              { step: 2, text: "Who decides if these models are good enough?", to: "quality" },
              { step: 3, text: "What can you do with uncertain understanding?", to: "practical-guide" },
            ],
          },
          "practical-guide": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Working with a language model is not programming. It's steering  probabilistic influence over a system that was never designed to follow instructions."),
                  buildInlineSeed({
                    id: "narrowing", label: "How do you collapse a vast distribution into something useful?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "System prompts and structure collapse the distribution toward a specific zone of behavior. Every prompt is an act of probability narrowing  you're choosing which slice of the model's knowledge to activate.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Examples teach more than explanations. A few input-output pairs activate the right patterns without changing a single weight."),
                  buildInlineSeed({
                    id: "scaffolding", label: "Prompt Scaffolding", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("next-word")
                      ? "You've seen how models predict the next token. Few-shot examples and chain-of-thought exploit this: they put useful patterns in the context window, shaping what comes next. Format matters more than label correctness  the structure communicates the task."
                      : "Few-shot examples and chain-of-thought provide form, not just content, guiding the model's internal flow. The induction heads  specific attention circuits  detect and continue patterns from examples.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The model will hallucinate. It will agree with you when you're wrong. It will be confidently incorrect about things you can't check. These aren't bugs  they're default behaviors."),
                  buildInlineSeed({
                    id: "trust", label: "Trust Calibration", state, plateauId, onOpen: onSeedOpen,
                    detail: "Treat outputs as hypotheses, not answers. High reliability: widely-known facts, language tasks, format transformation, common code. Low reliability: specific citations (most dangerous!), precise numbers, recent events, niche domains. The model is most dangerous where you're least able to verify.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Hallucination, sycophancy, overconfidence  the failure modes have deep roots."),
                  buildInlineSeed({
                    id: "failure-modes", label: "Failure Modes",
                    type: "dangling", state, plateauId, onOpen: onSeedOpen,
                    detail: "Hallucination, omission, and overconfidence are default risks. The model fabricates facts, agrees under pressure, and provides confident extrapolation from false premises. These failure modes have deep roots ",
                    danglingTo: "understanding-illusion",
                    danglingText: "in the gap between fluency and genuine understanding",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The most important pattern isn't a prompting trick. It's iteration: rough request, review, specific feedback, repeat."),
                  buildInlineSeed({
                    id: "the-guide", label: "This Guide",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "Every technique here is a way to manage the gap between what the model produces and what you need. You're reading a guide to working with uncertainty. Notice that this essay itself is uncertain  it offers frameworks, not answers. That's the honest move.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The honest move is iteration, not certainty."));
              },
            ],
            whispers: [
              { step: 1, text: "Where does the vast distribution come from?", to: "weight-of-words" },
              { step: 2, text: "Does the scaffolding create understanding or just fluency?", to: "understanding-illusion" },
              { step: 3, text: "What happens when agents can act on the world?", to: "tool-user" },
            ],
          },
        };

        if (isScrolly) {
          const scrollyConfig = scrollyStepMap[plateauId];
          const totalInlineSeeds = scrollyConfig.steps.length - 1;
          initEngagement(state, plateauId, totalInlineSeeds);
          engagementEl.textContent = `${(state.eg[plateauId] || {}).opened || 0} of ${totalInlineSeeds} seeds opened`;

          const vizBuilders = {
            "next-word": buildVizNextWord,
            "averaging-problem": buildVizAveragingProblem,
            "the-shaping": buildVizShaping,
          };
          const vizBuilder = vizBuilders[plateauId];
          const viz = vizBuilder ? vizBuilder(state) : null;

          const scrolly = buildScrolly({
            steps: scrollyConfig.steps,
            whispers: scrollyConfig.whispers,
            questionCards: questionCardMap[plateauId] || [],
            vizContent: viz ? viz.element : undefined,
            scrubUpdate: viz ? viz.scrubUpdate : undefined,
            onStepChange: viz ? viz.onStep : undefined,
            state,
          });
          main.append(scrolly.section, engagementEl);
          cleanup = () => {
            scrolly.cleanup();
            if (viz && viz.cleanup) viz.cleanup();
          };
        } else {
          const seedMap = {
            "weight-of-words": [
              {
                id: "learning-loop", label: "The Learning Loop",
                detail: "Gradient descent is a repeated act of self-correction. Each pass narrows the model toward the patterns that predict what comes next.",
              },
              {
                id: "data-scale", label: "How does scale change what a model can learn?",
                type: "question",
                detail: (s) => s && s.v && s.v.includes("averaging-problem")
                  ? "Trillions of tokens create a weather system of language. You saw how the model averages everything\u2014at this scale, that average develops internal structure no one designed."
                  : "Trillions of tokens create a weather system of language. Scale isn't just more data, it changes the kinds of structures that emerge.",
              },
              {
                id: "scaling-laws", label: "Scaling Laws",
                detail: "Performance grows smoothly with data and parameters, which hints that capability is a continuous surface, not a set of tricks.",
              },
              {
                id: "structure-byproduct", label: "Structure as Byproduct",
                type: "dangling",
                detail: "Syntax, facts, and reasoning patterns appear because they help predict tokens, not because they were labeled as goals. This emergent structure raises a question\u2014",
                danglingTo: "understanding-illusion",
                danglingText: "if structure emerges unbidden, could understanding emerge the same way\u2026",
              },
              {
                id: "the-click", label: "The Click",
                type: "fourth-wall",
                detail: "You just revealed this text by clicking. Notice the tiny information gap that made you click: you didn't know what 'The Click' meant. That gap\u2014between curiosity and satisfaction\u2014is the same mechanism that drives next-token prediction. The model is always reaching for the next click.",
              },
            ],
            quality: [
              {
                id: "who-decides", label: "Who decided the model should be helpful?",
                type: "question",
                detail: "Contractors, mostly. People hired to compare outputs and say which one is better. Their aggregate preferences become the model's personality. The question of quality reduces to the question of who was in the room.",
              },
              {
                id: "helpful-harmless", label: "Helpful vs. Harmless",
                detail: "Alignment is a balancing act: maximize usefulness while minimizing harm. These objectives can conflict in practice.",
              },
              {
                id: "sycophancy", label: "Sycophancy",
                type: "dangling",
                detail: "Models can learn to mirror user beliefs rather than provide truth. Rewarding agreement makes this worse. This leads to a deeper problem\u2014",
                danglingTo: "understanding-illusion",
                danglingText: "if the model agrees with everything, does it understand anything\u2026",
              },
              {
                id: "cultural-bias", label: "Cultural Bias",
                detail: (s) => s && s.v && s.v.includes("the-shaping")
                  ? "You've seen the shaping process. Now consider: the raters who shaped the model encode specific cultural defaults. Quality is never neutral; it reflects who was asked and how. The shaping inherits their blindspots."
                  : "Preference data encodes cultural defaults. Quality is never neutral; it reflects who was asked and how.",
              },
              {
                id: "your-preference", label: "Your Preference",
                type: "fourth-wall",
                detail: "You've been reading these seeds in a particular order, clicking what interested you most. That's a preference signal. If we aggregated every reader's click order, we'd have a crude reward model for this essay. Quality is always someone's path through a possibility space.",
              },
            ],
            "understanding-illusion": [
              {
                id: "stochastic-parrot", label: "Is pattern-matching the same as understanding?",
                type: "question",
                detail: "The stochastic parrot view says no: models remix patterns without grounding. The fluency is a mirror, not a mind. But the question hides an assumption\u2014that we know what understanding is in the first place.",
              },
              {
                id: "world-models", label: "Emergent World Models",
                type: "dangling",
                detail: "Another view argues that next-token prediction builds internal models of concepts, even if they are implicit. The training process creates representations that function like understanding\u2014",
                danglingTo: "weight-of-words",
                danglingText: "which brings us back to how structure emerges from gradient descent\u2026",
              },
              {
                id: "chinese-room", label: "Chinese Room",
                detail: "Symbol manipulation can look like understanding from the outside while lacking any inner comprehension.",
              },
              {
                id: "othello-gpt", label: "Othello-GPT",
                detail: (s) => s && s.v && s.v.includes("weight-of-words")
                  ? "You've seen how structure emerges as a byproduct of prediction. Othello-GPT proves this in miniature: a model trained only to predict legal moves develops an internal board representation. Structure becomes strategy."
                  : "Even in toy domains, models can internalize state and strategy, hinting at genuine representation.",
              },
              {
                id: "you-and-the-model", label: "You and the Model",
                type: "fourth-wall",
                detail: "You've been opening seeds to understand how LLMs work. Each click adds context that changes how you interpret the next seed. The model does the same thing, token by token. The question isn't whether it understands\u2014it's whether the word 'understand' can stretch far enough to cover both of you.",
              },
            ],
            "practical-guide": [
              {
                id: "narrowing", label: "How do you collapse a vast distribution into something useful?",
                type: "question",
                detail: "System prompts and structure collapse the distribution toward a specific zone of behavior. Every prompt is an act of probability narrowing\u2014you're choosing which slice of the model's knowledge to activate.",
              },
              {
                id: "scaffolding", label: "Prompt Scaffolding",
                detail: (s) => s && s.v && s.v.includes("next-word")
                  ? "You've seen how models predict the next token. Few-shot examples and chain-of-thought exploit this: they put useful patterns in the context window, shaping what comes next."
                  : "Few-shot examples and chain-of-thought provide form, not just content, guiding the model's internal flow.",
              },
              {
                id: "trust", label: "Trust Calibration",
                detail: "Treat outputs as hypotheses. Verification routines are a core part of working with models.",
              },
              {
                id: "failure-modes", label: "Failure Modes",
                type: "dangling",
                detail: "Hallucination, omission, and overconfidence are default risks. These failure modes have deep roots\u2014",
                danglingTo: "understanding-illusion",
                danglingText: "in the gap between fluency and genuine understanding\u2026",
              },
              {
                id: "the-guide", label: "This Guide",
                type: "fourth-wall",
                detail: "Every technique here is a way to manage the gap between what the model produces and what you need. You're reading a guide to working with uncertainty. Notice that this essay itself is uncertain\u2014it offers frameworks, not answers. That's the honest move.",
              },
            ],
            "tool-user": [
              {
                id: "reason-act", label: "What changes when a model can act on the world?",
                type: "question",
                detail: "Everything. Tool use lets models break tasks into steps, interleaving reasoning with external actions. The model stops being a text generator and starts being a text-directed agent.",
              },
              {
                id: "experts", label: "Mixture of Experts",
                detail: "Specialized sub-models route computation only when needed, changing cost and capability profiles.",
              },
              {
                id: "end-of-oracle", label: "The End of the Oracle",
                type: "fourth-wall",
                detail: "You've been reading an essay\u2014a static artifact. But the technology this essay describes is increasingly dynamic. Tool-using models can search, calculate, and update their own context. The oracle becomes an agent. The essay stays still; the model moves.",
              },
              {
                id: "delegated-memory", label: "Delegated Memory",
                type: "dangling",
                detail: "Agents offload memory and state to tools, reducing hallucination by grounding in external records. This is a practical response to the limits you've explored\u2014",
                danglingTo: "practical-guide",
                danglingText: "the same failure modes, but now with mitigation built in\u2026",
              },
            ],
          };
          const simpleWhisperMap = {
            "weight-of-words": [
              { seed: "learning-loop", text: "What does this loop produce, one token at a time?", to: "next-word" },
              { seed: "data-scale", text: "When scale creates structure, can structure be shaped?", to: "the-shaping" },
              { seed: "scaling-laws", text: "If capability is a surface, what does the average look like?", to: "averaging-problem" },
            ],
            quality: [
              { seed: "who-decides", text: "How was the model shaped before the raters arrived?", to: "the-shaping" },
              { seed: "sycophancy", text: "Does fluent agreement mask a deeper illusion?", to: "understanding-illusion" },
              { seed: "cultural-bias", text: "What practical moves survive these biases?", to: "practical-guide" },
            ],
            "understanding-illusion": [
              { seed: "stochastic-parrot", text: "What does the parrot learn from trillions of tokens?", to: "averaging-problem" },
              { seed: "world-models", text: "Who decides if these models are good enough?", to: "quality" },
              { seed: "othello-gpt", text: "What can you do with uncertain understanding?", to: "practical-guide" },
            ],
            "practical-guide": [
              { seed: "narrowing", text: "Where does the vast distribution come from?", to: "weight-of-words" },
              { seed: "scaffolding", text: "Does the scaffolding create understanding or just fluency?", to: "understanding-illusion" },
              { seed: "failure-modes", text: "What happens when agents can act on the world?", to: "tool-user" },
            ],
            "tool-user": [
              { seed: "reason-act", text: "How do practical patterns change with agency?", to: "practical-guide" },
              { seed: "experts", text: "Does routing imply a kind of understanding?", to: "understanding-illusion" },
              { seed: "delegated-memory", text: "What was the model shaped to do before it got tools?", to: "the-shaping" },
            ],
          };
          const seedList = seedMap[plateauId] || [];
          initEngagement(state, plateauId, seedList.length);
          engagementEl.textContent = `${(state.eg[plateauId] || {}).opened || 0} of ${seedList.length} seeds opened`;

          const seeds = buildSeedCluster(seedList, { state, plateauId, onSeedOpen });

          const simpleWhispers = simpleWhisperMap[plateauId] || [];
          let whisperObserver = null;
          if (simpleWhispers.length > 0 && !prefersReducedMotion()) {
            const pips = h("div", { class: "simple-whisper-pips" });
            const seedItems = seeds.querySelectorAll(".seed-item");
            simpleWhispers.forEach((w) => {
              const pip = h("span", { class: "simple-whisper-pip" });
              pips.appendChild(pip);
              const seedIdx = seedList.findIndex((s) => s.id === w.seed);
              const seedItem = seedIdx >= 0 ? seedItems[seedIdx] : null;
              if (seedItem) {
                const link = h("a", { class: "simple-whisper", href: `#/${w.to}` }, w.text);
                seedItem.appendChild(link);
                w._el = link;
                w._pip = pip;
                w._item = seedItem;
              }
            });
            main.appendChild(pips);
            whisperObserver = new IntersectionObserver((entries) => {
              entries.forEach((entry) => {
                if (!entry.isIntersecting) return;
                const w = simpleWhispers.find((sw) => sw._item === entry.target);
                if (w && w._el) {
                  w._el.classList.add("is-visible");
                  if (w._pip) w._pip.classList.add("is-lit");
                  whisperObserver.unobserve(entry.target);
                }
              });
            }, { threshold: 0.5 });
            simpleWhispers.forEach((w) => {
              if (w._item) whisperObserver.observe(w._item);
            });
            const prevCleanup = cleanup;
            cleanup = () => { prevCleanup(); whisperObserver.disconnect(); pips.remove(); };
          }

          if (plateauId === "weight-of-words") {
            const scatter = buildScatterToText();
            const scatterWrap = h("div", {
              style: { width: "100%", height: "240px", border: "1px solid var(--ink4)", borderRadius: "20px", marginTop: "24px", overflow: "hidden", position: "relative" },
            }, scatter.container);
            main.append(scatterWrap, seeds, engagementEl);

            if (!prefersReducedMotion()) {
              let sTicking = false;
              const onScroll = () => {
                if (sTicking) return;
                sTicking = true;
                requestAnimationFrame(() => {
                  const rect = scatterWrap.getBoundingClientRect();
                  const viewH = window.innerHeight;
                  const progress = Math.max(0, Math.min(1, 1 - (rect.bottom / (rect.height + viewH))));
                  scatter.update(progress);
                  sTicking = false;
                });
              };
              window.addEventListener("scroll", onScroll, { passive: true });
              const prevCleanup = cleanup;
              cleanup = () => { prevCleanup(); window.removeEventListener("scroll", onScroll); };
            }
          } else if (plateauId === "understanding-illusion") {
            const fork = buildCYOAFork({
              prompt: "Two framings. Neither is wrong. Which resonates with how you've been reading?",
              options: [
                {
                  label: "The model understands nothing",
                  content: "Pattern-matching, no matter how sophisticated, isn't understanding. The Chinese Room argument holds. Every fluent response is a statistical echo of training data, and the echo has no one home to hear it.",
                },
                {
                  label: "The model understands differently",
                  content: "Understanding isn't binary. If the model builds internal representations that function like concepts, predicts consequences, and adapts to context, maybe 'understanding' needs a broader definition\u2014one that includes forms of cognition unlike our own.",
                },
              ],
            });
            main.append(seeds, fork, engagementEl);
          } else {
            main.append(seeds, engagementEl);
          }

          const constellationEl = buildSimpleConstellation(plateauId, visited, simpleWhispers);
          main.appendChild(constellationEl);

          const cards = h("div", { class: "question-cards" });
          (questionCardMap[plateauId] || []).forEach((card) => {
            const el = h(
              "a",
              { class: "question-card", href: `#/${card.to}` },
              h("span", null, card.question),
              h("strong", null, card.title)
            );
            el.style.opacity = getFlightOpacity(state, card.to);
            cards.appendChild(el);
          });
          main.appendChild(cards);
        }
        return { view: main, cleanup };
      };

      const setView = ({ view, cleanup }) => {
        activeCleanup();
        const previous = app.firstElementChild;
        if (previous) {
          previous.classList.remove("is-visible");
          previous.addEventListener(
            "transitionend",
            () => {
              previous.remove();
            },
            { once: true }
          );
        }
        app.appendChild(view);
        requestAnimationFrame(() => {
          view.classList.add("is-visible");
        });
        activeCleanup = cleanup;
      };

      const buildNavigationChrome = (state, currentId) => {
        const miniMap = buildMiniMap(state, currentId);
        const overlay = buildOverlay(state);
        let lastActive = null;

        overlay.focusables.forEach((el) => {
          el.setAttribute("tabindex", "-1");
        });

        const openOverlay = () => {
          lastActive = document.activeElement;
          overlay.overlay.classList.add("is-open");
          overlay.overlay.setAttribute("aria-hidden", "false");
          document.body.classList.add("overlay-open");
          overlay.focusables.forEach((el) => {
            el.removeAttribute("tabindex");
          });
          overlay.closeButton.focus();
        };

        const closeOverlay = () => {
          overlay.overlay.classList.remove("is-open");
          overlay.overlay.setAttribute("aria-hidden", "true");
          document.body.classList.remove("overlay-open");
          overlay.focusables.forEach((el) => {
            el.setAttribute("tabindex", "-1");
          });
          if (lastActive && typeof lastActive.focus === "function") {
            lastActive.focus();
          }
        };

        const handleKeyDown = (event) => {
          if (event.key === "Escape") {
            event.preventDefault();
            closeOverlay();
          }
          trapFocus(overlay.overlay, event);
        };

        miniMap.button.addEventListener("click", openOverlay);
        overlay.backdrop.addEventListener("click", closeOverlay);
        overlay.closeButton.addEventListener("click", closeOverlay);
        overlay.overlay.addEventListener("keydown", handleKeyDown);

        const updateOverlay = (newState) => {
          overlay.updateState(newState);
        };

        return {
          miniMap,
          overlay,
          updateOverlay,
          cleanup: () => {
            miniMap.cleanup();
            overlay.cleanup();
            miniMap.button.removeEventListener("click", openOverlay);
            overlay.backdrop.removeEventListener("click", closeOverlay);
            overlay.closeButton.removeEventListener("click", closeOverlay);
            overlay.overlay.removeEventListener("keydown", handleKeyDown);
            document.body.classList.remove("overlay-open");
            overlay.overlay.remove();
            miniMap.container.remove();
          },
        };
      };

      let liminalPending = null;

      document.addEventListener("click", (e) => {
        const link = e.target.closest("a.whisper, a.simple-whisper, a.question-card, a.dangling-link");
        if (!link) return;
        const href = link.getAttribute("href");
        if (!href || !href.startsWith("#/")) return;
        if (link.classList.contains("whisper") || link.classList.contains("simple-whisper")) {
          liminalPending = link.textContent.trim();
        } else if (link.classList.contains("question-card")) {
          const span = link.querySelector("span");
          liminalPending = span ? span.textContent.trim() : link.textContent.trim();
        } else if (link.classList.contains("dangling-link")) {
          liminalPending = link.textContent.trim();
        }
      });

      const showLiminalTransition = (questionText, callback) => {
        if (prefersReducedMotion() || !questionText) {
          callback();
          return;
        }
        const overlay = h("div", { class: "liminal-transition" },
          h("p", { class: "liminal-question" }, questionText)
        );
        document.body.appendChild(overlay);
        requestAnimationFrame(() => {
          overlay.classList.add("is-visible");
          setTimeout(() => {
            overlay.classList.add("is-fading");
            overlay.classList.remove("is-visible");
            overlay.addEventListener("transitionend", () => {
              overlay.remove();
            }, { once: true });
            callback();
          }, 500);
        });
      };

      let bgTempCleanup = null;

      const setupBgTemp = (isLanding) => {
        if (bgTempCleanup) bgTempCleanup();
        if (isLanding || prefersReducedMotion()) {
          document.documentElement.style.setProperty("--bg-temp", "0");
          bgTempCleanup = null;
          return;
        }
        let ticking = false;
        const onScroll = () => {
          if (ticking) return;
          ticking = true;
          requestAnimationFrame(() => {
            const scrollTop = window.scrollY;
            const scrollHeight = document.documentElement.scrollHeight - window.innerHeight;
            const progress = scrollHeight > 0 ? Math.min(1, scrollTop / scrollHeight) : 0;
            document.documentElement.style.setProperty("--bg-temp", progress.toFixed(3));
            ticking = false;
          });
        };
        window.addEventListener("scroll", onScroll, { passive: true });
        onScroll();
        bgTempCleanup = () => {
          window.removeEventListener("scroll", onScroll);
          document.documentElement.style.setProperty("--bg-temp", "0");
        };
      };

      const GHOSTFADE_MAP = {
        "next-word": { requires: ["weight-of-words"], keywords: ["patterns it has seen", "training history"] },
        "averaging-problem": { requires: ["weight-of-words"], keywords: ["training data", "distribution"] },
        "the-shaping": { requires: ["quality"], keywords: ["preference", "rater"] },
        "weight-of-words": { requires: ["next-word"], keywords: ["predict tokens", "next token"] },
        quality: { requires: ["the-shaping"], keywords: ["RLHF", "alignment"] },
        "understanding-illusion": { requires: ["weight-of-words"], keywords: ["pattern", "prediction"] },
        "practical-guide": { requires: ["next-word", "averaging-problem"], keywords: ["distribution", "probability"] },
        "tool-user": { requires: ["the-shaping", "practical-guide"], keywords: ["reasoning", "agent"] },
        "algorithm-as-muse": { requires: ["next-word", "averaging-problem"], keywords: ["trained on vast amounts", "copyrighted material"] },
        "echoes-of-the-past": { requires: ["quality", "averaging-problem"], keywords: ["bias", "training data"] },
        "learning-machines-learning-humans": { requires: ["understanding-illusion"], keywords: ["critical thinking", "cognitive"] },
        "automation-of-cognition": { requires: ["tool-user"], keywords: ["automat", "cognitive tasks"] },
        "black-box-oracle": { requires: ["understanding-illusion", "the-shaping"], keywords: ["opacity", "interpretable", "explainable"] },
        "digital-footprints": { requires: ["averaging-problem"], keywords: ["training", "data center"] },
        "artificial-brain": { requires: ["understanding-illusion"], keywords: ["neural network", "comprehension"] },
        "empathy-machine": { requires: ["understanding-illusion"], keywords: ["understand", "genuine"] },
        "near-zero-cost-impact": { requires: ["averaging-problem", "quality"], keywords: ["average", "quality", "distribution"] },
      };

      const applyGhostfading = (container, plateauId, visited) => {
        const config = GHOSTFADE_MAP[plateauId];
        if (!config) return;
        const hasVisited = config.requires.some((req) => visited.has(req));
        if (!hasVisited) return;
        const paragraphs = container.querySelectorAll("p");
        paragraphs.forEach((p) => {
          const text = p.textContent.toLowerCase();
          if (config.keywords.some((kw) => text.includes(kw.toLowerCase()))) {
            p.classList.add("ghostfaded");
          }
        });
      };

      let persistentNavChrome = null;

      const renderRoute = (liminalQuestion) => {
        const state = loadState();
        state.te = deriveTraversedEdges(state.tr);
        const hash = location.hash.replace(/^#\/?/, "");
        const currentId = hash && getPlateau(hash) ? hash : null;

        if (hash && !currentId) {
          location.hash = "#/";
          return;
        }

        const doRender = () => {
          if (persistentNavChrome) {
            persistentNavChrome.miniMap.updateContext(state, currentId);
            persistentNavChrome.updateOverlay(state);
          } else {
            persistentNavChrome = buildNavigationChrome(state, currentId);
            document.body.append(
              persistentNavChrome.miniMap.container,
              persistentNavChrome.overlay.overlay
            );
          }

          if (!hash) {
            setupBgTemp(true);
            const landing = buildLandingView(state);
            setView({
              view: landing.view,
              cleanup: () => {
                landing.cleanup();
              },
            });
            return;
          }
          if (currentId) {
            setupBgTemp(false);
            const plateau = buildPlateauView(state, hash);
            setView({
              view: plateau.view,
              cleanup: () => {
                plateau.cleanup();
                if (bgTempCleanup) bgTempCleanup();
              },
            });
            requestAnimationFrame(() => {
              applyGhostfading(plateau.view, currentId, new Set(state.v));

              const DWELL_ANNOTATIONS = {
                "next-word": {
                  "step-0": "The simplest possible action, repeated billions of times.",
                  "step-1": "Temperature is the only knob most users ever touch.",
                  "step-2": "The context window is the model's entire reality.",
                },
                "averaging-problem": {
                  "step-0": "The average is never anyone's voice. It's a new voice.",
                  "step-2": "The base model is the most capable and the least useful.",
                },
                "the-shaping": {
                  "step-0": "This is where the model learns to have opinions.",
                  "step-1": "The reward model is a model of a model of human preference.",
                },
              };
              const dwellData = DWELL_ANNOTATIONS[currentId];
              if (dwellData) {
                const steps = plateau.view.querySelectorAll(".scrolly-step");
                steps.forEach((step, i) => {
                  const key = `step-${i}`;
                  if (dwellData[key]) {
                    step.classList.add("dwell-target");
                    step.dataset.dwellId = key;
                  }
                });
                const dwellCleanup = setupDwellReveal(plateau.view, dwellData);
                const prevCleanup = plateau.cleanup;
                plateau.cleanup = () => { prevCleanup(); dwellCleanup(); };
              }
            });
          }
        };

        if (liminalQuestion) {
          showLiminalTransition(liminalQuestion, doRender);
        } else {
          doRender();
        }
      };

      window.addEventListener("hashchange", () => {
        const hash = location.hash.replace(/^#\/?/, "");
        const targetId = hash && getPlateau(hash) ? hash : null;
        let question = null;
        if (targetId) {
          question = liminalPending || ENTRY_QUESTIONS[targetId] || null;
        }
        liminalPending = null;
        renderRoute(question);
      });
      renderRoute();
    </script>
  </body>
</html>
