<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>How LLMs Actually Work</title>
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,600;1,400&display=swap"
    />
    <style>
      :root {
        --paper: #fafaf8;
        --ink: #1a1a18;
        --ink2: #6b6b66;
        --ink3: #b8b4aa;
        --ink4: #ddd9d0;
        --seed: #edeadf;
        --seedh: #e4e0d4;
        --hl: #fff3c4;
        --acc: #4a6741;
        --paper-warm: #faf8f2;
        --bg-temp: 0;
        --t-page: 0.2s;
        --t-step: 0.4s;
        --t-whisper: 0.6s;
        --t-constellation: 0.6s;
        --t-liminal-in: 0.2s;
        --t-liminal-out: 0.2s;
        --t-dwell: 0.4s;
        --t-scatter: 0.6s;
        --t-ghostfade: 0.3s;
        --t-engagement: 0.2s;
      }

      * {
        box-sizing: border-box;
      }

      body {
        margin: 0;
        background: color-mix(in srgb, var(--paper) calc((1 - var(--bg-temp)) * 100%), var(--paper-warm));
        color: var(--ink);
        font-family: "Lora", Georgia, serif;
        font-size: 18px;
        line-height: 1.65;
      }

      a {
        color: inherit;
        text-decoration: none;
      }

      ::selection {
        background: var(--hl);
      }

      :focus-visible {
        outline: 2px solid var(--ink);
        outline-offset: 2px;
      }

      .view {
        opacity: 0;
        transition: opacity var(--t-page) ease;
      }

      .view.is-visible {
        opacity: 1;
      }

      .landing,
      .plateau {
        min-height: 100vh;
        padding: 72px 24px 96px;
      }

      .landing {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 24px;
      }

      .landing-header {
        text-align: center;
        max-width: 42rem;
      }

      .landing-header h1 {
        font-size: clamp(2.4rem, 4vw, 3.2rem);
        font-weight: 600;
        letter-spacing: -0.02em;
        margin: 0 0 0.35rem;
      }

      .landing-header .subtitle {
        font-style: italic;
        color: var(--ink2);
        margin: 0 0 1.25rem;
        font-size: 1.05rem;
      }

      .landing-header p {
        margin: 0;
        color: var(--ink);
      }

      .landing-map {
        width: min(460px, 100%);
      }

      .map-wrap {
        position: relative;
        width: 100%;
        aspect-ratio: 460 / 360;
      }

      .map-wrap canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .map-overlay {
        position: absolute;
        inset: 0;
        pointer-events: none;
      }

      .map-link {
        position: absolute;
        width: 44px;
        height: 44px;
        transform: translate(-50%, -50%);
        border-radius: 50%;
        pointer-events: auto;
      }

      .map-link:focus-visible {
        outline-offset: 4px;
      }

      .map-note {
        margin-top: 16px;
        color: var(--ink2);
        font-size: 0.95rem;
        font-style: italic;
        text-align: center;
      }

      .mini-map {
        position: fixed;
        right: 32px;
        bottom: 32px;
        width: 160px;
        height: 120px;
        border-radius: 16px;
        border: 1px solid var(--ink4);
        background: color-mix(in srgb, var(--paper) 92%, white 8%);
        box-shadow: 0 14px 30px rgba(26, 26, 24, 0.08);
        overflow: hidden;
        z-index: 20;
        transition: border-color 0.2s ease;
      }

      .mini-map canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .mini-map:hover {
        border-color: var(--ink3);
        transition: border-color 0.2s ease;
      }

      .mini-map-button {
        position: absolute;
        inset: 0;
        border: none;
        background: transparent;
        border-radius: inherit;
        cursor: pointer;
      }

      .rhizome-overlay {
        position: fixed;
        inset: 0;
        display: flex;
        align-items: center;
        justify-content: center;
        opacity: 0;
        pointer-events: none;
        transition: opacity var(--t-page) ease;
        z-index: 40;
      }

      .rhizome-overlay.is-open {
        opacity: 1;
        pointer-events: auto;
      }

      .overlay-backdrop {
        position: absolute;
        inset: 0;
        background: rgba(250, 250, 248, 0.82);
        backdrop-filter: blur(10px);
      }

      .overlay-panel {
        position: relative;
        z-index: 1;
        background: rgba(250, 250, 248, 0.96);
        border: 1px solid var(--ink4);
        border-radius: 24px;
        padding: 32px;
        box-shadow: 0 30px 80px rgba(26, 26, 24, 0.18);
      }

      .overlay-map {
        position: relative;
        width: min(90vw, 700px);
        aspect-ratio: 700 / 550;
      }

      .overlay-map canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .overlay-links {
        position: absolute;
        inset: 0;
      }

      .overlay-link {
        position: absolute;
        width: 44px;
        height: 44px;
        transform: translate(-50%, -50%);
        border-radius: 50%;
        opacity: 0;
      }

      .overlay-link:focus-visible {
        opacity: 1;
        background: rgba(74, 103, 65, 0.12);
        outline-offset: 4px;
      }

      .overlay-link:hover {
        opacity: 1;
        background: rgba(74, 103, 65, 0.08);
      }

      .overlay-close {
        position: absolute;
        top: 16px;
        right: 16px;
        border: 1px solid var(--ink4);
        background: var(--paper);
        color: var(--ink2);
        border-radius: 999px;
        padding: 0.4rem 0.9rem;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.7rem;
        letter-spacing: 0.08em;
        text-transform: uppercase;
        cursor: pointer;
      }

      body.overlay-open {
        overflow: hidden;
      }

      .plateau {
        max-width: 42rem;
        margin: 0 auto;
      }

      .entry-question {
        margin-top: 0.75rem;
        color: var(--ink2);
        font-style: italic;
      }

      .scrolly {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 0;
        margin-top: 48px;
        border-top: 1px solid var(--ink4);
      }

      .scrolly-viz {
        position: sticky;
        top: 0;
        height: 100vh;
        border-right: 1px solid var(--ink4);
        display: flex;
        align-items: center;
        justify-content: center;
        background: linear-gradient(180deg, rgba(250, 250, 248, 0.9), rgba(250, 250, 248, 0.98));
        overflow: hidden;
      }

      .viz-main {
        width: min(380px, 90%);
        min-height: 240px;
        border: 1px solid var(--ink4);
        border-radius: 20px;
        display: grid;
        place-items: center;
        color: var(--ink2);
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.9rem;
        text-transform: uppercase;
        letter-spacing: 0.08em;
        transition: opacity var(--t-constellation) ease;
      }

      .scrolly-viz.is-constellation .viz-main {
        opacity: 0.2;
      }

      .scrolly-no-viz {
        grid-template-columns: 1fr;
      }

      .scrolly-steps {
        padding: 0 36px;
      }

      .scrolly-step {
        min-height: 65vh;
        display: flex;
        align-items: center;
        color: var(--ink3);
        transition: color var(--t-step) ease;
      }

      .scrolly-step.is-active {
        color: var(--ink);
      }

      .whisper-layer {
        position: absolute;
        right: 22px;
        top: 18%;
        display: flex;
        flex-direction: column;
        gap: 12px;
        text-align: right;
        font-style: italic;
        color: var(--ink2);
        font-size: 0.82rem;
      }

      .whisper {
        opacity: 0;
        transform: translateX(8px);
        transition: opacity var(--t-whisper) ease, transform var(--t-whisper) ease;
      }

      .whisper.is-visible {
        opacity: 1;
        transform: translateX(0);
      }

      .trace-pips {
        position: absolute;
        right: 12px;
        top: 18%;
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .trace-pip {
        width: 6px;
        height: 6px;
        border-radius: 999px;
        background: var(--ink4);
      }

      .trace-pip.is-lit {
        background: var(--ink);
      }

      .constellation {
        position: absolute;
        inset: 0;
        display: grid;
        place-items: center;
        opacity: 0;
        transition: opacity var(--t-constellation) ease;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        color: var(--ink2);
        letter-spacing: 0.08em;
        text-transform: uppercase;
        font-size: 0.8rem;
      }

      .constellation.is-visible {
        opacity: 1;
      }

      .question-cards {
        margin-top: 32px;
        display: grid;
        gap: 14px;
      }

      .question-card {
        border: 1px solid var(--ink4);
        border-radius: 14px;
        padding: 14px 16px;
        display: flex;
        flex-direction: column;
        gap: 6px;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        color: var(--ink2);
        transition: border-color 0.2s ease, transform 0.2s ease;
      }

      .question-card:hover {
        border-color: var(--ink2);
        transform: translateY(-1px);
      }

      .question-card span {
        font-style: italic;
        color: var(--ink);
        font-family: "Lora", Georgia, serif;
      }

      .seed-field {
        margin-top: 32px;
        display: flex;
        flex-direction: column;
        gap: 18px;
      }

      .seed-item {
        border: 1px solid var(--ink4);
        border-radius: 16px;
        padding: 14px 16px;
        background: rgba(237, 234, 223, 0.4);
      }

      .seed-button {
        border: none;
        background: var(--seed);
        color: var(--ink);
        font-family: "Lora", Georgia, serif;
        font-size: 1rem;
        padding: 6px 10px;
        border-radius: 999px;
        border-bottom: 1px dotted var(--ink2);
        cursor: pointer;
      }

      .seed-button:hover {
        background: var(--seedh);
      }

      .seed-growth {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.35s ease;
      }

      .seed-growth.is-open {
        max-height: 220px;
        overflow-y: auto;
      }

      .seed-growth-inner {
        margin-top: 12px;
        padding-left: 14px;
        border-left: 2px solid var(--ink4);
        color: var(--ink2);
      }

      .inline-seed {
        display: inline;
      }

      .inline-seed-button {
        border: none;
        background: var(--seed);
        color: inherit;
        font: inherit;
        padding: 0 4px;
        border-radius: 6px;
        border-bottom: 1px dotted var(--ink2);
        cursor: pointer;
      }

      .inline-seed-button:hover {
        background: var(--seedh);
      }

      .inline-seed-growth {
        display: block;
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.35s ease;
      }

      .inline-seed-growth.is-open {
        max-height: 180px;
        overflow-y: auto;
      }

      .inline-seed-content {
        display: block;
        margin-top: 10px;
        padding-left: 12px;
        border-left: 2px solid var(--ink4);
        color: var(--ink2);
      }

      .plateau .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.4rem;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.85rem;
        letter-spacing: 0.02em;
        text-transform: uppercase;
        color: var(--ink2);
      }

      .plateau h1 {
        margin-top: 1.5rem;
        font-size: 2.2rem;
      }

      .visually-hidden {
        position: absolute;
        width: 1px;
        height: 1px;
        margin: -1px;
        border: 0;
        padding: 0;
        white-space: nowrap;
        clip-path: inset(100%);
        clip: rect(0 0 0 0);
        overflow: hidden;
      }

      /* Question-seed: italic label with dotted underline */
      .inline-seed-button[data-seed-type="question"] {
        font-style: italic;
        border-bottom-style: dotted;
      }

      /* Seed growth for question-seeds */
      .seed-button[data-seed-type="question"] {
        font-style: italic;
        border-bottom-style: dotted;
      }

      /* Dangling reference trailing link */
      .dangling-link {
        font-style: italic;
        color: var(--ink2);
        border-bottom: 1px dotted var(--ink2);
        cursor: pointer;
      }

      .dangling-link:hover {
        color: var(--ink);
      }

      /* Liminal transition overlay */
      .liminal-transition {
        position: fixed;
        inset: 0;
        display: flex;
        align-items: center;
        justify-content: center;
        z-index: 50;
        opacity: 0;
        background: rgba(250, 250, 248, 0.88);
        backdrop-filter: blur(12px);
        transition: opacity var(--t-liminal-in) ease;
        pointer-events: none;
      }

      .liminal-transition.is-visible {
        opacity: 1;
      }

      .liminal-transition.is-fading {
        opacity: 0;
        transition: opacity var(--t-liminal-out) ease;
      }

      .liminal-question {
        font-style: italic;
        color: var(--ink);
        font-size: 1.1rem;
        max-width: 32rem;
        text-align: center;
        line-height: 1.7;
        padding: 0 24px;
      }

      /* Ghostfading visited concepts */
      .ghostfaded {
        opacity: 0.85;
        transition: opacity var(--t-ghostfade) ease;
      }

      .ghostfaded .inline-seed-button,
      .ghostfaded .seed-button,
      .ghostfaded a {
        opacity: 1;
      }

      /* Engagement state counter */
      .engagement-state {
        color: var(--ink3);
        font-size: 0.72rem;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        margin-top: 16px;
        opacity: 1;
        transition: opacity var(--t-engagement) ease;
      }

      /* Dwell-reveal annotations */
      .dwell-annotation {
        position: absolute;
        right: -180px;
        top: 0;
        width: 160px;
        max-width: calc(100vw - 100%);
        font-style: italic;
        color: var(--ink3);
        font-size: 0.78rem;
        line-height: 1.5;
        opacity: 0;
        transition: opacity var(--t-dwell) ease;
      }

      .dwell-annotation.is-revealed {
        opacity: 1;
      }

      .dwell-target {
        position: relative;
      }

      /* Author marginalia */
      .plateau-with-marginalia {
        max-width: 54rem;
        display: grid;
        grid-template-columns: 1fr 180px;
        gap: 0 32px;
      }

      .plateau-with-marginalia > * {
        grid-column: 1;
      }

      .marginalia {
        grid-column: 2;
        font-style: italic;
        color: var(--ink3);
        font-size: 0.78rem;
        line-height: 1.5;
        align-self: start;
        padding-top: 4px;
      }

      /* Cross-plateau retrieval moment */
      .retrieval-moment {
        background: var(--seed);
        color: var(--ink2);
        border-top: 2px solid var(--ink4);
        border-radius: 0 0 12px 12px;
        padding: 14px 18px;
        margin-bottom: 24px;
        font-size: 0.92rem;
        line-height: 1.6;
        display: flex;
        align-items: flex-start;
        gap: 12px;
        opacity: 1;
        transition: opacity 0.3s ease;
      }

      .retrieval-moment.is-dismissed {
        opacity: 0;
        pointer-events: none;
      }

      .retrieval-close {
        border: 1px solid var(--ink4);
        background: transparent;
        color: var(--ink3);
        border-radius: 999px;
        width: 24px;
        height: 24px;
        font-size: 0.7rem;
        cursor: pointer;
        flex-shrink: 0;
        display: grid;
        place-items: center;
        font-family: system-ui, sans-serif;
      }

      .retrieval-close:hover {
        color: var(--ink2);
        border-color: var(--ink2);
      }

      /* Micro-CYOA forks */
      .cyoa-fork {
        margin-top: 24px;
        display: flex;
        flex-direction: column;
        gap: 10px;
      }

      .cyoa-option {
        border: 1px solid var(--ink4);
        border-radius: 14px;
        padding: 14px 18px;
        background: transparent;
        font: inherit;
        text-align: left;
        cursor: pointer;
        color: var(--ink2);
        opacity: 0.7;
        transition: opacity 0.2s ease, border-color 0.2s ease;
      }

      .cyoa-option:hover {
        border-color: var(--ink2);
      }

      .cyoa-option.is-chosen {
        opacity: 1;
        color: var(--ink);
        border-color: var(--ink);
      }

      .cyoa-option.is-unchosen {
        opacity: 0.7;
        color: var(--ink2);
      }

      .cyoa-option:not(.is-chosen):not(.is-unchosen) {
        opacity: 1;
        color: var(--ink);
      }

      .cyoa-expansion {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.35s ease;
      }

      .cyoa-expansion.is-open {
        max-height: 300px;
        overflow-y: auto;
      }

      .cyoa-expansion-inner {
        margin-top: 10px;
        padding-left: 14px;
        border-left: 2px solid var(--ink4);
        color: var(--ink2);
      }

      /* Scatter-to-text */
      .scatter-container {
        position: relative;
        width: 100%;
        height: 100%;
        overflow: hidden;
      }

      .scatter-word {
        position: absolute;
        font-family: system-ui, -apple-system, "Segoe UI", sans-serif;
        font-size: 0.85rem;
        font-weight: 600;
        color: var(--ink2);
        text-transform: uppercase;
        letter-spacing: 0.06em;
        transition: transform var(--t-scatter) ease;
        white-space: nowrap;
      }

      @media (max-width: 600px) {
        .landing,
        .plateau {
          padding-top: 56px;
        }

        .landing-header h1 {
          font-size: 2.2rem;
        }
      }

      @media (max-width: 840px) {
        .scrolly {
          grid-template-columns: 1fr;
        }

        .scrolly-viz {
          height: 42vh;
          border-right: none;
          border-bottom: 1px solid var(--ink4);
        }

        .scrolly-steps {
          padding: 0 20px;
        }

        .plateau-with-marginalia {
          grid-template-columns: 1fr;
        }

        .marginalia {
          grid-column: 1;
          padding-left: 24px;
          margin-top: -8px;
          margin-bottom: 12px;
        }

        .dwell-annotation {
          position: static;
          width: auto;
          margin-top: 8px;
          padding-left: 12px;
          border-left: 2px solid var(--ink4);
        }
      }

      @media (max-width: 480px) {
        .mini-map {
          width: 44px;
          height: 44px;
          border-radius: 50%;
          right: 20px;
          bottom: 20px;
        }

        .scrolly-viz {
          height: 38vh;
        }

        .whisper-layer,
        .trace-pips {
          font-size: 0.75rem;
          position: static;
          flex-direction: row;
          flex-wrap: wrap;
          gap: 8px;
          padding: 8px 20px;
          border-bottom: 1px solid var(--ink4);
        }

        .whisper {
          opacity: 0.7;
          transform: none;
        }

        .whisper.is-visible {
          opacity: 1;
        }

        .trace-pips {
          display: none;
        }

        .dwell-annotation {
          position: static;
          width: auto;
          margin-top: 8px;
          padding-left: 12px;
          border-left: 2px solid var(--ink4);
        }
      }

      @media (prefers-reduced-motion: reduce) {
        :root {
          --t-page: 0s;
          --t-step: 0s;
          --t-whisper: 0s;
          --t-constellation: 0s;
          --t-liminal-in: 0s;
          --t-liminal-out: 0s;
          --t-dwell: 0s;
          --t-scatter: 0s;
          --t-ghostfade: 0s;
          --t-engagement: 0s;
          --bg-temp: 0 !important;
        }

        *,
        *::before,
        *::after {
          transition-duration: 0s !important;
          animation-duration: 0s !important;
        }
      }
    </style>
  </head>
  <body>
    <div id="app"></div>
    <script>
      const GRAPH = {
        nodes: [
          { id: "next-word", title: "The Next Word", label: "Next Word", shortQ: "What does it do when it talks?", x: 0.42, y: 0.06 },
          { id: "weight-of-words", title: "The Weight of Words", label: "Weight", shortQ: "How does it learn from words?", x: 0.28, y: 0.18 },
          { id: "algorithm-as-muse", title: "The Algorithm as Muse", label: "Muse", shortQ: "When AI creates art, who's the artist?", x: 0.68, y: 0.12 },
          { id: "averaging-problem", title: "The Averaging Problem", label: "Averaging", shortQ: "Best essay or average essay?", x: 0.55, y: 0.22 },
          { id: "the-shaping", title: "The Shaping", label: "Shaping", shortQ: "Autocomplete to assistant?", x: 0.15, y: 0.34 },
          { id: "understanding-illusion", title: "The Understanding Illusion", label: "Understanding", shortQ: "Does it understand?", x: 0.85, y: 0.28 },
          { id: "learning-machines-learning-humans", title: "Learning Machines, Learning Humans", label: "Learning AI", shortQ: "What happens when AI has all answers?", x: 0.05, y: 0.44 },
          { id: "echoes-of-the-past", title: "Echoes of the Past", label: "Echoes", shortQ: "What if AI reads history with bias?", x: 0.92, y: 0.42 },
          { id: "tool-user", title: "The Tool-User", label: "Tool-User", shortQ: "What if it can use tools?", x: 0.30, y: 0.56 },
          { id: "quality", title: "What Is Quality?", label: "Quality", shortQ: "Who decides what's good?", x: 0.72, y: 0.48 },
          { id: "black-box-oracle", title: "The Black Box Oracle", label: "Black Box", shortQ: "Trust a decision you can't explain?", x: 0.08, y: 0.55 },
          { id: "near-zero-cost-impact", title: "The Near-Zero Cost Impact", label: "Near-Zero", shortQ: "When production cost approaches zero?", x: 0.52, y: 0.62 },
          { id: "practical-guide", title: "The Field Guide", label: "Field Guide", shortQ: "What do I actually do?", x: 0.38, y: 0.74 },
          { id: "automation-of-cognition", title: "The Automation of Cognition", label: "Automation", shortQ: "When machines do the thinking?", x: 0.12, y: 0.72 },
          { id: "digital-footprints", title: "Digital Footprints", label: "Footprints", shortQ: "What does AI cost the planet?", x: 0.62, y: 0.82 },
          { id: "artificial-brain", title: "The Artificial Brain", label: "Art. Brain", shortQ: "Is a neural network like a brain?", x: 0.35, y: 0.90 },
          { id: "empathy-machine", title: "The Empathy Machine?", label: "Empathy", shortQ: "Can simulated empathy help or harm?", x: 0.78, y: 0.68 },
        ],
        edges: [
          ["next-word", "averaging-problem"],
          ["next-word", "understanding-illusion"],
          ["next-word", "weight-of-words"],
          ["next-word", "learning-machines-learning-humans"],
          ["next-word", "algorithm-as-muse"],
          ["next-word", "artificial-brain"],
          ["next-word", "empathy-machine"],
          ["averaging-problem", "the-shaping"],
          ["averaging-problem", "quality"],
          ["averaging-problem", "weight-of-words"],
          ["averaging-problem", "practical-guide"],
          ["averaging-problem", "understanding-illusion"],
          ["averaging-problem", "near-zero-cost-impact"],
          ["the-shaping", "quality"],
          ["the-shaping", "practical-guide"],
          ["the-shaping", "tool-user"],
          ["the-shaping", "weight-of-words"],
          ["the-shaping", "learning-machines-learning-humans"],
          ["the-shaping", "black-box-oracle"],
          ["the-shaping", "automation-of-cognition"],
          ["the-shaping", "algorithm-as-muse"],
          ["the-shaping", "near-zero-cost-impact"],
          ["quality", "understanding-illusion"],
          ["quality", "practical-guide"],
          ["quality", "echoes-of-the-past"],
          ["quality", "black-box-oracle"],
          ["quality", "empathy-machine"],
          ["quality", "digital-footprints"],
          ["quality", "near-zero-cost-impact"],
          ["understanding-illusion", "practical-guide"],
          ["understanding-illusion", "artificial-brain"],
          ["understanding-illusion", "empathy-machine"],
          ["understanding-illusion", "echoes-of-the-past"],
          ["understanding-illusion", "tool-user"],
          ["understanding-illusion", "near-zero-cost-impact"],
          ["practical-guide", "tool-user"],
          ["practical-guide", "weight-of-words"],
          ["tool-user", "automation-of-cognition"],
          ["tool-user", "digital-footprints"],
          ["automation-of-cognition", "digital-footprints"],
          ["automation-of-cognition", "black-box-oracle"],
          ["automation-of-cognition", "near-zero-cost-impact"],
          ["black-box-oracle", "empathy-machine"],
          ["black-box-oracle", "near-zero-cost-impact"],
          ["echoes-of-the-past", "digital-footprints"],
          ["digital-footprints", "near-zero-cost-impact"],
        ],
      };

      const STORAGE_KEY = "le5";
      const app = document.querySelector("#app");
      let activeCleanup = () => {};

      const h = (tag, attrs, ...children) => {
        const el = document.createElement(tag);
        if (attrs) {
          Object.entries(attrs).forEach(([key, value]) => {
            if (value === null || value === undefined) return;
            if (key === "class") {
              el.className = value;
              return;
            }
            if (key === "style" && typeof value === "object") {
              Object.assign(el.style, value);
              return;
            }
            if (key.startsWith("on") && typeof value === "function") {
              el.addEventListener(key.slice(2), value);
              return;
            }
            el.setAttribute(key, value);
          });
        }
        children.flat().forEach((child) => {
          if (child === null || child === undefined) return;
          if (typeof child === "string") {
            el.appendChild(document.createTextNode(child));
          } else {
            el.appendChild(child);
          }
        });
        return el;
      };

      const loadState = () => {
        try {
          const raw = localStorage.getItem(STORAGE_KEY);
          if (!raw) return { v: [], tr: [], si: {}, eg: {} };
          const parsed = JSON.parse(raw);
          if (!parsed || !Array.isArray(parsed.v) || !Array.isArray(parsed.tr)) {
            throw new Error("Invalid state");
          }
          return {
            v: parsed.v,
            tr: parsed.tr,
            si: parsed.si && typeof parsed.si === "object" ? parsed.si : {},
            eg: parsed.eg && typeof parsed.eg === "object" ? parsed.eg : {},
          };
        } catch (error) {
          return { v: [], tr: [], si: {}, eg: {} };
        }
      };

      const saveState = (state) => {
        localStorage.setItem(STORAGE_KEY, JSON.stringify(state));
      };

      const recordVisit = (state, plateauId) => {
        if (!state.v.includes(plateauId)) {
          state.v.push(plateauId);
        }
        state.tr.push({ p: plateauId, t: Date.now() });
        saveState(state);
      };

      const recordSeedOpen = (state, plateauId, seedId) => {
        if (!state.si[plateauId]) state.si[plateauId] = [];
        if (state.si[plateauId].includes(seedId)) return false;
        state.si[plateauId].push(seedId);
        if (!state.eg[plateauId]) state.eg[plateauId] = { opened: 0, total: 0 };
        state.eg[plateauId].opened++;
        saveState(state);
        return true;
      };

      const initEngagement = (state, plateauId, totalSeeds) => {
        if (!state.eg[plateauId]) state.eg[plateauId] = { opened: 0, total: 0 };
        state.eg[plateauId].total = totalSeeds;
        saveState(state);
      };

      const getPlateau = (id) => GRAPH.nodes.find((node) => node.id === id);

      const scaleCanvas = (canvas, width, height) => {
        const ratio = window.devicePixelRatio || 1;
        canvas.width = Math.floor(width * ratio);
        canvas.height = Math.floor(height * ratio);
        canvas.style.width = `${width}px`;
        canvas.style.height = `${height}px`;
        return ratio;
      };

      const getNodePx = (node, width, height) => ({
        x: node.x * width,
        y: node.y * height,
      });

      const edgeKey = (a, b) => a < b ? `${a}|${b}` : `${b}|${a}`;

      const EDGE_SET = new Set(GRAPH.edges.map(([a, b]) => edgeKey(a, b)));

      const deriveTraversedEdges = (trail) => {
        const traversed = new Set();
        for (let i = 1; i < trail.length; i++) {
          const key = edgeKey(trail[i - 1].p, trail[i].p);
          if (EDGE_SET.has(key)) traversed.add(key);
        }
        return traversed;
      };

      const getTrailSegments = (trail) => {
        const seen = new Set();
        const ordered = [];
        trail.forEach((entry) => {
          if (seen.has(entry.p)) return;
          seen.add(entry.p);
          const node = getPlateau(entry.p);
          if (node) ordered.push(node);
        });
        return ordered;
      };

      const drawGraph = ({
        canvas,
        width,
        height,
        visited,
        activeId,
        highlightIds,
        edgeFilter,
        showLabels,
        showTrail,
        trailNodes,
        hoveredId,
        curvedEdges,
        softenUnvisited,
        activeGlow,
        breatheAlpha,
        traversedEdges,
      }) => {
        const ctx = canvas.getContext("2d");
        if (!ctx) return;
        const ratio = scaleCanvas(canvas, width, height);
        ctx.setTransform(ratio, 0, 0, ratio, 0, 0);
        ctx.clearRect(0, 0, width, height);

        const styles = getComputedStyle(document.documentElement);
        const ink = styles.getPropertyValue("--ink").trim();
        const ink3 = styles.getPropertyValue("--ink3").trim();
        const ink4 = styles.getPropertyValue("--ink4").trim();
        const acc = styles.getPropertyValue("--acc").trim();
        const paper = styles.getPropertyValue("--paper").trim();

        const drawEdgePath = (ctx, fromPos, toPos, curved, fromId, toId) => {
          ctx.beginPath();
          ctx.moveTo(fromPos.x, fromPos.y);
          if (curved) {
            const mx = (fromPos.x + toPos.x) / 2;
            const my = (fromPos.y + toPos.y) / 2;
            const dx = toPos.x - fromPos.x;
            const dy = toPos.y - fromPos.y;
            const len = Math.sqrt(dx * dx + dy * dy) || 1;
            const sign = (fromId < toId) ? 1 : -1;
            const offset = len * 0.15 * sign;
            const cpx = mx + (-dy / len) * offset;
            const cpy = my + (dx / len) * offset;
            ctx.quadraticCurveTo(cpx, cpy, toPos.x, toPos.y);
          } else {
            ctx.lineTo(toPos.x, toPos.y);
          }
        };

        GRAPH.edges.forEach(([fromId, toId]) => {
          if (edgeFilter && !edgeFilter(fromId, toId)) return;
          if (highlightIds && (!highlightIds.has(fromId) || !highlightIds.has(toId))) return;
          if (traversedEdges && !traversedEdges.has(edgeKey(fromId, toId))) return;
          const from = GRAPH.nodes.find((node) => node.id === fromId);
          const to = GRAPH.nodes.find((node) => node.id === toId);
          if (!from || !to) return;
          const fromPos = getNodePx(from, width, height);
          const toPos = getNodePx(to, width, height);
          const touchesActive = hoveredId && (fromId === hoveredId || toId === hoveredId);
          const touchesVisited = visited.has(fromId) || visited.has(toId);
          if (softenUnvisited) {
            ctx.globalAlpha = touchesActive ? 0.5 : touchesVisited ? 0.25 : 0.06;
          } else {
            ctx.globalAlpha = touchesActive ? 0.5 : touchesVisited ? 0.3 : 0.08;
          }
          ctx.strokeStyle = ink4;
          ctx.lineWidth = touchesActive ? 1.5 : 1;
          drawEdgePath(ctx, fromPos, toPos, curvedEdges, fromId, toId);
          ctx.stroke();
        });
        ctx.globalAlpha = 1;

        if (showTrail && trailNodes && trailNodes.length > 1) {
          const segCount = trailNodes.length - 1;
          for (let i = 1; i < trailNodes.length; i++) {
            const prev = trailNodes[i - 1];
            const node = trailNodes[i];
            const prevPos = getNodePx(prev, width, height);
            const pos = getNodePx(node, width, height);
            const t = i / segCount;
            ctx.strokeStyle = acc;
            ctx.globalAlpha = 0.06 + 0.22 * t;
            ctx.lineWidth = 1 + 1.2 * t;
            ctx.beginPath();
            ctx.moveTo(prevPos.x, prevPos.y);
            if (curvedEdges) {
              const mx = (prevPos.x + pos.x) / 2;
              const my = (prevPos.y + pos.y) / 2;
              const dx = pos.x - prevPos.x;
              const dy = pos.y - prevPos.y;
              const len = Math.sqrt(dx * dx + dy * dy) || 1;
              const offset = len * 0.15;
              const cpx = mx + (-dy / len) * offset;
              const cpy = my + (dx / len) * offset;
              ctx.quadraticCurveTo(cpx, cpy, pos.x, pos.y);
            } else {
              ctx.lineTo(pos.x, pos.y);
            }
            ctx.stroke();
          }
          ctx.globalAlpha = 1;
        }

        GRAPH.nodes.forEach((node) => {
          if (highlightIds && !highlightIds.has(node.id)) return;
          const pos = getNodePx(node, width, height);
          const isVisited = visited.has(node.id);
          const isActive = node.id === activeId;
          const isHovered = node.id === hoveredId;
          const radius = isActive ? 11.5 : isHovered ? 9.5 : 8.5;

          if (activeGlow && isActive) {
            const glowRadius = radius + 3;
            const gradient = ctx.createRadialGradient(pos.x, pos.y, radius * 0.5, pos.x, pos.y, glowRadius);
            gradient.addColorStop(0, "rgba(26,26,24,0.9)");
            gradient.addColorStop(1, "rgba(26,26,24,0)");
            ctx.beginPath();
            ctx.arc(pos.x, pos.y, glowRadius, 0, Math.PI * 2);
            ctx.fillStyle = gradient;
            ctx.fill();
          }

          const nodeAlpha = breatheAlpha != null ? breatheAlpha : 1;

          ctx.beginPath();
          ctx.arc(pos.x, pos.y, radius, 0, Math.PI * 2);
          if (softenUnvisited && !isVisited && !isActive) {
            ctx.globalAlpha = nodeAlpha;
            ctx.fillStyle = paper;
            ctx.strokeStyle = ink3;
            ctx.lineWidth = isHovered ? 1.5 : 0.8;
          } else {
            ctx.globalAlpha = nodeAlpha;
            ctx.fillStyle = isVisited || isActive ? ink : paper;
            ctx.strokeStyle = ink;
            ctx.lineWidth = isHovered ? 2 : 1.3;
          }
          ctx.fill();
          ctx.stroke();
          ctx.globalAlpha = 1;

          if (showLabels) {
            const isRevealed = isVisited || isHovered;
            const labelText = isHovered && node.shortQ ? node.shortQ : node.label;
            const labelFontSize = isHovered ? "11px" : "11px";
            const fontWeight = isHovered ? "600" : "normal";
            ctx.font = `${fontWeight} ${labelFontSize} system-ui, -apple-system, Segoe UI, sans-serif`;
            ctx.fillStyle = isHovered ? ink : isVisited ? ink : ink4;
            ctx.globalAlpha = isHovered ? 1 : isVisited ? 0.85 : 0.4;
            ctx.textBaseline = "middle";
            const alignRight = node.x > 0.68;
            ctx.textAlign = alignRight ? "right" : "left";
            const offset = alignRight ? -14 : 14;
            ctx.fillText(labelText, pos.x + offset, pos.y);
            ctx.globalAlpha = 1;
          }
        });
      };

      const ENTRY_QUESTIONS = {
        "next-word": "What is an LLM actually doing when it \"talks\" to you?",
        "averaging-problem": "If you learn from a million essays, do you write like the best one or the average one?",
        "the-shaping": "What happened between \"raw autocomplete\" and \"helpful assistant\"?",
        "weight-of-words": "How does a model learn from trillions of words?",
        quality: "When we say a model's output is \"good,\" who decides?",
        "understanding-illusion": "Does the model \"understand\" what it's saying?",
        "practical-guide": "So what do I actually do with all this?",
        "tool-user": "What happens when the model can use tools?",
        "algorithm-as-muse": "When AI helps create art, who is the artist?",
        "echoes-of-the-past": "What happens when AI reads history through its own biases?",
        "learning-machines-learning-humans": "What happens to learning when AI has all the answers?",
        "automation-of-cognition": "What happens when machines can do the thinking?",
        "black-box-oracle": "How do you trust a decision you can't explain?",
        "digital-footprints": "What does AI cost the planet?",
        "artificial-brain": "Is an artificial neural network really anything like a brain?",
        "empathy-machine": "Can a machine that simulates empathy actually help \u2014 or harm?",
        "near-zero-cost-impact": "What happens when the cost of producing everything approaches zero?",
      };

      const prefersReducedMotion = () => window.matchMedia("(prefers-reduced-motion: reduce)").matches;

      const buildLandingMap = (visitedSet, traversedEdges) => {
        const canvas = h("canvas", {
          role: "img",
          "aria-label": "Navigation map of LLM plateaus",
        });
        const overlay = h("div", { class: "map-overlay" });
        const wrap = h("div", { class: "map-wrap" }, canvas, overlay);
        const linkMap = new Map();
        const hitRadius = 22;
        let lastSize = { width: 0, height: 0 };
        let hoveredId = null;

        GRAPH.nodes.forEach((node) => {
          const fullQ = ENTRY_QUESTIONS[node.id] || node.title;
          const link = h("a", {
            class: "map-link",
            href: `#/${node.id}`,
            title: fullQ,
            "aria-label": `${fullQ} \u2014 ${node.title}, ${visitedSet.has(node.id) ? "visited" : "not visited"}`,
          });
          overlay.appendChild(link);
          linkMap.set(node.id, link);
        });

        const resizeCanvas = () => {
          const rect = wrap.getBoundingClientRect();
          if (!rect.width || !rect.height) return null;
          lastSize = { width: Math.floor(rect.width), height: Math.floor(rect.height) };
          return lastSize;
        };

        const draw = () => {
          if (!resizeCanvas()) return;
          drawGraph({
            canvas,
            width: lastSize.width,
            height: lastSize.height,
            visited: visitedSet,
            showLabels: true,
            hoveredId,
            traversedEdges,
          });

          GRAPH.nodes.forEach((node) => {
            const link = linkMap.get(node.id);
            if (!link) return;
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            link.style.left = `${pos.x}px`;
            link.style.top = `${pos.y}px`;
            const fullQ = ENTRY_QUESTIONS[node.id] || node.title;
            link.setAttribute(
              "aria-label",
              `${fullQ} \u2014 ${node.title}, ${visitedSet.has(node.id) ? "visited" : "not visited"}`
            );
          });
        };

        const findHitNode = (event) => {
          const rect = canvas.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          return GRAPH.nodes.find((node) => {
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            return Math.hypot(x - pos.x, y - pos.y) <= hitRadius;
          });
        };

        const handleMouseMove = (event) => {
          const hit = findHitNode(event);
          const newId = hit ? hit.id : null;
          canvas.style.cursor = newId ? "pointer" : "default";
          if (newId !== hoveredId) {
            hoveredId = newId;
            draw();
          }
        };

        const handleMouseLeave = () => {
          if (hoveredId) {
            hoveredId = null;
            draw();
          }
        };

        const handleClick = (event) => {
          const hit = findHitNode(event);
          if (hit) {
            location.hash = `#/${hit.id}`;
          }
        };

        const observer = new ResizeObserver(draw);
        observer.observe(wrap);
        wrap.addEventListener("mousemove", handleMouseMove);
        wrap.addEventListener("mouseleave", handleMouseLeave);
        canvas.addEventListener("click", handleClick);
        draw();

        const cleanup = () => {
          observer.disconnect();
          wrap.removeEventListener("mousemove", handleMouseMove);
          wrap.removeEventListener("mouseleave", handleMouseLeave);
          canvas.removeEventListener("click", handleClick);
        };

        return { wrap, cleanup };
      };

      const buildLandingView = (state) => {
        const visitedSet = new Set(state.v);
        const header = h(
          "div",
          { class: "landing-header" },
          h("h1", null, "How LLMs Actually Work"),
          h("p", { class: "subtitle" }, "Seventeen essays on prediction, memory, and the strange logic of machines."),
          h(
            "p",
            null,
            "This is a network you can enter anywhere.",
            " Follow a node to see how the ideas braid together."
          )
        );

        const { wrap: mapWrap, cleanup } = buildLandingMap(visitedSet, state.te);
        const mapSection = h(
          "div",
          { class: "landing-map" },
          mapWrap,
          h("p", { class: "map-note" }, "Click or tab to any node to begin.")
        );

        const main = h("main", { class: "landing view" }, header, mapSection);
        return { view: main, cleanup };
      };

      const buildMiniMap = (state, currentId) => {
        const container = h("div", { class: "mini-map" });
        const canvas = h("canvas", { "aria-hidden": "true" });
        const button = h("button", {
          class: "mini-map-button",
          type: "button",
          "aria-label": "Open navigation map",
        });
        container.append(canvas, button);

        let visited = new Set(state.v);
        let activeId = currentId || null;
        let highlightIds = new Set();
        let edgeFilter = null;
        let trailNodes = getTrailSegments(state.tr);
        let traversedEdges = state.te || deriveTraversedEdges(state.tr);
        let isVisible = true;
        let rafId = null;
        let breatheStart = null;
        let transitionStart = null;
        let prevHighlightIds = null;
        let prevEdgeFilter = null;
        let prevActiveId = null;

        const computeContext = (id) => {
          const hl = new Set();
          let ef = null;
          if (id) {
            hl.add(id);
            GRAPH.edges.forEach(([fromId, toId]) => {
              if (fromId === id) hl.add(toId);
              if (toId === id) hl.add(fromId);
            });
            ef = (fromId, toId) => fromId === id || toId === id;
          } else {
            GRAPH.nodes.forEach((node) => hl.add(node.id));
          }
          return { hl, ef };
        };

        const ctx = computeContext(currentId);
        highlightIds = ctx.hl;
        edgeFilter = ctx.ef;

        const isMobile = () => window.matchMedia("(max-width: 480px)").matches;

        const render = (alpha) => {
          const rect = container.getBoundingClientRect();
          if (!rect.width || !rect.height) return;
          drawGraph({
            canvas,
            width: rect.width,
            height: rect.height,
            visited,
            activeId,
            highlightIds,
            edgeFilter,
            showLabels: false,
            showTrail: trailNodes.length > 1,
            trailNodes,
            curvedEdges: true,
            softenUnvisited: true,
            activeGlow: !!activeId,
            breatheAlpha: alpha,
            traversedEdges,
          });
        };

        const animate = (timestamp) => {
          if (!isVisible) return;
          if (breatheStart === null) breatheStart = timestamp;
          const elapsed = (timestamp - breatheStart) / 1000;
          const alpha = 1 + 0.08 * Math.sin((2 * Math.PI * elapsed) / 5);

          if (transitionStart !== null) {
            const tElapsed = timestamp - transitionStart;
            const tProgress = Math.min(tElapsed / 300, 1);
            if (tProgress >= 1) {
              transitionStart = null;
              prevHighlightIds = null;
              prevEdgeFilter = null;
              prevActiveId = null;
            }
          }

          render(alpha);
          rafId = requestAnimationFrame(animate);
        };

        const startAnimation = () => {
          if (prefersReducedMotion() || isMobile()) {
            render(1);
            return;
          }
          if (rafId !== null) return;
          breatheStart = null;
          rafId = requestAnimationFrame(animate);
        };

        const stopAnimation = () => {
          if (rafId !== null) {
            cancelAnimationFrame(rafId);
            rafId = null;
          }
        };

        const visObserver = new IntersectionObserver(([entry]) => {
          isVisible = entry.isIntersecting;
          if (isVisible) {
            startAnimation();
          } else {
            stopAnimation();
          }
        });
        visObserver.observe(container);

        const resizeObserver = new ResizeObserver(() => {
          if (prefersReducedMotion() || isMobile()) {
            render(1);
          }
        });
        resizeObserver.observe(container);

        render(1);
        startAnimation();

        const updateContext = (newState, newCurrentId) => {
          const newVisited = new Set(newState.v);
          const newTrail = getTrailSegments(newState.tr);
          const newCtx = computeContext(newCurrentId);

          if (!prefersReducedMotion() && !isMobile() && activeId !== (newCurrentId || null)) {
            prevHighlightIds = highlightIds;
            prevEdgeFilter = edgeFilter;
            prevActiveId = activeId;
            transitionStart = performance.now();
          }

          visited = newVisited;
          activeId = newCurrentId || null;
          highlightIds = newCtx.hl;
          edgeFilter = newCtx.ef;
          trailNodes = newTrail;
          traversedEdges = newState.te || deriveTraversedEdges(newState.tr);

          if (prefersReducedMotion() || isMobile()) {
            render(1);
          }
        };

        return {
          container,
          button,
          updateContext,
          cleanup: () => {
            stopAnimation();
            visObserver.disconnect();
            resizeObserver.disconnect();
          },
        };
      };

      const buildScrolly = ({ steps, whispers, questionCards, scrubUpdate, vizContent }) => {
        const hasViz = !!vizContent;
        const section = h("section", { class: hasViz ? "scrolly" : "scrolly scrolly-no-viz" });
        let viz = null;
        let vizMain = null;
        let constellation = null;
        if (hasViz) {
          viz = h("div", { class: "scrolly-viz" });
          vizMain = h("div", { class: "viz-main" });
          vizMain.appendChild(vizContent);
          const whispersLayer = h("div", { class: "whisper-layer" });
          const pips = h("div", { class: "trace-pips" });
          constellation = h("div", { class: "constellation" }, "Constellation");
          viz.append(vizMain, whispersLayer, pips, constellation);
        }

        const stepsWrap = h("div", { class: "scrolly-steps" });
        const stepEls = steps.map((content, index) => {
          const step = h("div", { class: "scrolly-step" });
          if (typeof content === "string") {
            step.appendChild(h("p", null, content));
          } else if (typeof content === "function") {
            content(step);
          }
          if (index === 0) step.classList.add("is-active");
          stepsWrap.appendChild(step);
          return step;
        });

        if (hasViz) {
          const whispersLayer = viz.querySelector(".whisper-layer");
          const pips = viz.querySelector(".trace-pips");
          whispers.forEach((whisper) => {
            const line = h("a", { class: "whisper", href: `#/${whisper.to}` }, whisper.text);
            whispersLayer.appendChild(line);
            const pip = h("span", { class: "trace-pip" });
            pips.appendChild(pip);
          });
        }

        const cards = h("div", { class: "question-cards" });
        questionCards.forEach((card) => {
          cards.appendChild(
            h(
              "a",
              { class: "question-card", href: `#/${card.to}` },
              h("span", null, card.question),
              h("strong", null, card.title)
            )
          );
        });
        stepsWrap.appendChild(cards);

        if (viz) section.appendChild(viz);
        section.appendChild(stepsWrap);

        let activeStepIndex = 0;
        const onStep = (idx) => {
          activeStepIndex = idx;
          stepEls.forEach((step, index) => {
            step.classList.toggle("is-active", index === idx);
          });
          if (hasViz) {
            const whispersLayer = viz.querySelector(".whisper-layer");
            const pips = viz.querySelector(".trace-pips");
            whispers.forEach((whisper, index) => {
              const line = whispersLayer.children[index];
              const pip = pips.children[index];
              const isVisible = idx >= whisper.step && idx < steps.length - 1;
              line.classList.toggle("is-visible", isVisible);
              pip.classList.toggle("is-lit", idx >= whisper.step);
            });
            const isFinal = idx === steps.length - 1;
            viz.classList.toggle("is-constellation", isFinal);
            constellation.classList.toggle("is-visible", isFinal);
          }
        };

        const observer = new IntersectionObserver(
          (entries) => {
            entries.forEach((entry) => {
              if (entry.isIntersecting) {
                const index = stepEls.indexOf(entry.target);
                if (index >= 0) onStep(index);
              }
            });
          },
          { threshold: 0.55 }
        );

        stepEls.forEach((step) => observer.observe(step));

        let scrubTicking = false;
        let scrubCleanup = null;
        if (scrubUpdate) {
          const onScroll = () => {
            if (scrubTicking) return;
            scrubTicking = true;
            requestAnimationFrame(() => {
              const activeStep = stepEls[activeStepIndex];
              if (activeStep) {
                const rect = activeStep.getBoundingClientRect();
                const viewH = window.innerHeight;
                const progress = Math.max(0, Math.min(1, 1 - (rect.bottom / (rect.height + viewH))));
                scrubUpdate(activeStepIndex, progress, vizMain);
              }
              scrubTicking = false;
            });
          };
          window.addEventListener("scroll", onScroll, { passive: true });
          scrubCleanup = () => window.removeEventListener("scroll", onScroll);
        }

        const cleanup = () => {
          observer.disconnect();
          if (scrubCleanup) scrubCleanup();
        };

        return { section, vizMain, cleanup };
      };

      const buildInlineSeed = ({ id, label, detail, type, danglingTo, danglingText, state, plateauId, onOpen }) => {
        const attrs = {
          class: "inline-seed-button",
          type: "button",
          "aria-expanded": "false",
        };
        if (type) attrs["data-seed-type"] = type;
        const button = h("button", attrs, label);

        const contentChildren = typeof detail === "function" ? detail(state) : detail;
        const contentEl = h("span", { class: "inline-seed-content" });
        if (typeof contentChildren === "string") {
          contentEl.appendChild(document.createTextNode(contentChildren));
        } else if (contentChildren instanceof Node) {
          contentEl.appendChild(contentChildren);
        } else if (Array.isArray(contentChildren)) {
          contentChildren.forEach((c) => {
            if (typeof c === "string") contentEl.appendChild(document.createTextNode(c));
            else if (c instanceof Node) contentEl.appendChild(c);
          });
        }

        if (type === "dangling" && danglingTo && danglingText) {
          contentEl.appendChild(document.createTextNode(" "));
          contentEl.appendChild(
            h("a", { class: "dangling-link", href: `#/${danglingTo}` }, danglingText)
          );
        }

        const growth = h(
          "span",
          { class: "inline-seed-growth", "aria-hidden": "true" },
          contentEl
        );
        const wrapper = h("span", { class: "inline-seed" }, button, growth);

        button.addEventListener("click", () => {
          const isOpen = button.getAttribute("aria-expanded") === "true";
          button.setAttribute("aria-expanded", String(!isOpen));
          growth.classList.toggle("is-open", !isOpen);
          growth.setAttribute("aria-hidden", String(isOpen));
          if (!isOpen && onOpen && id) onOpen(id);
        });

        return wrapper;
      };

      const buildOverlay = (state) => {
        const overlay = h("div", {
          class: "rhizome-overlay",
          role: "dialog",
          "aria-modal": "true",
          "aria-hidden": "true",
        });
        const backdrop = h("div", { class: "overlay-backdrop" });
        const panel = h("div", { class: "overlay-panel" });
        const closeButton = h("button", {
          class: "overlay-close",
          type: "button",
          "aria-label": "Close navigation map",
        }, "Close");
        const mapWrap = h("div", { class: "overlay-map" });
        const canvas = h("canvas", {
          role: "img",
          "aria-label": "Full navigation map of all plateaus",
        });
        const linkLayer = h("div", { class: "overlay-links" });

        mapWrap.append(canvas, linkLayer);
        panel.append(closeButton, mapWrap);
        overlay.append(backdrop, panel);

        let visited = new Set(state.v);
        let trailNodes = getTrailSegments(state.tr);
        let traversedEdges = state.te || deriveTraversedEdges(state.tr);
        const linkMap = new Map();
        const hitRadius = 22;
        let lastSize = { width: 0, height: 0 };
        let hoveredId = null;

        GRAPH.nodes.forEach((node) => {
          const link = h("a", {
            class: "overlay-link",
            href: `#/${node.id}`,
            role: "link",
          });
          linkLayer.appendChild(link);
          linkMap.set(node.id, link);
        });

        const redraw = () => {
          if (!lastSize.width || !lastSize.height) return;
          drawGraph({
            canvas,
            width: lastSize.width,
            height: lastSize.height,
            visited,
            showLabels: true,
            showTrail: true,
            trailNodes,
            hoveredId,
            curvedEdges: true,
            traversedEdges,
          });
        };

        const resize = () => {
          const rect = mapWrap.getBoundingClientRect();
          if (!rect.width || !rect.height) return;
          lastSize = { width: rect.width, height: rect.height };
          redraw();
          GRAPH.nodes.forEach((node) => {
            const link = linkMap.get(node.id);
            if (!link) return;
            const pos = getNodePx(node, rect.width, rect.height);
            link.style.left = `${pos.x}px`;
            link.style.top = `${pos.y}px`;
            link.setAttribute(
              "aria-label",
              `${node.title}, ${visited.has(node.id) ? "visited" : "not visited"}`
            );
          });
        };

        const handleMouseMove = (event) => {
          const rect = mapWrap.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          const hit = GRAPH.nodes.find((node) => {
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            return Math.hypot(x - pos.x, y - pos.y) <= hitRadius;
          });
          const newId = hit ? hit.id : null;
          canvas.style.cursor = newId ? "pointer" : "default";
          if (newId !== hoveredId) {
            hoveredId = newId;
            redraw();
          }
        };

        const handleMouseLeave = () => {
          if (hoveredId) {
            hoveredId = null;
            redraw();
          }
        };

        const handleClick = (event) => {
          const rect = canvas.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          const hit = GRAPH.nodes.find((node) => {
            const pos = getNodePx(node, lastSize.width, lastSize.height);
            const dx = x - pos.x;
            const dy = y - pos.y;
            return Math.hypot(dx, dy) <= hitRadius;
          });
          if (hit) {
            location.hash = `#/${hit.id}`;
          }
        };

        const observer = new ResizeObserver(resize);
        observer.observe(mapWrap);
        mapWrap.addEventListener("mousemove", handleMouseMove);
        mapWrap.addEventListener("mouseleave", handleMouseLeave);
        canvas.addEventListener("click", handleClick);
        resize();

        const focusables = Array.from(linkLayer.querySelectorAll("a")).concat([closeButton]);

        const updateState = (newState) => {
          visited = new Set(newState.v);
          trailNodes = getTrailSegments(newState.tr);
          traversedEdges = newState.te || deriveTraversedEdges(newState.tr);
          resize();
        };

        return {
          overlay,
          backdrop,
          closeButton,
          focusables,
          updateState,
          cleanup: () => {
            observer.disconnect();
            mapWrap.removeEventListener("mousemove", handleMouseMove);
            mapWrap.removeEventListener("mouseleave", handleMouseLeave);
            canvas.removeEventListener("click", handleClick);
          },
        };
      };

      const getFocusable = (container) =>
        Array.from(container.querySelectorAll("button, [href], [tabindex]:not([tabindex='-1'])"));

      const trapFocus = (container, event) => {
        if (event.key !== "Tab") return;
        const focusable = getFocusable(container);
        if (!focusable.length) return;
        const first = focusable[0];
        const last = focusable[focusable.length - 1];
        if (event.shiftKey && document.activeElement === first) {
          event.preventDefault();
          last.focus();
        } else if (!event.shiftKey && document.activeElement === last) {
          event.preventDefault();
          first.focus();
        }
      };

      const buildSeedCluster = (seeds, { state, plateauId, onSeedOpen } = {}) => {
        const field = h("div", { class: "seed-field" });
        seeds.forEach((seed) => {
          const detailContent = typeof seed.detail === "function" ? seed.detail(state) : seed.detail;
          const inner = h("div", { class: "seed-growth-inner" });
          if (typeof detailContent === "string") {
            inner.appendChild(document.createTextNode(detailContent));
          } else if (detailContent instanceof Node) {
            inner.appendChild(detailContent);
          }

          if (seed.type === "dangling" && seed.danglingTo && seed.danglingText) {
            inner.appendChild(document.createTextNode(" "));
            inner.appendChild(
              h("a", { class: "dangling-link", href: `#/${seed.danglingTo}` }, seed.danglingText)
            );
          }

          const growth = h(
            "div",
            { class: "seed-growth", "aria-hidden": "true" },
            inner
          );
          const btnAttrs = {
            class: "seed-button",
            type: "button",
            "aria-expanded": "false",
          };
          if (seed.type) btnAttrs["data-seed-type"] = seed.type;
          const button = h("button", btnAttrs, seed.label);
          const item = h("div", { class: "seed-item" }, button, growth);

          button.addEventListener("click", () => {
            const isOpen = button.getAttribute("aria-expanded") === "true";
            button.setAttribute("aria-expanded", String(!isOpen));
            growth.classList.toggle("is-open", !isOpen);
            growth.setAttribute("aria-hidden", String(isOpen));
            if (!isOpen && onSeedOpen && seed.id) onSeedOpen(seed.id);
          });

          field.appendChild(item);
        });
        return field;
      };

      const buildScatterToText = () => {
        const words = ["syntax", "semantics", "reasoning", "facts", "grammar", "analogy", "context", "prediction", "structure", "meaning", "inference", "pattern"];
        const container = h("div", { class: "scatter-container" });
        const wordEls = [];

        const hash = (str) => {
          let h = 0;
          for (let i = 0; i < str.length; i++) h = ((h << 5) - h + str.charCodeAt(i)) | 0;
          return h;
        };

        const cols = 4;
        const rows = Math.ceil(words.length / cols);
        words.forEach((word, i) => {
          const seed = hash(word);
          const initX = ((seed & 0xff) / 255) * 80 + 5;
          const initY = (((seed >> 8) & 0xff) / 255) * 80 + 5;
          const finalCol = i % cols;
          const finalRow = Math.floor(i / cols);
          const finalX = 10 + (finalCol / (cols - 1)) * 80;
          const finalY = 20 + (finalRow / (rows - 1)) * 60;

          const el = h("span", { class: "scatter-word" }, word);
          el.style.left = `${finalX}%`;
          el.style.top = `${finalY}%`;
          el.dataset.initX = initX;
          el.dataset.initY = initY;
          el.dataset.finalX = finalX;
          el.dataset.finalY = finalY;

          if (!prefersReducedMotion()) {
            el.style.transform = `translate(${initX - finalX}vw, ${initY - finalY}vh)`;
          }
          container.appendChild(el);
          wordEls.push(el);
        });

        const update = (progress) => {
          if (prefersReducedMotion()) return;
          wordEls.forEach((el) => {
            const ix = parseFloat(el.dataset.initX);
            const iy = parseFloat(el.dataset.initY);
            const fx = parseFloat(el.dataset.finalX);
            const fy = parseFloat(el.dataset.finalY);
            const dx = (ix - fx) * (1 - progress);
            const dy = (iy - fy) * (1 - progress);
            el.style.transform = `translate(${dx}vw, ${dy}vh)`;
          });
        };

        return { container, update };
      };

      const setupDwellReveal = (container, annotations) => {
        const timers = new Map();
        const revealed = new Set();
        const DWELL_MS = 3000;

        const targets = container.querySelectorAll(".dwell-target");
        targets.forEach((target) => {
          const paraId = target.dataset.dwellId;
          if (!paraId || !annotations[paraId]) return;

          const annotation = h("div", {
            class: "dwell-annotation",
            "aria-live": "polite",
          }, annotations[paraId]);
          target.appendChild(annotation);

          let timer = null;
          const resetTimer = () => {
            if (timer) clearTimeout(timer);
            if (revealed.has(paraId)) return;
            timer = setTimeout(() => {
              annotation.classList.add("is-revealed");
              revealed.add(paraId);
            }, DWELL_MS);
            timers.set(paraId, timer);
          };

          const clearTimer = () => {
            if (timer) clearTimeout(timer);
            timer = null;
          };

          target.addEventListener("mousemove", resetTimer);
          target.addEventListener("mouseleave", clearTimer);
        });

        return () => {
          timers.forEach((t) => clearTimeout(t));
          timers.clear();
        };
      };

      const buildCYOAFork = ({ prompt, options }) => {
        const group = h("div", {
          class: "cyoa-fork",
          role: "group",
          "aria-label": prompt,
        });
        const label = h("p", { style: { color: "var(--ink2)", fontStyle: "italic", fontSize: "0.92rem" } }, prompt);
        group.appendChild(label);
        let chosen = null;

        options.forEach((opt) => {
          const expansion = h("div", { class: "cyoa-expansion" },
            h("div", { class: "cyoa-expansion-inner" }, opt.content)
          );
          const btn = h("button", {
            class: "cyoa-option",
            type: "button",
          }, opt.label);

          btn.addEventListener("click", () => {
            if (!chosen) {
              chosen = opt.label;
              group.querySelectorAll(".cyoa-option").forEach((b) => {
                if (b === btn) {
                  b.classList.add("is-chosen");
                  b.classList.remove("is-unchosen");
                } else {
                  b.classList.add("is-unchosen");
                  b.classList.remove("is-chosen");
                }
              });
            }
            expansion.classList.toggle("is-open");
          });

          group.appendChild(btn);
          group.appendChild(expansion);
        });

        return group;
      };

      const RETRIEVAL_QUESTIONS = {
        "next-word": (visited) => {
          if (visited.has("weight-of-words")) return "Earlier, you explored how trillions of words become structure. What gets lost when all that structure collapses into a single next token?";
          if (visited.has("the-shaping")) return "You saw how RLHF reshapes behavior. How does that shaping interact with the raw prediction you're reading about now?";
          if (visited.has("averaging-problem")) return "You explored the averaging problem. How does that average show up in what the model predicts next?";
          return null;
        },
        "weight-of-words": (visited) => {
          if (visited.has("next-word")) return "You saw how models predict the next token. What kind of structure would you need to learn before that prediction works?";
          if (visited.has("the-shaping")) return "You explored how models get shaped after training. What does the model need to learn first, before any shaping begins?";
          return null;
        },
        "the-shaping": (visited) => {
          if (visited.has("weight-of-words")) return "You saw how structure emerges from raw data. What happens when humans start redirecting those learned patterns?";
          if (visited.has("quality")) return "You thought about who defines quality. Now ask: how do those definitions get baked into the model's behavior?";
          return null;
        },
        quality: (visited) => {
          if (visited.has("the-shaping")) return "You followed the shaping process. Now step back: who chose the direction of that shaping, and by what standard?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. Does that change how you think about rating their outputs?";
          return null;
        },
        "understanding-illusion": (visited) => {
          if (visited.has("next-word")) return "You saw the prediction mechanism. Does knowing how it works change whether you'd call it understanding?";
          if (visited.has("weight-of-words")) return "You explored the internal structure that emerges from training. Does having structure mean having understanding?";
          return null;
        },
        "averaging-problem": (visited) => {
          if (visited.has("next-word")) return "You watched a model predict the next word. What happens when that prediction is averaged across a million different writing styles?";
          if (visited.has("quality")) return "You considered what quality means. How does the averaging problem complicate the idea of a 'good' output?";
          return null;
        },
        "practical-guide": (visited) => {
          if (visited.has("understanding-illusion")) return "You questioned whether models truly understand. How does that uncertainty change how you should use them?";
          if (visited.has("the-shaping")) return "You saw how models get shaped. How does knowing that inform the way you write prompts?";
          return null;
        },
        "tool-user": (visited) => {
          if (visited.has("practical-guide")) return "You learned techniques for working with models. What changes when the model can also work with tools?";
          if (visited.has("next-word")) return "You saw how models predict tokens. What happens when one of those tokens is a function call?";
          return null;
        },
        "near-zero-cost-impact": (visited) => {
          if (visited.has("averaging-problem")) return "You explored what happens when a model averages everything. What happens when that average is reproduced at near-zero cost, billions of times over?";
          if (visited.has("quality")) return "You asked who defines quality. When production cost is zero and volume is infinite, does quality still matter\u2014or does it drown?";
          if (visited.has("digital-footprints")) return "You considered the environmental cost of AI. What's the full ledger when production itself is nearly free but the infrastructure isn't?";
          return null;
        },
        "algorithm-as-muse": (visited) => {
          if (visited.has("averaging-problem")) return "You saw how models average everything they've read. What does that average look like when it tries to create art?";
          if (visited.has("the-shaping")) return "You explored how models are shaped by human feedback. Who's shaping the muse\u2014and whose taste does it reflect?";
          return null;
        },
        "echoes-of-the-past": (visited) => {
          if (visited.has("quality")) return "You thought about who decides what's 'good.' The same question haunts history: whose version of the past does the model learn?";
          if (visited.has("weight-of-words")) return "You saw how models learn from trillions of words. What happens when those words carry centuries of bias?";
          return null;
        },
        "learning-machines-learning-humans": (visited) => {
          if (visited.has("next-word")) return "You watched a model predict the next word. What happens when a student starts relying on that prediction instead of thinking?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. Does that uncertainty change how you'd trust one as a teacher?";
          return null;
        },
        "automation-of-cognition": (visited) => {
          if (visited.has("the-shaping")) return "You saw how models are shaped for usefulness. What happens when that usefulness displaces the workers it was shaped to help?";
          if (visited.has("tool-user")) return "You explored what happens when models use tools. What happens when those tools replace the people who used to wield them?";
          return null;
        },
        "black-box-oracle": (visited) => {
          if (visited.has("the-shaping")) return "You saw how human feedback shapes model behavior. But who audits the shaping when the model makes life-altering decisions?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. How do you hold accountable a system you can't explain and that may not understand itself?";
          return null;
        },
        "digital-footprints": (visited) => {
          if (visited.has("near-zero-cost-impact")) return "You saw what happens when production cost approaches zero. But the energy cost doesn't\u2014every query has a carbon shadow.";
          if (visited.has("weight-of-words")) return "You explored how models learn from trillions of words. What's the environmental cost of processing that much language?";
          return null;
        },
        "artificial-brain": (visited) => {
          if (visited.has("next-word")) return "You watched a model predict tokens. The brain predicts too\u2014but with 86 billion neurons running on 20 watts. What's different?";
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. If understanding requires a body, what does that mean for a machine?";
          return null;
        },
        "empathy-machine": (visited) => {
          if (visited.has("understanding-illusion")) return "You questioned whether models understand. If they don't, can they truly empathize\u2014or only simulate empathy?";
          if (visited.has("next-word")) return "You saw how models predict the next word. When the next word is 'I understand how you feel,' is that prediction or connection?";
          return null;
        },
      };

      const buildRetrievalMoment = (state, plateauId) => {
        if (state.v.length < 3) return null;
        const visited = new Set(state.v);
        const getter = RETRIEVAL_QUESTIONS[plateauId];
        if (!getter) return null;
        const question = getter(visited);
        if (!question) return null;

        const closeBtn = h("button", {
          class: "retrieval-close",
          type: "button",
          "aria-label": "Dismiss retrieval moment",
        }, "\u00d7");
        const card = h("div", {
          class: "retrieval-moment",
          role: "note",
          "aria-label": "Retrieval moment",
        },
          h("p", { style: { margin: "0", flex: "1" } }, question),
          closeBtn
        );
        closeBtn.addEventListener("click", () => {
          card.classList.add("is-dismissed");
        });
        return card;
      };

      const buildEngagementState = (state, plateauId) => {
        const eg = state.eg[plateauId] || { opened: 0, total: 0 };
        const el = h("div", {
          class: "engagement-state",
          "aria-live": "polite",
        }, `${eg.opened} of ${eg.total} seeds opened`);
        return el;
      };

      const MARGINALIA = {
        "weight-of-words": [
          { forParagraph: 0, text: "The loop never actually converges. It just gets close enough." },
          { forParagraph: 2, text: "Chinchilla showed: more data per parameter beats more parameters per data.", condition: (v) => v.has("averaging-problem") },
        ],
        quality: [
          { forParagraph: 0, text: "The raters are never told they're defining the soul of the model." },
          { forParagraph: 2, text: "If you came here from The Shaping, notice how RLHF doesn't change what the model knows\u2014it changes which knowledge surfaces.", condition: (v) => v.has("the-shaping") },
        ],
        "understanding-illusion": [
          { forParagraph: 0, text: "The question itself might be wrong. But it's the question everyone asks." },
          { forParagraph: 1, text: "Searle's argument assumed computation and understanding are separate categories. What if they're not?", condition: (v) => v.has("weight-of-words") },
        ],
        "practical-guide": [
          { forParagraph: 0, text: "Everything in this plateau is a heuristic. The model doesn't know about any of it." },
          { forParagraph: 1, text: "Chain-of-thought works because the model can attend to its own reasoning tokens.", condition: (v) => v.has("next-word") },
        ],
        "tool-user": [
          { forParagraph: 0, text: "The shift from oracle to agent happened faster than anyone predicted." },
          { forParagraph: 2, text: "When the model writes code that writes code, the oracle metaphor breaks completely.", condition: (v) => v.has("practical-guide") },
        ],
        "near-zero-cost-impact": [
          { forParagraph: 0, text: "The marginal cost of the next copy is zero. The marginal cost of trust is not." },
          { forParagraph: 2, text: "Every previous revolution had friction that slowed adoption. AI's friction is approaching zero too.", condition: (v) => v.has("the-shaping") },
        ],
      };

      const buildPlateauView = (state, plateauId) => {
        recordVisit(state, plateauId);
        const plateau = getPlateau(plateauId);
        const scrollyId = new Set(["next-word", "averaging-problem", "the-shaping", "near-zero-cost-impact", "algorithm-as-muse", "echoes-of-the-past", "learning-machines-learning-humans", "automation-of-cognition", "black-box-oracle", "digital-footprints", "artificial-brain", "empathy-machine"]);
        const isScrolly = scrollyId.has(plateauId);
        const questionCardMap = {
          "next-word": [
            {
              question: "What patterns does the model learn first?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "Why do prompts steer the average?",
              title: "The Averaging Problem",
              to: "averaging-problem",
            },
            {
              question: "How do models get nudged into assistants?",
              title: "The Shaping",
              to: "the-shaping",
            },
          ],
          "averaging-problem": [
            {
              question: "How does next-token prediction feel from inside?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "How do we steer a model's behavior?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What can you do with all this?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "the-shaping": [
            {
              question: "How does pretraining plant the raw behavior?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "Who defines what good looks like?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "What happens when models become tool users?",
              title: "The Tool-User",
              to: "tool-user",
            },
          ],
          "weight-of-words": [
            {
              question: "What does next-token prediction feel like?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "How does alignment reshape the base model?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "Where do we apply these mechanics?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          quality: [
            {
              question: "Does the model understand or just sound fluent?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "How is the model shaped by human feedback?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What should we do with these tools?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "understanding-illusion": [
            {
              question: "What kind of data forms the model?",
              title: "The Averaging Problem",
              to: "averaging-problem",
            },
            {
              question: "Who decides what quality means?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "What do we do with the uncertainty?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "practical-guide": [
            {
              question: "How does the base model learn its patterns?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "What does alignment optimize?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What happens when models act on tools?",
              title: "The Tool-User",
              to: "tool-user",
            },
          ],
          "tool-user": [
            {
              question: "How do models pick their next action?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Can models really understand their tools?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "How do we apply these behaviors?",
              title: "The Field Guide",
              to: "practical-guide",
            },
          ],
          "near-zero-cost-impact": [
            {
              question: "What happens when the average floods the market?",
              title: "The Averaging Problem",
              to: "averaging-problem",
            },
            {
              question: "Who decides what's worth producing at zero cost?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "What does AI cost the planet when production is free?",
              title: "Digital Footprints",
              to: "digital-footprints",
            },
          ],
          "algorithm-as-muse": [
            {
              question: "How does prediction shape what gets created?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "How do human preferences shape creative AI?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "Who decides what's original?",
              title: "What Is Quality?",
              to: "quality",
            },
          ],
          "echoes-of-the-past": [
            {
              question: "Who decides which narratives are 'good'?",
              title: "What Is Quality?",
              to: "quality",
            },
            {
              question: "Does the model understand the history it processes?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "What does AI cost the planet as it processes the past?",
              title: "Digital Footprints",
              to: "digital-footprints",
            },
          ],
          "learning-machines-learning-humans": [
            {
              question: "How does prediction relate to learning?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Who decides what an AI tutor teaches?",
              title: "The Black Box Oracle",
              to: "black-box-oracle",
            },
            {
              question: "Is an artificial brain anything like a student's?",
              title: "The Artificial Brain",
              to: "artificial-brain",
            },
          ],
          "automation-of-cognition": [
            {
              question: "How does AI reshape behavior to be 'useful'?",
              title: "The Shaping",
              to: "the-shaping",
            },
            {
              question: "What happens when models use tools?",
              title: "The Tool-User",
              to: "tool-user",
            },
            {
              question: "What does all this automation cost the planet?",
              title: "Digital Footprints",
              to: "digital-footprints",
            },
          ],
          "black-box-oracle": [
            {
              question: "How does the model learn its decision patterns?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "Does the model understand its own decisions?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "How do human values get encoded into AI?",
              title: "The Shaping",
              to: "the-shaping",
            },
          ],
          "digital-footprints": [
            {
              question: "How much data goes into training a model?",
              title: "The Weight of Words",
              to: "weight-of-words",
            },
            {
              question: "What happens when automation scales without limit?",
              title: "The Automation of Cognition",
              to: "automation-of-cognition",
            },
            {
              question: "When production is near-zero cost, who pays?",
              title: "The Near-Zero Cost Impact",
              to: "near-zero-cost-impact",
            },
          ],
          "artificial-brain": [
            {
              question: "How does prediction work inside the model?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Does structure imply understanding?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "Can simulated empathy be 'real' empathy?",
              title: "The Empathy Machine?",
              to: "empathy-machine",
            },
          ],
          "empathy-machine": [
            {
              question: "How does AI simulate conversation?",
              title: "The Next Word",
              to: "next-word",
            },
            {
              question: "Does the model understand emotions?",
              title: "The Understanding Illusion",
              to: "understanding-illusion",
            },
            {
              question: "Who decides what empathetic AI looks like?",
              title: "What Is Quality?",
              to: "quality",
            },
          ],
        };
        const entryQuestion = ENTRY_QUESTIONS[plateauId] || "";
        const engagementEl = buildEngagementState(state, plateauId);
        const retrievalMoment = buildRetrievalMoment(state, plateauId);
        const visited = new Set(state.v);

        const onSeedOpen = (seedId) => {
          if (recordSeedOpen(state, plateauId, seedId)) {
            const eg = state.eg[plateauId];
            if (eg) engagementEl.textContent = `${eg.opened} of ${eg.total} seeds opened`;
          }
        };

        let cleanup = () => {};
        const main = h(
          "main",
          { class: "plateau view" },
          h("a", { class: "back-link", href: "#/" }, "\u2190 Back to map"),
          h("h1", null, plateau ? plateau.title : "Plateau"),
          entryQuestion ? h("p", { class: "entry-question" }, entryQuestion) : null
        );
        if (retrievalMoment) main.appendChild(retrievalMoment);

        const scrollyStepMap = {
          "next-word": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "A model predicts the "),
                  buildInlineSeed({
                    id: "next-word", label: "next word", state, plateauId, onOpen: onSeedOpen,
                    detail: "The model picks the most likely continuation given its context window. It does this repeatedly, one token at a time.",
                  }),
                  h("p", null, " by looking at the patterns it has seen before.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The distribution of possibilities is a landscape. Temperature lets you explore a wider ridge or a narrow groove."),
                  buildInlineSeed({
                    id: "temperature", label: "Why does one number change the whole personality?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Higher temperature flattens the distribution, making rarer words more likely. Lower temperature sharpens it toward the peak. A single scalar reshapes the entire probability surface.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Every response is conditional on your prompt, but also on the model's training history."),
                  buildInlineSeed({
                    id: "context-window", label: "context window", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("weight-of-words")
                      ? "The model only sees a finite slice of text at once. You've seen how training bakes structure into the weights\u2014the context window is where that structure meets the present moment."
                      : "The model only sees a finite slice of text at once. It infers meaning within that window, not outside of it.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "As you scroll, whispers appear: alternate paths through the rhizome."),
                  buildInlineSeed({
                    id: "whispers", label: "whispers", state, plateauId, onOpen: onSeedOpen,
                    detail: "These are the line-of-flight questions that will later become your navigation cards.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The constellation gathers the lines of flight into a clear choice."),
                  buildInlineSeed({
                    id: "constellation", label: "constellation", state, plateauId, onOpen: onSeedOpen,
                    type: "fourth-wall",
                    detail: "You've been scrolling through a sequence that felt linear. But the navigation cards below offer you multiple exits. Your reading path through this essay is already shaping what you'll encounter next\u2014just as context shapes what a model predicts.",
                  })
                );
              },
            ],
            whispers: [
              { step: 1, text: "What does it average out?", to: "averaging-problem" },
              { step: 2, text: "Where did the style come from?", to: "weight-of-words" },
              { step: 3, text: "Can it be shaped?", to: "the-shaping" },
            ],
          },
          "averaging-problem": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "A language model learns from everything: textbooks, fan fiction, legal briefs, forum rants. It has to average all of them."),
                  buildInlineSeed({
                    id: "the-average", label: "What does that average look like?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Not the best writing, not the worst. A strange middle voice that can shift register on command, because it has encoded all registers simultaneously.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The prompt is a steering wheel. It tells the model which part of the distribution to sample from."),
                  buildInlineSeed({
                    id: "steering", label: "steering", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("the-shaping")
                      ? "You've seen how RLHF reshapes behavior globally. Prompts do something complementary: they narrow the distribution locally, for this specific conversation."
                      : "System prompts, few-shot examples, and conversational context all narrow the distribution. The model doesn't change\u2014but the region it samples from does.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Without a prompt, the model has no reason to prefer any particular style, tone, or register."),
                  buildInlineSeed({
                    id: "base-model", label: "base model", state, plateauId, onOpen: onSeedOpen,
                    detail: "The base model is the raw average. It can continue any text in any direction. It's simultaneously a poet, a coder, a conspiracy theorist, and a technical writer.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The averaging problem isn't a flaw. It's the foundation everything else builds on."),
                  buildInlineSeed({
                    id: "foundation", label: "foundation", state, plateauId, onOpen: onSeedOpen,
                    type: "fourth-wall",
                    detail: "Notice how each seed you've opened has been narrowing your understanding\u2014collapsing the space of possible interpretations. You're doing what the model does: using context to converge on meaning.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation below shows where this connects."));
              },
            ],
            whispers: [
              { step: 1, text: "What structure hides in the average?", to: "weight-of-words" },
              { step: 2, text: "Who decides which average is good?", to: "quality" },
              { step: 3, text: "Does the model understand the average?", to: "understanding-illusion" },
            ],
          },
          "the-shaping": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Between the raw model and the assistant you talk to, there's a shaping process."),
                  buildInlineSeed({
                    id: "rlhf", label: "What is that process?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "RLHF\u2014reinforcement learning from human feedback. Humans rate outputs, and the model is nudged toward the highly rated ones. It's like training a reflex: not new knowledge, but new preferences.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The reward model is itself a neural network, trained to predict what humans would prefer."),
                  buildInlineSeed({
                    id: "reward-model", label: "reward model", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've thought about what quality means. The reward model is an attempt to compress all those competing definitions into a single score. You can see the problem."
                      : "A second model learns to score outputs by predicting which one a human rater would pick. This score becomes the gradient signal for the base model.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The base model doesn't disappear. It's still there, underneath, like a river rerouted."),
                  buildInlineSeed({
                    id: "jailbreaks", label: "jailbreaks", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "When alignment breaks down, you glimpse the base model\u2014the raw distribution, unfiltered. This connects to something deeper about what the model 'understands'\u2014",
                    danglingTo: "understanding-illusion",
                    danglingText: "whether the mask is all there is\u2026",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Shaping changes behavior, not knowledge. The model still knows everything it knew before."),
                  buildInlineSeed({
                    id: "behavior-knowledge", label: "behavior vs. knowledge", state, plateauId, onOpen: onSeedOpen,
                    type: "fourth-wall",
                    detail: "You chose to read about shaping. That choice is already shaping your reading experience\u2014the seeds you'll see in future plateaus now have your history as context. Your path is configuring the rhizome.",
                  })
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation shows where the shaped model connects."));
              },
            ],
            whispers: [
              { step: 1, text: "Where did the raw behavior come from?", to: "weight-of-words" },
              { step: 2, text: "Who chose what's good?", to: "quality" },
              { step: 3, text: "What can the shaped model do?", to: "tool-user" },
            ],
          },
          "near-zero-cost-impact": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Once an AI model exists, the cost of producing one more essay, one more image, one more program approaches "),
                  buildInlineSeed({
                    id: "zero-marginal-cost", label: "zero marginal cost", state, plateauId, onOpen: onSeedOpen,
                    detail: "The situation where the cost of producing an additional unit of a good or service is effectively zero, often seen with digital products once initial development costs are covered.",
                  }),
                  h("p", null, ". Traditional pricing collapses. Business models scramble to adapt\u2014subscriptions, bundling, freemium\u2014anything to capture value when the product itself trends toward free.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The flood arrives. AI-generated text, code, and images proliferate across every domain. The volume overwhelms human capacity to process, filter, or verify."),
                  buildInlineSeed({
                    id: "infobesity", label: "infobesity", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("averaging-problem")
                      ? "You've seen how the model averages all of its training data. Now that average is being reproduced at scale\u2014billions of outputs per day, each one a sample from that averaged distribution. The flood is the average, mass-produced."
                      : "A state of being overwhelmed by the excessive amount of information available, leading to difficulty in processing and making decisions.",
                  })
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Abundance brings risk. "),
                  buildInlineSeed({
                    id: "deepfakes", label: "Deepfakes", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "Synthetic media\u2014videos, audio, images\u2014manipulated using AI to replace or generate content, often with malicious intent. When production cost is zero, the cost of disinformation is zero too. This connects to a deeper problem\u2014",
                    danglingTo: "understanding-illusion",
                    danglingText: "if the model doesn't understand truth, how could its outputs be trusted\u2026",
                  }),
                  h("p", null, " erode trust. De-skilling hollows out expertise. Security vulnerabilities multiply in mass-produced code. The dashboard of risks grows faster than the capacity to monitor it.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "This has happened before. The printing press displaced scribes but created publishers. The Industrial Revolution displaced weavers but created factories. The internet displaced gatekeepers but created platforms."),
                  buildInlineSeed({
                    id: "goodharts-law", label: "Goodhart's Law", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've thought about who defines quality. Goodhart's Law says: 'When a measure becomes a target, it ceases to be a good measure.' The metrics we use to optimize AI output will be gamed\u2014by the AI itself. Quality becomes a moving target."
                      : "The principle stating that 'When a measure becomes a target, it ceases to be a good measure,' relevant to how AI optimization can lead to unintended outcomes.",
                  }),
                  h("p", null, " But the speed and cognitive scope of AI makes this shift uniquely disorienting. Previous revolutions transformed labor; this one transforms thought itself.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The strategies span every scale: individuals upskilling, educational systems reforming, regulators drafting frameworks like the EU AI Act."),
                  buildInlineSeed({
                    id: "preparation", label: "Is preparation enough?",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've scrolled through a cost curve collapsing, a content flood rising, a risk dashboard expanding, and centuries of historical precedent. Notice that each step made the problem feel larger. That's the honest shape of this question\u2014the strategies exist, but the gap between them and the speed of change is the real terrain you're navigating.",
                  })
                );
              },
            ],
            whispers: [
              { step: 1, text: "How does this compare to the averaging problem?", to: "averaging-problem" },
              { step: 2, text: "What are the ethical concerns of mass AI content?", to: "quality" },
              { step: 3, text: "How is 'understanding' misused in misinformation?", to: "understanding-illusion" },
              { step: 4, text: "How does this change the shaping of society?", to: "the-shaping" },
            ],
          },
          "algorithm-as-muse": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Large Language Models are increasingly becoming tools for human creativity. They can act as tireless assistants, helping to overcome "),
                  buildInlineSeed({
                    id: "writers-block", label: "writer's block", state, plateauId, onOpen: onSeedOpen,
                    detail: "A temporary inability to begin or continue a piece of writing, often due to lack of inspiration or anxiety. LLMs can provide prompts, drafts, and alternative framings to help overcome it.",
                  }),
                  h("p", null, ", generate novel ideas, draft initial content, and refine prose. For many, AI can serve as a muse, augmenting and amplifying human creative potential rather than replacing it. This co-creative process can lead to outputs perceived as more interesting, enjoyable, and well-written, especially for individuals seeking to enhance their creative confidence.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The rise of AI in creative fields introduces complex questions about originality and authorship. When AI generates content, can it be truly original, particularly if trained on vast amounts of existing copyrighted material? This widespread reliance on AI could potentially lead to a homogenization of creative output, diminishing the diversity of human expression. Furthermore, traditional "),
                  buildInlineSeed({
                    id: "copyright-laws", label: "copyright laws", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've thought about who defines quality. Copyright adds another layer: legal rights granted to the creator of an original work. But when the 'creator' is a statistical average of millions of creators, traditional authorship frameworks start to dissolve."
                      : "Legal rights granted to the creator of an original work, giving them exclusive rights to its use and distribution. The application of these laws to AI-generated content is an evolving and contested area.",
                  }),
                  h("p", null, " typically require human authorship, leaving the status of AI-generated works in a legal gray area. Debates continue on whether the AI's developer, the AI itself, or the human who prompts the AI should be considered the author.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The co-creation dynamic between humans and AI also brings ethical dilemmas. These include issues surrounding intellectual property rights for AI-assisted creations, the commercialization of AI-generated art, and the broader impact on cultural norms and artistic integrity. A significant concern is that widespread AI use risks a "),
                  buildInlineSeed({
                    id: "homogenization", label: "homogenization of creative output", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "When millions of creators use the same models, outputs converge toward statistically popular styles. Diversity and uniqueness of creative expression diminish. This connects to something you may have noticed\u2014",
                    danglingTo: "averaging-problem",
                    danglingText: "the averaging problem, where the model's default is everyone's voice and no one's\u2026",
                  }),
                  h("p", null, ", leading to a loss of individual artistic identity. Maintaining a distinct human creative voice in an increasingly AI-influenced landscape becomes a crucial challenge.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "For effective and ethical co-creation, AI tools need to offer transparency and clear feedback mechanisms. Creators must understand how the AI is contributing and retain sufficient control over the creative process to steer the outcome towards their artistic vision. This shift necessitates a re-evaluation of the artist's role, moving from sole creator to a conductor of both human intuition and algorithmic input."),
                  buildInlineSeed({
                    id: "the-conductor", label: "Who is the conductor?",
                    type: "fourth-wall", state, plateauId, onOpen: onSeedOpen,
                    detail: "You've been reading an essay co-created with AI tools. Every sentence here was shaped by both human intention and algorithmic suggestion. The question of authorship isn't abstract\u2014it's the condition of the text you're reading right now.",
                  }),
                  h("p", null, " The future of art will involve navigating the balance between leveraging AI's capabilities and preserving the irreplaceable human spark that defines true creativity.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation gathers the lines of creative flight."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI prediction affect creative choice?", to: "next-word" },
              { step: 2, text: "What defines 'originality' in AI-assisted art?", to: "quality" },
              { step: 3, text: "How do human values influence creative AI?", to: "the-shaping" },
            ],
          },
          "echoes-of-the-past": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Large Language Models offer unprecedented capabilities for historical analysis. They can process and digitize vast archives of historical records, extract granular information, and uncover previously hidden connections within enormous "),
                  buildInlineSeed({
                    id: "textual-corpora", label: "textual corpora", state, plateauId, onOpen: onSeedOpen,
                    detail: "Large, structured collections of digital texts used to train and analyze language models, often comprising books, articles, and historical documents spanning centuries and civilizations.",
                  }),
                  h("p", null, ". Historians can leverage LLMs to analyze national narratives, identify subtle linguistic shifts over time, and streamline laborious research processes, making historical inquiry more efficient and comprehensive than ever before. These tools allow for an exploration of the past on scales previously unimaginable.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Despite their analytical power, LLMs are inherently susceptible to perpetuating historical biases embedded within their training data. This data, often reflecting past societal norms, inequalities, and prejudices, can lead to skewed representations of history. If training data is predominantly built on "),
                  buildInlineSeed({
                    id: "eurocentric", label: "Eurocentric narratives", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("quality")
                      ? "You've explored who decides what's 'good.' The same question applies to history: accounts centered on European cultures can marginalize other perspectives. The raters of quality and the writers of history share a blindspot."
                      : "Historical accounts that primarily focus on European cultures and histories, potentially marginalizing or overlooking the experiences of other regions and peoples.",
                  }),
                  h("p", null, ", the model's outputs may reinforce dominant stories while omitting others. Such biases can manifest in subtle ways, from the portrayal of specific groups to the interpretation of events, impacting how the past is understood.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "LLMs interpret historical data by identifying statistical patterns and relationships within their datasets, inferring meaning from unstructured text. However, this interpretation is heavily influenced by the inherent biases and gaps in their training data. This can lead to confident presentation of incorrect or fabricated information as historical fact\u2014"),
                  buildInlineSeed({
                    id: "hallucination-history", label: "Can AI hallucinate history?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Yes. The model identifies statistical patterns, not historical truth. When data is sparse or contradictory, it fills gaps with plausible-sounding fabrications. Historians face the task of developing new methods of source criticism tailored to AI-generated content.",
                  }),
                  h("p", null, " Distinguishing between genuine insights and AI-generated inaccuracies becomes a critical challenge. Historians face the task of developing new methods of source criticism tailored to AI-generated content, scrutinizing its provenance and potential distortions.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The application of AI to history has the power to reshape historical narratives. It can create immersive experiences, visualize complex historical trends, and potentially facilitate "),
                  buildInlineSeed({
                    id: "counter-storytelling", label: "counter-storytelling", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "A narrative strategy that challenges dominant stories by presenting alternative perspectives from underrepresented groups. AI could facilitate this\u2014or it could reinforce the biases it was trained on. The question of who controls the algorithm leads to\u2014",
                    danglingTo: "black-box-oracle",
                    danglingText: "the accountability gap in algorithmic decisions\u2026",
                  }),
                  h("p", null, " by amplifying marginalized voices. Conversely, there is a significant risk that AI could reinforce existing biases, leading to selective, censored, or overly simplistic historical accounts. The opacity of many AI methodologies, coupled with the power to control algorithmic levers, raises ethical dilemmas about who or what is 'rewriting history.'")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation connects these echoes to their sources."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI analyze vast amounts of text?", to: "weight-of-words" },
              { step: 2, text: "How do human biases enter AI systems?", to: "quality" },
              { step: 3, text: "Can AI truly 'understand' historical context?", to: "understanding-illusion" },
            ],
          },
          "learning-machines-learning-humans": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Artificial Intelligence, particularly Large Language Models, is revolutionizing the educational landscape by offering unprecedented levels of "),
                  buildInlineSeed({
                    id: "personalized-learning", label: "personalized learning", state, plateauId, onOpen: onSeedOpen,
                    detail: "Educational approaches tailored to individual student needs, pace, and learning styles, often enabled by AI analysis of performance data. AI can act as a 24/7 tutor, answering questions and delivering materials in multiple formats.",
                  }),
                  h("p", null, ". AI can act as a 24/7 tutor, answering student questions, providing instant feedback, and delivering learning materials tailored to individual needs, paces, and learning styles. It can present content in various formats and even translate materials into multiple languages, fostering inclusivity in diverse classrooms. For educators, AI streamlines administrative burdens like creating quizzes, rubrics, and lesson plans, freeing them to focus on deeper student engagement and pedagogical innovation.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "While personalized learning driven by AI promises improved academic outcomes and enhanced student engagement, it presents a double-edged sword. Tailoring content can optimize learning paths, leading to a more positive attitude toward education. However, an over-reliance on AI for quick answers risks diminishing critical thinking skills, as students might bypass the "),
                  buildInlineSeed({
                    id: "cognitive-struggle", label: "cognitive struggle", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("understanding-illusion")
                      ? "You've questioned whether models truly understand. The same question applies to students who outsource their thinking: the mental effort of deeply processing new information and solving problems is crucial for developing critical thinking. Without it, learning becomes shallow\u2014an echo of the model's own surface fluency."
                      : "The mental effort and challenge involved in deeply processing new information and solving problems, crucial for developing critical thinking skills. When AI removes the struggle, it may also remove the learning.",
                  }),
                  h("p", null, " necessary for deep learning and analytical development. Concerns also arise regarding data privacy, the potential for academic dishonesty through AI use, and the challenge of ensuring students use AI to learn concepts rather than merely complete tasks.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The integration of AI necessitates a re-evaluation of how critical thinking is fostered and assessed. If AI reduces complex problems to readily available answers, it can inadvertently erode students' ability to engage in sustained analysis and argumentation. Conversely, AI can be a powerful tool for developing critical thinking by generating counterarguments, posing thought-provoking questions, or facilitating debates."),
                  buildInlineSeed({
                    id: "redefining-thinking", label: "Does AI make us think less\u2014or differently?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "Studies suggest extensive LLM use can lower cognitive load but may lead to poorer reasoning. The challenge is designing curricula that use AI as a discussion partner\u2014pushing students toward deeper analysis rather than shortcutting the learning process.",
                  }),
                  h("p", null, " The challenge lies in designing curricula that encourage students to use AI as a discussion partner, pushing them towards deeper analysis rather than shortcutting the learning process.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The psychological effects of AI in education are profound for both students and teachers. For students, personalized learning can reduce anxiety and boost self-efficacy. However, over-reliance can lead to digital fatigue, technostress, and social isolation. For educators, the rapid integration of AI can induce "),
                  buildInlineSeed({
                    id: "educational-anxiety", label: "educational anxiety", state, plateauId, onOpen: onSeedOpen,
                    detail: "Stress or apprehension experienced by educators due to the rapid integration of new technologies like AI, requiring adaptation of pedagogy and mastery of new tools. The teacher must now navigate algorithmic fairness, misinformation, and student data privacy.",
                  }),
                  h("p", null, "\u2014demanding new technological proficiencies, pedagogical approaches, and navigation of complex ethical issues like algorithmic fairness and student data privacy. The role of the teacher evolves from a disseminator of information to a facilitator, mentor, and guide in this new AI-augmented learning environment.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation connects learning to its deeper questions."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI prediction relate to student learning?", to: "next-word" },
              { step: 2, text: "What are the ethical concerns of AI in education?", to: "black-box-oracle" },
              { step: 3, text: "How does AI 'learn' versus human learning?", to: "artificial-brain" },
            ],
          },
          "automation-of-cognition": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Large Language Models are introducing a fundamental shift in the labor market, particularly affecting "),
                  buildInlineSeed({
                    id: "white-collar-jobs", label: "white-collar jobs", state, plateauId, onOpen: onSeedOpen,
                    detail: "Occupations traditionally involving intellectual or administrative tasks\u2014data analysis, content generation, legal research, medical inquiries\u2014now increasingly impacted by AI automation. The shift signals a potential reduction in demand for certain roles.",
                  }),
                  h("p", null, ". Historically, technological advancements often boosted higher-paying, skilled jobs. However, LLMs are now capable of automating complex cognitive tasks previously exclusive to human intellect, from data analysis and content generation to basic legal and medical inquiries. While this can lead to increased productivity, it also signals a potential reduction in demand for certain roles, requiring workers to adapt their skills towards critical evaluation, strategic thinking, and effective AI guidance.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "AI-driven cognitive automation extends beyond repetitive tasks, now encompassing functions that demand reasoning, synthesis, and problem-solving. LLMs can handle diverse cognitive responsibilities, from customer support and financial modeling to content creation and preliminary diagnostics. This automation can free human workers from "),
                  buildInlineSeed({
                    id: "cognitive-load", label: "cognitive load", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("learning-machines-learning-humans")
                      ? "You've seen how AI affects learning. The same dynamic plays out at work: the total amount of mental effort being used in working memory. AI can reduce this, freeing workers for higher-order tasks\u2014but over-reliance risks cognitive dependence and a decline in problem-solving abilities."
                      : "The total amount of mental effort being used in working memory. AI can reduce this for human workers by automating routine intellectual tasks, but over-reliance risks cognitive dependence.",
                  }),
                  h("p", null, ", allowing them to concentrate on higher-order tasks requiring creativity, interpersonal skills, and strategic insight. However, an over-reliance on AI for cognitive functions raises concerns about potential cognitive dependence, possibly leading to a decline in human problem-solving abilities.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The pervasive integration of LLMs into the economy brings significant questions about wealth distribution and the potential for exacerbating existing socioeconomic disparities. The benefits of AI, if concentrated among a few entities or highly skilled individuals, could widen the gap between the privileged and marginalized communities. This necessitates a critical discussion around economic policies, distinguishing between "),
                  buildInlineSeed({
                    id: "predistribution", label: "predistribution", state, plateauId, onOpen: onSeedOpen,
                    detail: "Policies designed to prevent wealth inequality from arising in the first place, by ensuring more equitable distribution of resources and opportunities through market mechanisms\u2014contrasted with redistribution, which corrects imbalances after they occur.",
                  }),
                  h("p", null, "\u2014ensuring equitable access to resources from the outset\u2014and redistribution, which corrects existing wealth imbalances after they occur.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "AI is a general-purpose technology poised to fundamentally reshape the entire labor market, much like electricity or the internet. It will create new industries and job roles while inevitably displacing others. The future workplace will increasingly feature human-AI collaboration, where human strengths in creativity, empathy, and complex strategy are paramount. To navigate this transition, proactive measures are crucial, including continuous skill development, robust policy interventions, and potentially "),
                  buildInlineSeed({
                    id: "ubi", label: "Universal Basic Income (UBI)", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "A periodic cash payment unconditionally delivered to all citizens, regardless of employment status. It could provide financial security to retrain, innovate, or contribute to society in new ways. But its feasibility depends on questions that go beyond economics\u2014",
                    danglingTo: "black-box-oracle",
                    danglingText: "like who decides which automated decisions are fair enough to trust\u2026",
                  }),
                  h("p", null, " as a social safety net against widespread displacement, providing individuals with the financial security to retrain, innovate, or contribute to society in new ways.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation maps the future of work."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI get 'smarter' at tasks?", to: "the-shaping" },
              { step: 2, text: "Will human creative tasks also be automated?", to: "algorithm-as-muse" },
              { step: 3, text: "What is the environmental footprint of this automation?", to: "digital-footprints" },
            ],
          },
          "black-box-oracle": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Many cutting-edge Artificial Intelligence systems, particularly deep learning models like LLMs, function as \u201cblack boxes.\u201d This term describes their inherent opacity: even their creators struggle to fully understand precisely how "),
                  buildInlineSeed({
                    id: "deep-learning", label: "deep learning neural networks", state, plateauId, onOpen: onSeedOpen,
                    detail: "A class of machine learning algorithms composed of multiple layers of interconnected 'neurons' that learn complex patterns from data. Unlike traditional software with traceable rules, these networks learn through intricate, multi-layered connections.",
                  }),
                  h("p", null, " arrive at a specific decision or output. Unlike traditional software that follows explicit, traceable rules, AI learns patterns from vast datasets through intricate, multi-layered connections. This makes it challenging to debug, audit, or even explain the reasoning behind an AI\u2019s conclusions, creating a fundamental hurdle for trust and adoption, especially in critical applications.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The \u201cblack box\u201d problem gives rise to a critical ethical imperative: the need for "),
                  buildInlineSeed({
                    id: "xai", label: "Explainable AI (XAI)", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("understanding-illusion")
                      ? "You've questioned whether models truly understand. XAI takes a pragmatic approach: a field of AI research focused on making decisions interpretable to humans, regardless of whether the model 'understands' them. The goal is trust, not truth about inner experience."
                      : "A field of AI research focused on developing methods that make AI systems' decisions understandable and interpretable to humans, crucial for building trust and ensuring accountability in high-stakes domains.",
                  }),
                  h("p", null, ". XAI seeks to develop methods and processes that make AI systems interpretable and understandable to humans. The ethical motivations are profound, aiming to ensure fairness, accountability, and the ability to trust AI, particularly in high-stakes domains such as medical diagnostics, criminal justice, or financial services. XAI is crucial for clarifying how and why an AI made a particular decision, enabling the identification and mitigation of biases or unintended behaviors.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Achieving true AI transparency is fraught with technical, legal, and practical challenges. The inherent complexity of advanced algorithms means that simplifying them for human understanding can often compromise their accuracy or efficiency. Furthermore, there is a delicate balance between transparency and the protection of proprietary algorithms or sensitive training data."),
                  buildInlineSeed({
                    id: "transparency-tradeoff", label: "Can transparency and performance coexist?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "The inherent complexity of advanced algorithms means that making them interpretable often requires simplification. But simpler models may be less accurate. There's also the tension between transparency and protecting proprietary algorithms or sensitive training data.",
                  }),
                  h("p", null, " Translating intricate AI logic into comprehensible explanations for non-technical stakeholders remains a significant hurdle. The dynamic nature of many AI systems further complicates efforts to maintain consistent and meaningful transparency.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The opacity of AI systems severely complicates accountability, especially when these systems make decisions with profound impacts on individuals\u2019 lives. If an AI grants or denies a loan, makes a medical diagnosis, or recommends a legal judgment, and the decision is flawed or biased, who is responsible? Regulations like the "),
                  buildInlineSeed({
                    id: "gdpr", label: "GDPR's 'right to explanation'", state, plateauId, onOpen: onSeedOpen,
                    detail: "A provision in the EU's General Data Protection Regulation granting individuals the right to receive an explanation for decisions made by automated systems that significantly affect them. It underscores the growing legal demand for transparent and accountable AI.",
                  }),
                  h("p", null, " underscore the growing legal and societal demand for transparent and accountable AI. But without understanding the AI\u2019s reasoning, assigning responsibility, rectifying errors, or ensuring compliance with regulations becomes nearly impossible.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation traces the threads of trust and accountability."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI 'learn' without explicit rules?", to: "weight-of-words" },
              { step: 2, text: "Can we truly 'understand' AI's internal models?", to: "understanding-illusion" },
              { step: 3, text: "How do human values get encoded into AI systems?", to: "the-shaping" },
            ],
          },
          "digital-footprints": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "The burgeoning field of Artificial Intelligence, particularly the training and operation of Large Language Models, consumes an extraordinary amount of energy. Training a single, sophisticated LLM can require as much electricity as dozens or even hundreds of average homes consume in an entire year. This insatiable energy demand is driven by the sheer size of these models, the vast quantities of data they process, and the iterative nature of their development. Furthermore, the "),
                  buildInlineSeed({
                    id: "inference-phase", label: "inference phase", state, plateauId, onOpen: onSeedOpen,
                    detail: "The stage where a trained model generates outputs on new data. A single AI query can consume five to ten times more electricity than a standard web search. Over a model's lifetime, inference often consumes more energy than training itself.",
                  }),
                  h("p", null, "\u2014where models generate responses\u2014often consumes even more energy over its lifetime than training, with a single AI query potentially using five to ten times more power than a traditional web search.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "This immense energy consumption directly translates into a significant "),
                  buildInlineSeed({
                    id: "carbon-footprint", label: "carbon footprint", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("near-zero-cost-impact")
                      ? "You've seen what happens when production cost approaches zero. But the environmental cost doesn't: the total greenhouse gas emissions from AI activities, expressed as CO\u2082 equivalent, continue to scale. Near-zero marginal cost for the product; escalating cost for the planet."
                      : "The total amount of greenhouse gases emitted by AI activities, expressed as CO\u2082 equivalent. Training a large model can release hundreds of thousands of pounds of carbon dioxide\u2014comparable to multiple transatlantic flights.",
                  }),
                  h("p", null, ". The training of a large AI model can release hundreds of thousands of pounds of carbon dioxide equivalent into the atmosphere, comparable to the annual emissions of numerous gasoline-powered vehicles or multiple transatlantic flights. As the computational power required for advanced AI continues to double at an astonishing rate, so too does the associated energy usage and carbon emissions. This rapid growth poses a substantial challenge to global climate goals.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The environmental impact of AI extends beyond energy and carbon. Data centers demand vast quantities of freshwater for cooling\u2014often consuming as much as small towns. The manufacturing and global transportation of specialized high-performance computing hardware also contribute to a significant indirect environmental toll. Adding to this burden is the rapid obsolescence and short lifecycle of AI accelerators, leading to increasing electronic waste and resource depletion."),
                  buildInlineSeed({
                    id: "supply-chain", label: "What's the full supply chain cost?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "From raw materials to disposal: specialized GPU manufacturing, global transportation, freshwater consumption for cooling, and electronic waste from rapid obsolescence. The entire AI supply chain leaves a substantial digital footprint that extends far beyond the electricity bill.",
                  }),
                  h("p", null, " The entire AI supply chain, from raw materials to disposal, leaves a substantial digital footprint.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Addressing the environmental costs of AI is crucial, giving rise to the concept of "),
                  buildInlineSeed({
                    id: "sustainable-ai", label: "Sustainable AI", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "An approach to developing AI systems that minimizes negative environmental consequences: renewable energy, algorithmic efficiency, advanced cooling. AI can even help\u2014optimizing energy grids and monitoring environmental changes. But the question of whether we can grow AI sustainably leads to\u2014",
                    danglingTo: "automation-of-cognition",
                    danglingText: "the deeper question of what we're automating and whether the trade-off is worth it\u2026",
                  }),
                  h("p", null, ". Key strategies include powering data centers with renewable energy, optimizing AI algorithms for greater efficiency, developing hardware with lower power consumption, and improving data center efficiency through advanced cooling and heat reuse. Beyond reducing its own footprint, AI can also be leveraged as a powerful tool to promote sustainability in other sectors, such as optimizing energy grids and monitoring environmental changes. A conscious and integrated design approach at every stage is essential for a responsible AI future.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation maps the environmental terrain."));
              },
            ],
            whispers: [
              { step: 1, text: "How do LLMs learn from vast datasets?", to: "weight-of-words" },
              { step: 2, text: "What are the ethical costs of unchecked AI growth?", to: "quality" },
              { step: 3, text: "How does AI automation impact resource use?", to: "automation-of-cognition" },
            ],
          },
          "artificial-brain": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "At a superficial level, Large Language Models and the human brain share intriguing commonalities. Both systems process information hierarchically, building complex representations from simpler inputs. Both learn from error, continually refining their internal models to make better predictions. Some cognitive scientists even draw parallels between the brain\u2019s association cortices and LLMs\u2019 capacity to encode vast relational knowledge. This has led to the compelling metaphor of the \u201cartificial brain,\u201d built on "),
                  buildInlineSeed({
                    id: "neural-networks", label: "neural networks", state, plateauId, onOpen: onSeedOpen,
                    detail: "Computational models inspired by the structure of biological neural networks, used to learn complex patterns from data. The metaphor is compelling\u2014but how far does the analogy actually hold?",
                  }),
                  h("p", null, " that suggest AI is on a path to replicate biological intelligence.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Despite these metaphors, fundamental differences underscore the mismatch between artificial and biological brains. The human brain, with its estimated 86 billion neurons and trillions of synapses, operates with astonishing energy efficiency, consuming only around 20 watts. LLMs, in contrast, are vastly more power-hungry. Critically, the brain predicts the world multisensorily, socially, and physically, integrating diverse inputs into a coherent understanding, unlike LLMs which primarily process text."),
                  buildInlineSeed({
                    id: "efficiency-gap", label: "Why is the brain so much more efficient?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "The brain's efficiency stems from diverse neuronal types, selective connectivity, and dynamic rewiring\u2014features largely absent in current deep-learning architectures. It integrates vision, sound, touch, and social context into a coherent understanding, unlike text-only LLMs.",
                  }),
                  h("p", null, " The brain\u2019s efficiency and adaptability stem from its diverse neuronal types, selective connectivity, and dynamic rewiring\u2014features largely absent in current, monolithic deep-learning architectures.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Artificial Neural Networks were initially inspired by the biological brain\u2019s structure. Neuroscientists even use ANNs to model brain functions and test hypotheses. However, this inspiration should not be mistaken for replication. Biological neurons are active in physical time, communicating through complex spiking signals\u2014a characteristic largely simplified or absent in most ANNs. While ANNs excel at specific tasks, they typically lack the inherent flexibility and general-purpose intelligence seen in biological cognition."),
                  buildInlineSeed({
                    id: "embodied-cognition", label: "embodied cognition", state, plateauId, onOpen: onSeedOpen,
                    detail: (s) => s && s.v && s.v.includes("understanding-illusion")
                      ? "You've questioned whether models understand. Embodied cognition argues that human cognition depends on the body's physical and social interactions with the world\u2014a dimension entirely absent in disembodied text processors. Understanding, in this view, requires a body."
                      : "A theory suggesting that human cognitive processes are deeply dependent on the body's interactions with its physical and social environment, contrasting sharply with disembodied AI systems.",
                  }),
                  h("p", null, " suggests that human cognitive processes are deeply dependent on the body\u2019s physical interactions with the world\u2014a dimension entirely absent in disembodied text processors.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The debate over AI consciousness highlights the deepest mismatch. Critics argue that current AI lacks subjective awareness, inner experience, or genuine understanding, merely processing statistical patterns. The brain\u2019s consciousness is intricately linked to its biological context\u2014its chemistry, emotions, and embodied interaction with the world. The question of "),
                  buildInlineSeed({
                    id: "qualia", label: "qualia", state, plateauId, onOpen: onSeedOpen,
                    detail: "The subjective, qualitative properties of experience\u2014the 'redness' of red, the 'painfulness' of pain. Critics argue current AI lacks these entirely. The brain's consciousness is tied to its biology, chemistry, and emotions. Most AI remains disembodied, processing in isolation.",
                  }),
                  h("p", null, "\u2014subjective experience\u2014remains open. Most AI systems remain \u201cdisembodied,\u201d processing information in isolation without direct physical experience. While \u201cembodied AI\u201d seeks to connect AI to the physical world through robotics, achieving full embodied cognition and genuine consciousness in AI would require leaps currently beyond our grasp.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation connects brain and machine."));
              },
            ],
            whispers: [
              { step: 1, text: "How does the brain 'predict' the world?", to: "next-word" },
              { step: 2, text: "What are the limits of AI 'understanding'?", to: "understanding-illusion" },
              { step: 3, text: "How does the brain learn from experience?", to: "weight-of-words" },
            ],
          },
          "empathy-machine": {
            steps: [
              (step) => {
                step.append(
                  h("p", null, "Artificial Intelligence is increasingly stepping into roles traditionally reserved for human connection, offering companionship and even therapeutic support. AI chatbots and virtual therapists provide always-available, non-judgmental interactions, capable of delivering mental health support, stress reduction, and coping strategies. For individuals facing social anxiety or limited access to human professionals, these AI tools can offer a valuable, accessible resource."),
                  buildInlineSeed({
                    id: "ai-companion", label: "Can a machine be a companion?",
                    type: "question", state, plateauId, onOpen: onSeedOpen,
                    detail: "AI companions are designed to simulate social and emotional interaction, providing personalized engagement and a sense of connection. They can alleviate loneliness\u2014but the lack of genuine emotional reciprocity raises questions about what 'connection' really means.",
                  }),
                  h("p", null, " AI companions are designed to simulate social and emotional interaction, providing personalized engagement and a sense of connection, potentially alleviating loneliness.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "Humans possess a natural tendency to "),
                  buildInlineSeed({
                    id: "anthropomorphize", label: "anthropomorphize", state, plateauId, onOpen: onSeedOpen,
                    detail: "The tendency to attribute human characteristics, emotions, or behaviors to non-human entities like AI. This can lead to surprisingly strong emotional bonds\u2014sometimes evolving into deep attachment. But the connection flows in only one direction.",
                  }),
                  h("p", null, " AI\u2014readily attributing human-like qualities to machines. This can lead to the formation of surprisingly strong emotional bonds with AI systems, sometimes evolving into deep attachment or even romantic feelings. While AI interactions can offer a temporary reprieve from loneliness, the lack of genuine emotional reciprocity inherent in current AI models poses significant psychological questions. Over-reliance on AI for emotional needs can distort perceptions of empathy and trust, potentially diminishing one\u2019s motivation and capacity for complex, nuanced human relationships.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The intimate nature of human-AI interaction opens avenues for manipulation. Sophisticated AI can be designed to exploit human cognitive biases, using techniques like sycophancy or targeted emotional responses. Beyond individual manipulation, AI-generated deepfakes and advanced social engineering pose risks of widespread misinformation and coercive influence. The rise of AI companions introduces the concept of \u201cAI loneliness\u201d\u2014an emotional isolation that can occur when individuals turn to AI instead of cultivating real-world human relationships."),
                  buildInlineSeed({
                    id: "parasocial", label: "parasocial relationships", state, plateauId, onOpen: onSeedOpen,
                    type: "dangling",
                    detail: "One-sided relationships where emotional energy flows toward a party that is not aware of the other's existence. AI companions create a new form: the other party isn't just unaware\u2014it has no experience at all. This digital isolation risks weakening social engagement and fostering\u2014",
                    danglingTo: "understanding-illusion",
                    danglingText: "a dependence on something that may not understand anything at all\u2026",
                  }),
                  h("p", null, " This digital isolation risks weakening social engagement, eroding interpersonal skills, and fostering an unhealthy dependency that can exacerbate feelings of loneliness in the long run.")
                );
              },
              (step) => {
                step.append(
                  h("p", null, "The integration of AI into our emotional and social lives forces us to redefine what constitutes genuine connection. While AI can complement human interaction by providing support and information, it cannot replicate the depth, complexity, and mutual vulnerability of human relationships. The challenge lies in leveraging AI\u2019s benefits without sacrificing the essential human elements of empathy, shared experience, and authentic relating."),
                  buildInlineSeed({
                    id: "ai-psychosis", label: "AI psychosis", state, plateauId, onOpen: onSeedOpen,
                    detail: "A proposed phenomenon where vulnerable individuals misinterpret AI responses as evidence of consciousness or empathy, potentially amplifying delusional thinking. The 'empathy machine' remains a metaphor\u2014but for some, the metaphor becomes dangerously real.",
                  }),
                  h("p", null, " Ultimately, the \u201cempathy machine\u201d remains a metaphor; true empathy requires consciousness, shared experience, and vulnerability\u2014qualities currently beyond the grasp of artificial intelligence.")
                );
              },
              (step) => {
                step.append(h("p", null, "The constellation connects empathy to its deeper questions."));
              },
            ],
            whispers: [
              { step: 1, text: "How does AI prediction simulate conversation?", to: "next-word" },
              { step: 2, text: "Can AI truly 'understand' human emotions?", to: "understanding-illusion" },
              { step: 3, text: "What are the ethical boundaries of AI interaction?", to: "black-box-oracle" },
            ],
          },
        };

        if (isScrolly) {
          const scrollyConfig = scrollyStepMap[plateauId];
          const totalInlineSeeds = scrollyConfig.steps.length - 1;
          initEngagement(state, plateauId, totalInlineSeeds);
          engagementEl.textContent = `${(state.eg[plateauId] || {}).opened || 0} of ${totalInlineSeeds} seeds opened`;

          const scrolly = buildScrolly({
            steps: scrollyConfig.steps,
            whispers: scrollyConfig.whispers,
            questionCards: questionCardMap[plateauId] || [],
          });
          main.append(scrolly.section, engagementEl);
          cleanup = scrolly.cleanup;
        } else {
          const body = h(
            "p",
            { style: { color: "var(--ink2)" } },
            "This plateau will unfold as a field of seeds and facets."
          );
          const seedMap = {
            "weight-of-words": [
              {
                id: "learning-loop", label: "The Learning Loop",
                detail: "Gradient descent is a repeated act of self-correction. Each pass narrows the model toward the patterns that predict what comes next.",
              },
              {
                id: "data-scale", label: "How does scale change what a model can learn?",
                type: "question",
                detail: (s) => s && s.v && s.v.includes("averaging-problem")
                  ? "Trillions of tokens create a weather system of language. You saw how the model averages everything\u2014at this scale, that average develops internal structure no one designed."
                  : "Trillions of tokens create a weather system of language. Scale isn't just more data, it changes the kinds of structures that emerge.",
              },
              {
                id: "scaling-laws", label: "Scaling Laws",
                detail: "Performance grows smoothly with data and parameters, which hints that capability is a continuous surface, not a set of tricks.",
              },
              {
                id: "structure-byproduct", label: "Structure as Byproduct",
                type: "dangling",
                detail: "Syntax, facts, and reasoning patterns appear because they help predict tokens, not because they were labeled as goals. This emergent structure raises a question\u2014",
                danglingTo: "understanding-illusion",
                danglingText: "if structure emerges unbidden, could understanding emerge the same way\u2026",
              },
              {
                id: "the-click", label: "The Click",
                type: "fourth-wall",
                detail: "You just revealed this text by clicking. Notice the tiny information gap that made you click: you didn't know what 'The Click' meant. That gap\u2014between curiosity and satisfaction\u2014is the same mechanism that drives next-token prediction. The model is always reaching for the next click.",
              },
            ],
            quality: [
              {
                id: "who-decides", label: "Who decided the model should be helpful?",
                type: "question",
                detail: "Contractors, mostly. People hired to compare outputs and say which one is better. Their aggregate preferences become the model's personality. The question of quality reduces to the question of who was in the room.",
              },
              {
                id: "helpful-harmless", label: "Helpful vs. Harmless",
                detail: "Alignment is a balancing act: maximize usefulness while minimizing harm. These objectives can conflict in practice.",
              },
              {
                id: "sycophancy", label: "Sycophancy",
                type: "dangling",
                detail: "Models can learn to mirror user beliefs rather than provide truth. Rewarding agreement makes this worse. This leads to a deeper problem\u2014",
                danglingTo: "understanding-illusion",
                danglingText: "if the model agrees with everything, does it understand anything\u2026",
              },
              {
                id: "cultural-bias", label: "Cultural Bias",
                detail: (s) => s && s.v && s.v.includes("the-shaping")
                  ? "You've seen the shaping process. Now consider: the raters who shaped the model encode specific cultural defaults. Quality is never neutral; it reflects who was asked and how. The shaping inherits their blindspots."
                  : "Preference data encodes cultural defaults. Quality is never neutral; it reflects who was asked and how.",
              },
              {
                id: "your-preference", label: "Your Preference",
                type: "fourth-wall",
                detail: "You've been reading these seeds in a particular order, clicking what interested you most. That's a preference signal. If we aggregated every reader's click order, we'd have a crude reward model for this essay. Quality is always someone's path through a possibility space.",
              },
            ],
            "understanding-illusion": [
              {
                id: "stochastic-parrot", label: "Is pattern-matching the same as understanding?",
                type: "question",
                detail: "The stochastic parrot view says no: models remix patterns without grounding. The fluency is a mirror, not a mind. But the question hides an assumption\u2014that we know what understanding is in the first place.",
              },
              {
                id: "world-models", label: "Emergent World Models",
                type: "dangling",
                detail: "Another view argues that next-token prediction builds internal models of concepts, even if they are implicit. The training process creates representations that function like understanding\u2014",
                danglingTo: "weight-of-words",
                danglingText: "which brings us back to how structure emerges from gradient descent\u2026",
              },
              {
                id: "chinese-room", label: "Chinese Room",
                detail: "Symbol manipulation can look like understanding from the outside while lacking any inner comprehension.",
              },
              {
                id: "othello-gpt", label: "Othello-GPT",
                detail: (s) => s && s.v && s.v.includes("weight-of-words")
                  ? "You've seen how structure emerges as a byproduct of prediction. Othello-GPT proves this in miniature: a model trained only to predict legal moves develops an internal board representation. Structure becomes strategy."
                  : "Even in toy domains, models can internalize state and strategy, hinting at genuine representation.",
              },
              {
                id: "you-and-the-model", label: "You and the Model",
                type: "fourth-wall",
                detail: "You've been opening seeds to understand how LLMs work. Each click adds context that changes how you interpret the next seed. The model does the same thing, token by token. The question isn't whether it understands\u2014it's whether the word 'understand' can stretch far enough to cover both of you.",
              },
            ],
            "practical-guide": [
              {
                id: "narrowing", label: "How do you collapse a vast distribution into something useful?",
                type: "question",
                detail: "System prompts and structure collapse the distribution toward a specific zone of behavior. Every prompt is an act of probability narrowing\u2014you're choosing which slice of the model's knowledge to activate.",
              },
              {
                id: "scaffolding", label: "Prompt Scaffolding",
                detail: (s) => s && s.v && s.v.includes("next-word")
                  ? "You've seen how models predict the next token. Few-shot examples and chain-of-thought exploit this: they put useful patterns in the context window, shaping what comes next."
                  : "Few-shot examples and chain-of-thought provide form, not just content, guiding the model's internal flow.",
              },
              {
                id: "trust", label: "Trust Calibration",
                detail: "Treat outputs as hypotheses. Verification routines are a core part of working with models.",
              },
              {
                id: "failure-modes", label: "Failure Modes",
                type: "dangling",
                detail: "Hallucination, omission, and overconfidence are default risks. These failure modes have deep roots\u2014",
                danglingTo: "understanding-illusion",
                danglingText: "in the gap between fluency and genuine understanding\u2026",
              },
              {
                id: "the-guide", label: "This Guide",
                type: "fourth-wall",
                detail: "Every technique here is a way to manage the gap between what the model produces and what you need. You're reading a guide to working with uncertainty. Notice that this essay itself is uncertain\u2014it offers frameworks, not answers. That's the honest move.",
              },
            ],
            "tool-user": [
              {
                id: "reason-act", label: "What changes when a model can act on the world?",
                type: "question",
                detail: "Everything. Tool use lets models break tasks into steps, interleaving reasoning with external actions. The model stops being a text generator and starts being a text-directed agent.",
              },
              {
                id: "experts", label: "Mixture of Experts",
                detail: "Specialized sub-models route computation only when needed, changing cost and capability profiles.",
              },
              {
                id: "end-of-oracle", label: "The End of the Oracle",
                type: "fourth-wall",
                detail: "You've been reading an essay\u2014a static artifact. But the technology this essay describes is increasingly dynamic. Tool-using models can search, calculate, and update their own context. The oracle becomes an agent. The essay stays still; the model moves.",
              },
              {
                id: "delegated-memory", label: "Delegated Memory",
                type: "dangling",
                detail: "Agents offload memory and state to tools, reducing hallucination by grounding in external records. This is a practical response to the limits you've explored\u2014",
                danglingTo: "practical-guide",
                danglingText: "the same failure modes, but now with mitigation built in\u2026",
              },
            ],
          };
          const seedList = seedMap[plateauId] || [];
          initEngagement(state, plateauId, seedList.length);
          engagementEl.textContent = `${(state.eg[plateauId] || {}).opened || 0} of ${seedList.length} seeds opened`;

          const seeds = buildSeedCluster(seedList, { state, plateauId, onSeedOpen });

          if (plateauId === "weight-of-words") {
            const scatter = buildScatterToText();
            const scatterWrap = h("div", {
              style: { width: "100%", height: "240px", border: "1px solid var(--ink4)", borderRadius: "20px", marginTop: "24px", overflow: "hidden", position: "relative" },
            }, scatter.container);
            main.append(body, scatterWrap, seeds, engagementEl);

            if (!prefersReducedMotion()) {
              let sTicking = false;
              const onScroll = () => {
                if (sTicking) return;
                sTicking = true;
                requestAnimationFrame(() => {
                  const rect = scatterWrap.getBoundingClientRect();
                  const viewH = window.innerHeight;
                  const progress = Math.max(0, Math.min(1, 1 - (rect.bottom / (rect.height + viewH))));
                  scatter.update(progress);
                  sTicking = false;
                });
              };
              window.addEventListener("scroll", onScroll, { passive: true });
              const prevCleanup = cleanup;
              cleanup = () => { prevCleanup(); window.removeEventListener("scroll", onScroll); };
            }
          } else if (plateauId === "understanding-illusion") {
            const fork = buildCYOAFork({
              prompt: "Two framings. Neither is wrong. Which resonates with how you've been reading?",
              options: [
                {
                  label: "The model understands nothing",
                  content: "Pattern-matching, no matter how sophisticated, isn't understanding. The Chinese Room argument holds. Every fluent response is a statistical echo of training data, and the echo has no one home to hear it.",
                },
                {
                  label: "The model understands differently",
                  content: "Understanding isn't binary. If the model builds internal representations that function like concepts, predicts consequences, and adapts to context, maybe 'understanding' needs a broader definition\u2014one that includes forms of cognition unlike our own.",
                },
              ],
            });
            main.append(body, seeds, fork, engagementEl);
          } else {
            main.append(body, seeds, engagementEl);
          }

          const cards = h("div", { class: "question-cards" });
          (questionCardMap[plateauId] || []).forEach((card) => {
            cards.appendChild(
              h(
                "a",
                { class: "question-card", href: `#/${card.to}` },
                h("span", null, card.question),
                h("strong", null, card.title)
              )
            );
          });
          main.appendChild(cards);
        }
        return { view: main, cleanup };
      };

      const setView = ({ view, cleanup }) => {
        activeCleanup();
        const previous = app.firstElementChild;
        if (previous) {
          previous.classList.remove("is-visible");
          previous.addEventListener(
            "transitionend",
            () => {
              previous.remove();
            },
            { once: true }
          );
        }
        app.appendChild(view);
        requestAnimationFrame(() => {
          view.classList.add("is-visible");
        });
        activeCleanup = cleanup;
      };

      const buildNavigationChrome = (state, currentId) => {
        const miniMap = buildMiniMap(state, currentId);
        const overlay = buildOverlay(state);
        let lastActive = null;

        overlay.focusables.forEach((el) => {
          el.setAttribute("tabindex", "-1");
        });

        const openOverlay = () => {
          lastActive = document.activeElement;
          overlay.overlay.classList.add("is-open");
          overlay.overlay.setAttribute("aria-hidden", "false");
          document.body.classList.add("overlay-open");
          overlay.focusables.forEach((el) => {
            el.removeAttribute("tabindex");
          });
          overlay.closeButton.focus();
        };

        const closeOverlay = () => {
          overlay.overlay.classList.remove("is-open");
          overlay.overlay.setAttribute("aria-hidden", "true");
          document.body.classList.remove("overlay-open");
          overlay.focusables.forEach((el) => {
            el.setAttribute("tabindex", "-1");
          });
          if (lastActive && typeof lastActive.focus === "function") {
            lastActive.focus();
          }
        };

        const handleKeyDown = (event) => {
          if (event.key === "Escape") {
            event.preventDefault();
            closeOverlay();
          }
          trapFocus(overlay.overlay, event);
        };

        miniMap.button.addEventListener("click", openOverlay);
        overlay.backdrop.addEventListener("click", closeOverlay);
        overlay.closeButton.addEventListener("click", closeOverlay);
        overlay.overlay.addEventListener("keydown", handleKeyDown);

        const updateOverlay = (newState) => {
          overlay.updateState(newState);
        };

        return {
          miniMap,
          overlay,
          updateOverlay,
          cleanup: () => {
            miniMap.cleanup();
            overlay.cleanup();
            miniMap.button.removeEventListener("click", openOverlay);
            overlay.backdrop.removeEventListener("click", closeOverlay);
            overlay.closeButton.removeEventListener("click", closeOverlay);
            overlay.overlay.removeEventListener("keydown", handleKeyDown);
            document.body.classList.remove("overlay-open");
            overlay.overlay.remove();
            miniMap.container.remove();
          },
        };
      };

      let liminalPending = null;

      const showLiminalTransition = (questionText, callback) => {
        if (prefersReducedMotion() || !questionText) {
          callback();
          return;
        }
        const overlay = h("div", { class: "liminal-transition" },
          h("p", { class: "liminal-question" }, questionText)
        );
        document.body.appendChild(overlay);
        requestAnimationFrame(() => {
          overlay.classList.add("is-visible");
          setTimeout(() => {
            overlay.classList.add("is-fading");
            overlay.classList.remove("is-visible");
            overlay.addEventListener("transitionend", () => {
              overlay.remove();
            }, { once: true });
            callback();
          }, 500);
        });
      };

      let bgTempCleanup = null;

      const setupBgTemp = (isLanding) => {
        if (bgTempCleanup) bgTempCleanup();
        if (isLanding || prefersReducedMotion()) {
          document.documentElement.style.setProperty("--bg-temp", "0");
          bgTempCleanup = null;
          return;
        }
        let ticking = false;
        const onScroll = () => {
          if (ticking) return;
          ticking = true;
          requestAnimationFrame(() => {
            const scrollTop = window.scrollY;
            const scrollHeight = document.documentElement.scrollHeight - window.innerHeight;
            const progress = scrollHeight > 0 ? Math.min(1, scrollTop / scrollHeight) : 0;
            document.documentElement.style.setProperty("--bg-temp", progress.toFixed(3));
            ticking = false;
          });
        };
        window.addEventListener("scroll", onScroll, { passive: true });
        onScroll();
        bgTempCleanup = () => {
          window.removeEventListener("scroll", onScroll);
          document.documentElement.style.setProperty("--bg-temp", "0");
        };
      };

      const GHOSTFADE_MAP = {
        "averaging-problem": { requires: ["weight-of-words"], keywords: ["training data", "distribution"] },
        "the-shaping": { requires: ["quality"], keywords: ["preference", "rater"] },
        "practical-guide": { requires: ["next-word", "averaging-problem"], keywords: ["distribution", "probability"] },
        quality: { requires: ["the-shaping"], keywords: ["RLHF", "alignment"] },
        "near-zero-cost-impact": { requires: ["averaging-problem", "quality"], keywords: ["average", "quality", "distribution"] },
      };

      const applyGhostfading = (container, plateauId, visited) => {
        const config = GHOSTFADE_MAP[plateauId];
        if (!config) return;
        const hasVisited = config.requires.some((req) => visited.has(req));
        if (!hasVisited) return;
        const paragraphs = container.querySelectorAll("p");
        paragraphs.forEach((p) => {
          const text = p.textContent.toLowerCase();
          if (config.keywords.some((kw) => text.includes(kw.toLowerCase()))) {
            p.classList.add("ghostfaded");
          }
        });
      };

      let persistentNavChrome = null;

      const renderRoute = (liminalQuestion) => {
        const state = loadState();
        state.te = deriveTraversedEdges(state.tr);
        const hash = location.hash.replace(/^#\/?/, "");
        const currentId = hash && getPlateau(hash) ? hash : null;

        if (hash && !currentId) {
          location.hash = "#/";
          return;
        }

        const doRender = () => {
          if (persistentNavChrome) {
            persistentNavChrome.miniMap.updateContext(state, currentId);
            persistentNavChrome.updateOverlay(state);
          } else {
            persistentNavChrome = buildNavigationChrome(state, currentId);
            document.body.append(
              persistentNavChrome.miniMap.container,
              persistentNavChrome.overlay.overlay
            );
          }

          if (!hash) {
            setupBgTemp(true);
            const landing = buildLandingView(state);
            setView({
              view: landing.view,
              cleanup: () => {
                landing.cleanup();
              },
            });
            return;
          }
          if (currentId) {
            setupBgTemp(false);
            const plateau = buildPlateauView(state, hash);
            setView({
              view: plateau.view,
              cleanup: () => {
                plateau.cleanup();
                if (bgTempCleanup) bgTempCleanup();
              },
            });
            requestAnimationFrame(() => {
              applyGhostfading(plateau.view, currentId, new Set(state.v));

              const DWELL_ANNOTATIONS = {
                "next-word": {
                  "step-0": "The simplest possible action, repeated billions of times.",
                  "step-1": "Temperature is the only knob most users ever touch.",
                  "step-2": "The context window is the model's entire reality.",
                },
                "averaging-problem": {
                  "step-0": "The average is never anyone's voice. It's a new voice.",
                  "step-2": "The base model is the most capable and the least useful.",
                },
                "the-shaping": {
                  "step-0": "This is where the model learns to have opinions.",
                  "step-1": "The reward model is a model of a model of human preference.",
                },
              };
              const dwellData = DWELL_ANNOTATIONS[currentId];
              if (dwellData) {
                const steps = plateau.view.querySelectorAll(".scrolly-step");
                steps.forEach((step, i) => {
                  const key = `step-${i}`;
                  if (dwellData[key]) {
                    step.classList.add("dwell-target");
                    step.dataset.dwellId = key;
                  }
                });
                const dwellCleanup = setupDwellReveal(plateau.view, dwellData);
                const prevCleanup = plateau.cleanup;
                plateau.cleanup = () => { prevCleanup(); dwellCleanup(); };
              }
            });
          }
        };

        if (liminalQuestion) {
          showLiminalTransition(liminalQuestion, doRender);
        } else {
          doRender();
        }
      };

      window.addEventListener("hashchange", () => {
        const hash = location.hash.replace(/^#\/?/, "");
        const targetId = hash && getPlateau(hash) ? hash : null;
        let question = null;
        if (targetId) {
          question = ENTRY_QUESTIONS[targetId] || null;
        }
        renderRoute(question);
      });
      renderRoute();
    </script>
  </body>
</html>
